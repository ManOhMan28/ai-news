{
  "schema_name": "DoclingDocument",
  "version": "1.0.0",
  "name": "2412.18607v1",
  "origin": {
    "mimetype": "application/pdf",
    "binary_hash": 1786084884464320551,
    "filename": "2412.18607v1.pdf"
  },
  "furniture": {
    "self_ref": "#/furniture",
    "children": [],
    "name": "_root_",
    "label": "unspecified"
  },
  "body": {
    "self_ref": "#/body",
    "children": [
      {
        "$ref": "#/texts/0"
      },
      {
        "$ref": "#/texts/1"
      },
      {
        "$ref": "#/groups/0"
      },
      {
        "$ref": "#/texts/3"
      },
      {
        "$ref": "#/texts/4"
      },
      {
        "$ref": "#/texts/5"
      },
      {
        "$ref": "#/pictures/0"
      },
      {
        "$ref": "#/texts/29"
      },
      {
        "$ref": "#/texts/30"
      },
      {
        "$ref": "#/texts/31"
      },
      {
        "$ref": "#/texts/32"
      },
      {
        "$ref": "#/texts/33"
      },
      {
        "$ref": "#/texts/34"
      },
      {
        "$ref": "#/texts/35"
      },
      {
        "$ref": "#/texts/36"
      },
      {
        "$ref": "#/texts/37"
      },
      {
        "$ref": "#/texts/38"
      },
      {
        "$ref": "#/texts/39"
      },
      {
        "$ref": "#/groups/1"
      },
      {
        "$ref": "#/texts/43"
      },
      {
        "$ref": "#/texts/44"
      },
      {
        "$ref": "#/texts/45"
      },
      {
        "$ref": "#/texts/46"
      },
      {
        "$ref": "#/texts/47"
      },
      {
        "$ref": "#/texts/48"
      },
      {
        "$ref": "#/texts/49"
      },
      {
        "$ref": "#/texts/50"
      },
      {
        "$ref": "#/texts/51"
      },
      {
        "$ref": "#/texts/52"
      },
      {
        "$ref": "#/texts/53"
      },
      {
        "$ref": "#/texts/54"
      },
      {
        "$ref": "#/texts/55"
      },
      {
        "$ref": "#/texts/56"
      },
      {
        "$ref": "#/texts/57"
      },
      {
        "$ref": "#/texts/58"
      },
      {
        "$ref": "#/texts/59"
      },
      {
        "$ref": "#/texts/60"
      },
      {
        "$ref": "#/texts/61"
      },
      {
        "$ref": "#/pictures/1"
      },
      {
        "$ref": "#/texts/104"
      },
      {
        "$ref": "#/texts/105"
      },
      {
        "$ref": "#/texts/106"
      },
      {
        "$ref": "#/texts/107"
      },
      {
        "$ref": "#/texts/108"
      },
      {
        "$ref": "#/texts/109"
      },
      {
        "$ref": "#/texts/110"
      },
      {
        "$ref": "#/texts/111"
      },
      {
        "$ref": "#/texts/112"
      },
      {
        "$ref": "#/texts/113"
      },
      {
        "$ref": "#/texts/114"
      },
      {
        "$ref": "#/texts/115"
      },
      {
        "$ref": "#/texts/116"
      },
      {
        "$ref": "#/texts/117"
      },
      {
        "$ref": "#/pictures/2"
      },
      {
        "$ref": "#/pictures/3"
      },
      {
        "$ref": "#/texts/132"
      },
      {
        "$ref": "#/texts/133"
      },
      {
        "$ref": "#/texts/134"
      },
      {
        "$ref": "#/texts/135"
      },
      {
        "$ref": "#/texts/136"
      },
      {
        "$ref": "#/texts/137"
      },
      {
        "$ref": "#/texts/138"
      },
      {
        "$ref": "#/texts/139"
      },
      {
        "$ref": "#/texts/140"
      },
      {
        "$ref": "#/tables/0"
      },
      {
        "$ref": "#/texts/141"
      },
      {
        "$ref": "#/texts/142"
      },
      {
        "$ref": "#/texts/143"
      },
      {
        "$ref": "#/texts/144"
      },
      {
        "$ref": "#/texts/145"
      },
      {
        "$ref": "#/texts/146"
      },
      {
        "$ref": "#/texts/147"
      },
      {
        "$ref": "#/texts/148"
      },
      {
        "$ref": "#/texts/149"
      },
      {
        "$ref": "#/tables/1"
      },
      {
        "$ref": "#/texts/150"
      },
      {
        "$ref": "#/texts/151"
      },
      {
        "$ref": "#/texts/152"
      },
      {
        "$ref": "#/texts/153"
      },
      {
        "$ref": "#/texts/154"
      },
      {
        "$ref": "#/pictures/4"
      },
      {
        "$ref": "#/texts/155"
      },
      {
        "$ref": "#/tables/2"
      },
      {
        "$ref": "#/texts/156"
      },
      {
        "$ref": "#/texts/157"
      },
      {
        "$ref": "#/texts/158"
      },
      {
        "$ref": "#/texts/159"
      },
      {
        "$ref": "#/tables/3"
      },
      {
        "$ref": "#/texts/160"
      },
      {
        "$ref": "#/texts/161"
      },
      {
        "$ref": "#/texts/162"
      },
      {
        "$ref": "#/texts/163"
      },
      {
        "$ref": "#/pictures/5"
      },
      {
        "$ref": "#/pictures/6"
      },
      {
        "$ref": "#/texts/164"
      },
      {
        "$ref": "#/texts/165"
      },
      {
        "$ref": "#/pictures/7"
      },
      {
        "$ref": "#/texts/167"
      },
      {
        "$ref": "#/pictures/8"
      },
      {
        "$ref": "#/texts/169"
      },
      {
        "$ref": "#/tables/4"
      },
      {
        "$ref": "#/texts/170"
      },
      {
        "$ref": "#/tables/5"
      },
      {
        "$ref": "#/texts/171"
      },
      {
        "$ref": "#/texts/172"
      },
      {
        "$ref": "#/texts/173"
      },
      {
        "$ref": "#/texts/174"
      },
      {
        "$ref": "#/texts/175"
      },
      {
        "$ref": "#/tables/6"
      },
      {
        "$ref": "#/texts/176"
      },
      {
        "$ref": "#/texts/177"
      },
      {
        "$ref": "#/texts/178"
      },
      {
        "$ref": "#/texts/179"
      },
      {
        "$ref": "#/texts/180"
      },
      {
        "$ref": "#/texts/181"
      },
      {
        "$ref": "#/texts/182"
      },
      {
        "$ref": "#/groups/2"
      },
      {
        "$ref": "#/texts/195"
      },
      {
        "$ref": "#/groups/3"
      },
      {
        "$ref": "#/texts/224"
      },
      {
        "$ref": "#/groups/4"
      },
      {
        "$ref": "#/texts/254"
      },
      {
        "$ref": "#/groups/5"
      },
      {
        "$ref": "#/texts/265"
      },
      {
        "$ref": "#/texts/266"
      },
      {
        "$ref": "#/texts/267"
      },
      {
        "$ref": "#/texts/268"
      },
      {
        "$ref": "#/texts/269"
      },
      {
        "$ref": "#/texts/270"
      },
      {
        "$ref": "#/texts/271"
      },
      {
        "$ref": "#/texts/272"
      },
      {
        "$ref": "#/texts/273"
      },
      {
        "$ref": "#/texts/274"
      },
      {
        "$ref": "#/pictures/9"
      },
      {
        "$ref": "#/texts/311"
      },
      {
        "$ref": "#/texts/312"
      },
      {
        "$ref": "#/texts/313"
      },
      {
        "$ref": "#/texts/314"
      },
      {
        "$ref": "#/texts/315"
      },
      {
        "$ref": "#/texts/316"
      },
      {
        "$ref": "#/texts/317"
      },
      {
        "$ref": "#/texts/318"
      },
      {
        "$ref": "#/pictures/10"
      },
      {
        "$ref": "#/texts/322"
      }
    ],
    "name": "_root_",
    "label": "unspecified"
  },
  "groups": [
    {
      "self_ref": "#/groups/0",
      "parent": {
        "$ref": "#/body"
      },
      "children": [
        {
          "$ref": "#/texts/2"
        }
      ],
      "name": "group",
      "label": "key_value_area"
    },
    {
      "self_ref": "#/groups/1",
      "parent": {
        "$ref": "#/body"
      },
      "children": [
        {
          "$ref": "#/texts/40"
        },
        {
          "$ref": "#/texts/41"
        },
        {
          "$ref": "#/texts/42"
        }
      ],
      "name": "list",
      "label": "list"
    },
    {
      "self_ref": "#/groups/2",
      "parent": {
        "$ref": "#/body"
      },
      "children": [
        {
          "$ref": "#/texts/183"
        },
        {
          "$ref": "#/texts/184"
        },
        {
          "$ref": "#/texts/185"
        },
        {
          "$ref": "#/texts/186"
        },
        {
          "$ref": "#/texts/187"
        },
        {
          "$ref": "#/texts/188"
        },
        {
          "$ref": "#/texts/189"
        },
        {
          "$ref": "#/texts/190"
        },
        {
          "$ref": "#/texts/191"
        },
        {
          "$ref": "#/texts/192"
        },
        {
          "$ref": "#/texts/193"
        },
        {
          "$ref": "#/texts/194"
        }
      ],
      "name": "list",
      "label": "list"
    },
    {
      "self_ref": "#/groups/3",
      "parent": {
        "$ref": "#/body"
      },
      "children": [
        {
          "$ref": "#/texts/196"
        },
        {
          "$ref": "#/texts/197"
        },
        {
          "$ref": "#/texts/198"
        },
        {
          "$ref": "#/texts/199"
        },
        {
          "$ref": "#/texts/200"
        },
        {
          "$ref": "#/texts/201"
        },
        {
          "$ref": "#/texts/202"
        },
        {
          "$ref": "#/texts/203"
        },
        {
          "$ref": "#/texts/204"
        },
        {
          "$ref": "#/texts/205"
        },
        {
          "$ref": "#/texts/206"
        },
        {
          "$ref": "#/texts/207"
        },
        {
          "$ref": "#/texts/208"
        },
        {
          "$ref": "#/texts/209"
        },
        {
          "$ref": "#/texts/210"
        },
        {
          "$ref": "#/texts/211"
        },
        {
          "$ref": "#/texts/212"
        },
        {
          "$ref": "#/texts/213"
        },
        {
          "$ref": "#/texts/214"
        },
        {
          "$ref": "#/texts/215"
        },
        {
          "$ref": "#/texts/216"
        },
        {
          "$ref": "#/texts/217"
        },
        {
          "$ref": "#/texts/218"
        },
        {
          "$ref": "#/texts/219"
        },
        {
          "$ref": "#/texts/220"
        },
        {
          "$ref": "#/texts/221"
        },
        {
          "$ref": "#/texts/222"
        },
        {
          "$ref": "#/texts/223"
        }
      ],
      "name": "list",
      "label": "list"
    },
    {
      "self_ref": "#/groups/4",
      "parent": {
        "$ref": "#/body"
      },
      "children": [
        {
          "$ref": "#/texts/225"
        },
        {
          "$ref": "#/texts/226"
        },
        {
          "$ref": "#/texts/227"
        },
        {
          "$ref": "#/texts/228"
        },
        {
          "$ref": "#/texts/229"
        },
        {
          "$ref": "#/texts/230"
        },
        {
          "$ref": "#/texts/231"
        },
        {
          "$ref": "#/texts/232"
        },
        {
          "$ref": "#/texts/233"
        },
        {
          "$ref": "#/texts/234"
        },
        {
          "$ref": "#/texts/235"
        },
        {
          "$ref": "#/texts/236"
        },
        {
          "$ref": "#/texts/237"
        },
        {
          "$ref": "#/texts/238"
        },
        {
          "$ref": "#/texts/239"
        },
        {
          "$ref": "#/texts/240"
        },
        {
          "$ref": "#/texts/241"
        },
        {
          "$ref": "#/texts/242"
        },
        {
          "$ref": "#/texts/243"
        },
        {
          "$ref": "#/texts/244"
        },
        {
          "$ref": "#/texts/245"
        },
        {
          "$ref": "#/texts/246"
        },
        {
          "$ref": "#/texts/247"
        },
        {
          "$ref": "#/texts/248"
        },
        {
          "$ref": "#/texts/249"
        },
        {
          "$ref": "#/texts/250"
        },
        {
          "$ref": "#/texts/251"
        },
        {
          "$ref": "#/texts/252"
        },
        {
          "$ref": "#/texts/253"
        }
      ],
      "name": "list",
      "label": "list"
    },
    {
      "self_ref": "#/groups/5",
      "parent": {
        "$ref": "#/body"
      },
      "children": [
        {
          "$ref": "#/texts/255"
        },
        {
          "$ref": "#/texts/256"
        },
        {
          "$ref": "#/texts/257"
        },
        {
          "$ref": "#/texts/258"
        },
        {
          "$ref": "#/texts/259"
        },
        {
          "$ref": "#/texts/260"
        },
        {
          "$ref": "#/texts/261"
        },
        {
          "$ref": "#/texts/262"
        },
        {
          "$ref": "#/texts/263"
        },
        {
          "$ref": "#/texts/264"
        }
      ],
      "name": "list",
      "label": "list"
    }
  ],
  "texts": [
    {
      "self_ref": "#/texts/0",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "page_header",
      "prov": [
        {
          "page_no": 1,
          "bbox": {
            "l": 18.119998931884766,
            "t": 582.3599853515625,
            "r": 35.959999084472656,
            "b": 232.72000122070312,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            38
          ]
        }
      ],
      "orig": "arXiv:2412.18607v1 [cs.CV] 24 Dec 2024",
      "text": "arXiv:2412.18607v1 [cs.CV] 24 Dec 2024"
    },
    {
      "self_ref": "#/texts/1",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "section_header",
      "prov": [
        {
          "page_no": 1,
          "bbox": {
            "l": 61.370845794677734,
            "t": 685.3392333984375,
            "r": 550.5046997070312,
            "b": 654.9110717773438,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            101
          ]
        }
      ],
      "orig": "DrivingGPT: Unifying Driving World Modeling and Planning with Multi-modal Autoregressive Transformers",
      "text": "DrivingGPT: Unifying Driving World Modeling and Planning with Multi-modal Autoregressive Transformers",
      "level": 1
    },
    {
      "self_ref": "#/texts/2",
      "parent": {
        "$ref": "#/groups/0"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 1,
          "bbox": {
            "l": 174.3780059814453,
            "t": 629.9111938476562,
            "r": 434.0374450683594,
            "b": 617.6787719726562,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            55
          ]
        }
      ],
      "orig": "Yuntao Chen 3 Yuqi Wang 1 , 2 Zhaoxiang Zhang 1 , 2 , 3",
      "text": "Yuntao Chen 3 Yuqi Wang 1 , 2 Zhaoxiang Zhang 1 , 2 , 3"
    },
    {
      "self_ref": "#/texts/3",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 1,
          "bbox": {
            "l": 73.54109954833984,
            "t": 610.5731811523438,
            "r": 538.73974609375,
            "b": 571.0037231445312,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            234
          ]
        }
      ],
      "orig": "1 New Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences 2 School of Artificial Intelligence, University of Chinese Academy of Sciences 3 Centre for Artificial Intelligence and Robotics, HKISI, CAS",
      "text": "1 New Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences 2 School of Artificial Intelligence, University of Chinese Academy of Sciences 3 Centre for Artificial Intelligence and Robotics, HKISI, CAS"
    },
    {
      "self_ref": "#/texts/4",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 1,
          "bbox": {
            "l": 131.59225463867188,
            "t": 563.8424072265625,
            "r": 476.75,
            "b": 553.0827026367188,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            53
          ]
        }
      ],
      "orig": "Project page: https://rogerchern.github.io/DrivingGPT",
      "text": "Project page: https://rogerchern.github.io/DrivingGPT"
    },
    {
      "self_ref": "#/texts/5",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "caption",
      "prov": [
        {
          "page_no": 1,
          "bbox": {
            "l": 58.544830322265625,
            "t": 362.1647644042969,
            "r": 553.4847412109375,
            "b": 321.8042907714844,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            496
          ]
        }
      ],
      "orig": "Figure 1. Driving as next token prediction. Our DrivingGPT treat interleaved discrete visual and action tokens of a driving sequence as a unified driving language and leverage multimodal autoregressive transformers to simultaneously perform world modeling and end-to-end planning by standard next token prediction given historical driving tokens. The red rectangle in planning denotes the ego car and the blue line is the generated trajectory while the brown line is the human driving trajectory.",
      "text": "Figure 1. Driving as next token prediction. Our DrivingGPT treat interleaved discrete visual and action tokens of a driving sequence as a unified driving language and leverage multimodal autoregressive transformers to simultaneously perform world modeling and end-to-end planning by standard next token prediction given historical driving tokens. The red rectangle in planning denotes the ego car and the blue line is the generated trajectory while the brown line is the human driving trajectory."
    },
    {
      "self_ref": "#/texts/6",
      "parent": {
        "$ref": "#/pictures/0"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 1,
          "bbox": {
            "l": 74.67589569091797,
            "t": 536.4949340820312,
            "r": 193.44920349121094,
            "b": 529.8604736328125,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            23
          ]
        }
      ],
      "orig": "Historical Observations",
      "text": "Historical Observations"
    },
    {
      "self_ref": "#/texts/7",
      "parent": {
        "$ref": "#/pictures/0"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 1,
          "bbox": {
            "l": 152.310546875,
            "t": 448.7085266113281,
            "r": 183.94635009765625,
            "b": 443.6141357421875,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            7
          ]
        }
      ],
      "orig": "current",
      "text": "current"
    },
    {
      "self_ref": "#/texts/8",
      "parent": {
        "$ref": "#/pictures/0"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 1,
          "bbox": {
            "l": 121.91584014892578,
            "t": 404.7943115234375,
            "r": 177.14480590820312,
            "b": 398.9972229003906,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            12
          ]
        }
      ],
      "orig": "Action Token",
      "text": "Action Token"
    },
    {
      "self_ref": "#/texts/9",
      "parent": {
        "$ref": "#/pictures/0"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 1,
          "bbox": {
            "l": 121.92366027832031,
            "t": 419.678955078125,
            "r": 177.16378784179688,
            "b": 413.8726501464844,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            12
          ]
        }
      ],
      "orig": "Visual Token",
      "text": "Visual Token"
    },
    {
      "self_ref": "#/texts/10",
      "parent": {
        "$ref": "#/pictures/0"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 1,
          "bbox": {
            "l": 233.8260040283203,
            "t": 497.1634826660156,
            "r": 244.82403564453125,
            "b": 428.0963439941406,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            10
          ]
        }
      ],
      "orig": "DrivingGPT",
      "text": "DrivingGPT"
    },
    {
      "self_ref": "#/texts/11",
      "parent": {
        "$ref": "#/pictures/0"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 1,
          "bbox": {
            "l": 379.377197265625,
            "t": 537.2562866210938,
            "r": 451.73553466796875,
            "b": 528.89111328125,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            14
          ]
        }
      ],
      "orig": "World Modeling",
      "text": "World Modeling"
    },
    {
      "self_ref": "#/texts/12",
      "parent": {
        "$ref": "#/pictures/0"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 1,
          "bbox": {
            "l": 389.2998046875,
            "t": 463.18170166015625,
            "r": 429.70965576171875,
            "b": 454.8165283203125,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            8
          ]
        }
      ],
      "orig": "Planning",
      "text": "Planning"
    },
    {
      "self_ref": "#/texts/13",
      "parent": {
        "$ref": "#/pictures/0"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 1,
          "bbox": {
            "l": 296.5035400390625,
            "t": 485.8625183105469,
            "r": 301.75689697265625,
            "b": 479.82244873046875,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            1
          ]
        }
      ],
      "orig": "\ud835\udc76",
      "text": "\ud835\udc76"
    },
    {
      "self_ref": "#/texts/14",
      "parent": {
        "$ref": "#/pictures/0"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 1,
          "bbox": {
            "l": 302.667724609375,
            "t": 482.5852966308594,
            "r": 313.0604248046875,
            "b": 478.05316162109375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "\ud835\udc95+\ud835\udfcf",
      "text": "\ud835\udc95+\ud835\udfcf"
    },
    {
      "self_ref": "#/texts/15",
      "parent": {
        "$ref": "#/pictures/0"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 1,
          "bbox": {
            "l": 367.58038330078125,
            "t": 485.0395202636719,
            "r": 372.82647705078125,
            "b": 479.0078430175781,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            1
          ]
        }
      ],
      "orig": "\ud835\udc76",
      "text": "\ud835\udc76"
    },
    {
      "self_ref": "#/texts/16",
      "parent": {
        "$ref": "#/pictures/0"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 1,
          "bbox": {
            "l": 373.75927734375,
            "t": 481.76715087890625,
            "r": 384.0251770019531,
            "b": 477.2433776855469,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "\ud835\udc95+\ud835\udfd0",
      "text": "\ud835\udc95+\ud835\udfd0"
    },
    {
      "self_ref": "#/texts/17",
      "parent": {
        "$ref": "#/pictures/0"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 1,
          "bbox": {
            "l": 432.97454833984375,
            "t": 485.0395202636719,
            "r": 438.22064208984375,
            "b": 479.0078430175781,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            1
          ]
        }
      ],
      "orig": "\ud835\udc76",
      "text": "\ud835\udc76"
    },
    {
      "self_ref": "#/texts/18",
      "parent": {
        "$ref": "#/pictures/0"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 1,
          "bbox": {
            "l": 439.1485595703125,
            "t": 481.76715087890625,
            "r": 449.4193420410156,
            "b": 477.2433776855469,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "\ud835\udc95+\ud835\udfd1",
      "text": "\ud835\udc95+\ud835\udfd1"
    },
    {
      "self_ref": "#/texts/19",
      "parent": {
        "$ref": "#/pictures/0"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 1,
          "bbox": {
            "l": 499.10174560546875,
            "t": 484.2476806640625,
            "r": 504.3551025390625,
            "b": 478.2076110839844,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            1
          ]
        }
      ],
      "orig": "\ud835\udc76",
      "text": "\ud835\udc76"
    },
    {
      "self_ref": "#/texts/20",
      "parent": {
        "$ref": "#/pictures/0"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 1,
          "bbox": {
            "l": 505.2611083984375,
            "t": 480.94903564453125,
            "r": 515.8768310546875,
            "b": 476.4431457519531,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "\ud835\udc95+\ud835\udfd2",
      "text": "\ud835\udc95+\ud835\udfd2"
    },
    {
      "self_ref": "#/texts/21",
      "parent": {
        "$ref": "#/pictures/0"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 1,
          "bbox": {
            "l": 420.2942810058594,
            "t": 390.92236328125,
            "r": 425.643798828125,
            "b": 384.97845458984375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            1
          ]
        }
      ],
      "orig": "\ud835\udc68",
      "text": "\ud835\udc68"
    },
    {
      "self_ref": "#/texts/22",
      "parent": {
        "$ref": "#/pictures/0"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 1,
          "bbox": {
            "l": 426.48260498046875,
            "t": 387.6825256347656,
            "r": 436.8655700683594,
            "b": 383.150390625,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "\ud835\udc95+\ud835\udfcf",
      "text": "\ud835\udc95+\ud835\udfcf"
    },
    {
      "self_ref": "#/texts/23",
      "parent": {
        "$ref": "#/pictures/0"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 1,
          "bbox": {
            "l": 445.9476013183594,
            "t": 390.42529296875,
            "r": 451.297119140625,
            "b": 384.48138427734375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            1
          ]
        }
      ],
      "orig": "\ud835\udc68",
      "text": "\ud835\udc68"
    },
    {
      "self_ref": "#/texts/24",
      "parent": {
        "$ref": "#/pictures/0"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 1,
          "bbox": {
            "l": 452.1213684082031,
            "t": 387.18548583984375,
            "r": 462.40740966796875,
            "b": 382.6533508300781,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "\ud835\udc95+\ud835\udfd0",
      "text": "\ud835\udc95+\ud835\udfd0"
    },
    {
      "self_ref": "#/texts/25",
      "parent": {
        "$ref": "#/pictures/0"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 1,
          "bbox": {
            "l": 471.0675354003906,
            "t": 390.6595153808594,
            "r": 476.4096374511719,
            "b": 384.7238464355469,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            1
          ]
        }
      ],
      "orig": "\ud835\udc68",
      "text": "\ud835\udc68"
    },
    {
      "self_ref": "#/texts/26",
      "parent": {
        "$ref": "#/pictures/0"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 1,
          "bbox": {
            "l": 477.2551574707031,
            "t": 387.4196472167969,
            "r": 487.52105712890625,
            "b": 382.8958740234375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "\ud835\udc95+\ud835\udfd1",
      "text": "\ud835\udc95+\ud835\udfd1"
    },
    {
      "self_ref": "#/texts/27",
      "parent": {
        "$ref": "#/pictures/0"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 1,
          "bbox": {
            "l": 495.8333740234375,
            "t": 390.75262451171875,
            "r": 501.1828918457031,
            "b": 384.8087158203125,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            1
          ]
        }
      ],
      "orig": "\ud835\udc68",
      "text": "\ud835\udc68"
    },
    {
      "self_ref": "#/texts/28",
      "parent": {
        "$ref": "#/pictures/0"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 1,
          "bbox": {
            "l": 502.02655029296875,
            "t": 387.486572265625,
            "r": 512.627685546875,
            "b": 382.9806823730469,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "\ud835\udc95+\ud835\udfd2",
      "text": "\ud835\udc95+\ud835\udfd2"
    },
    {
      "self_ref": "#/texts/29",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "section_header",
      "prov": [
        {
          "page_no": 1,
          "bbox": {
            "l": 154.49058532714844,
            "t": 303.8700866699219,
            "r": 198.85633850097656,
            "b": 295.465576171875,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            8
          ]
        }
      ],
      "orig": "Abstract",
      "text": "Abstract",
      "level": 1
    },
    {
      "self_ref": "#/texts/30",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 1,
          "bbox": {
            "l": 57.04545211791992,
            "t": 263.54443359375,
            "r": 294.98223876953125,
            "b": 78.94764709472656,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            905
          ]
        }
      ],
      "orig": "World model-based searching and planning are widely recognized as a promising path toward human-level physical intelligence. However, current driving world models primarily rely on video diffusion models, which specialize in visual generation but lack the flexibility to incorporate other modalities like action. In contrast, autoregressive transformers have demonstrated exceptional capability in modeling multimodal data. Our work aims to unify both driving model simulation and trajectory planning into a single sequence modeling problem. We introduce a multimodal driving language based on interleaved image and action tokens, and develop DrivingGPT to learn joint world modeling and planning through standard next-token prediction. Our DrivingGPT demonstrates strong performance in both action-conditioned video generation and end-to-end planning, outperforming strong baselines on large-scale nuPlan",
      "text": "World model-based searching and planning are widely recognized as a promising path toward human-level physical intelligence. However, current driving world models primarily rely on video diffusion models, which specialize in visual generation but lack the flexibility to incorporate other modalities like action. In contrast, autoregressive transformers have demonstrated exceptional capability in modeling multimodal data. Our work aims to unify both driving model simulation and trajectory planning into a single sequence modeling problem. We introduce a multimodal driving language based on interleaved image and action tokens, and develop DrivingGPT to learn joint world modeling and planning through standard next-token prediction. Our DrivingGPT demonstrates strong performance in both action-conditioned video generation and end-to-end planning, outperforming strong baselines on large-scale nuPlan"
    },
    {
      "self_ref": "#/texts/31",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 1,
          "bbox": {
            "l": 317.41937255859375,
            "t": 302.4253845214844,
            "r": 420.641845703125,
            "b": 295.4515686035156,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            22
          ]
        }
      ],
      "orig": "and NAVSIM benchmarks.",
      "text": "and NAVSIM benchmarks."
    },
    {
      "self_ref": "#/texts/32",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "section_header",
      "prov": [
        {
          "page_no": 1,
          "bbox": {
            "l": 318.027099609375,
            "t": 262.2679748535156,
            "r": 393.8828430175781,
            "b": 253.85153198242188,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            15
          ]
        }
      ],
      "orig": "1. Introduction",
      "text": "1. Introduction",
      "level": 1
    },
    {
      "self_ref": "#/texts/33",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 1,
          "bbox": {
            "l": 317.2798767089844,
            "t": 240.1223602294922,
            "r": 553.5130615234375,
            "b": 78.84796905517578,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            787
          ]
        }
      ],
      "orig": "Driving world models [19 , 27 , 31 , 60 , 63 , 74] have gained significant attention as model-based searching and planning are widely considered essential paths toward human-level physical intelligence [34]. These models serve multiple purposes, including training data augmentation, rare scenario generation, and contingency planning. Most current world models are developed by fine-tuning existing diffusion models [1 , 46], leveraging the generalization capabilities of video generation foundation models. Control signals-such as text, layout, and driving maneuvers-are incorporated through two main approaches: cross-attention between spatial features of diffusion models [36] and control signal features, or channel-level feature modulation techniques like AdaLN [42] and FiLM [43].",
      "text": "Driving world models [19 , 27 , 31 , 60 , 63 , 74] have gained significant attention as model-based searching and planning are widely considered essential paths toward human-level physical intelligence [34]. These models serve multiple purposes, including training data augmentation, rare scenario generation, and contingency planning. Most current world models are developed by fine-tuning existing diffusion models [1 , 46], leveraging the generalization capabilities of video generation foundation models. Control signals-such as text, layout, and driving maneuvers-are incorporated through two main approaches: cross-attention between spatial features of diffusion models [36] and control signal features, or channel-level feature modulation techniques like AdaLN [42] and FiLM [43]."
    },
    {
      "self_ref": "#/texts/34",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "page_footer",
      "prov": [
        {
          "page_no": 1,
          "bbox": {
            "l": 304.6148376464844,
            "t": 57.84661102294922,
            "r": 307.43426513671875,
            "b": 51.11189270019531,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            1
          ]
        }
      ],
      "orig": "1",
      "text": "1"
    },
    {
      "self_ref": "#/texts/35",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 2,
          "bbox": {
            "l": 58.589664459228516,
            "t": 716.8414306640625,
            "r": 294.6634521484375,
            "b": 555.5670776367188,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            772
          ]
        }
      ],
      "orig": "Despite advances in driving world models, a fundamental challenge persists: the seamless integration of world modeling and planning in a differentiable framework remains largely unresolved, thereby limiting the full potential of differentiable model-based planning. World models currently base primarily on video diffusion architectures, limiting their ability to generate multiple modalities such as text and action sequences. As a result, achieving true end-to-end integration of driving planning and world modeling within the diffusion model framework continues to be a significant technical challenge. These limitations motivate us to explore alternative architectures that naturally handle multi-modal inputs and outputs and enable end-to-end differentiable planning.",
      "text": "Despite advances in driving world models, a fundamental challenge persists: the seamless integration of world modeling and planning in a differentiable framework remains largely unresolved, thereby limiting the full potential of differentiable model-based planning. World models currently base primarily on video diffusion architectures, limiting their ability to generate multiple modalities such as text and action sequences. As a result, achieving true end-to-end integration of driving planning and world modeling within the diffusion model framework continues to be a significant technical challenge. These limitations motivate us to explore alternative architectures that naturally handle multi-modal inputs and outputs and enable end-to-end differentiable planning."
    },
    {
      "self_ref": "#/texts/36",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 2,
          "bbox": {
            "l": 58.589664459228516,
            "t": 550.1213989257812,
            "r": 294.5538635253906,
            "b": 426.0572814941406,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            605
          ]
        }
      ],
      "orig": "In contrast to diffusion models, autoregressive transformers with next-token prediction training targets have demonstrated exceptional modeling ability in a wide range of tasks tasks including language modeling [5 , 16 , 53 , 58], visual question answering [38 , 59], image generation [41 , 45 , 49 , 57 , 72], video prediction [20 , 61 , 68 , 69], sequential decision making [9 , 47] and robot manipulation [3 , 4 , 8 , 40]. The natural ability of autoregressive transformers to handle sequential data and multiple modalities makes them particularly promising for integrated model-based driving planners.",
      "text": "In contrast to diffusion models, autoregressive transformers with next-token prediction training targets have demonstrated exceptional modeling ability in a wide range of tasks tasks including language modeling [5 , 16 , 53 , 58], visual question answering [38 , 59], image generation [41 , 45 , 49 , 57 , 72], video prediction [20 , 61 , 68 , 69], sequential decision making [9 , 47] and robot manipulation [3 , 4 , 8 , 40]. The natural ability of autoregressive transformers to handle sequential data and multiple modalities makes them particularly promising for integrated model-based driving planners."
    },
    {
      "self_ref": "#/texts/37",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 2,
          "bbox": {
            "l": 58.52988815307617,
            "t": 418.54937744140625,
            "r": 294.7729797363281,
            "b": 93.25096130371094,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            1569
          ]
        }
      ],
      "orig": "In this work, we aim to leverage the modeling capabilities of autoregressive transformers for both world modeling and trajectory planning in driving tasks. Specifically, we formulate visual driving world modeling and end-toend driving trajectory planning as a unified sequence modeling problem. We transform driving video frames into discrete tokens using pretrained VQ-VAEs [57]. Similarly, we convert driving trajectories into frame-to-frame relative actions, which are then quantized into discrete bins. We design a multi-modal driving language by unifying the image and action vocabularies, interleaving image and action tokens on a frame-by-frame basis. We use a Llama-like DrivingGPT architecture with frame-wise 1D rotary embeddings [48] to model the multi-modal driving language through standard next token prediction. Our DrivingGPT demonstrates strong performance across both world modeling and planning tasks. In terms of video generation, our method surpasses the strong SVD baseline [1], outperforming it in metrics such as FID and FVD. Additionally, since video generation in DrivingGPT is jointly trained with the planning task, our approach exhibits a more accurate understanding of action conditions when generating long-horizon videos, as shown in Figure 3. Experiments on the challenging NAVSIM benchmark [15] further demonstrate the effectiveness of the proposed multi-modal driving language as a training target for planning. Our DrivingGPT outperforms the prevalent visual encoder with an MLP trajectory decoder planner in terms of driving scores.",
      "text": "In this work, we aim to leverage the modeling capabilities of autoregressive transformers for both world modeling and trajectory planning in driving tasks. Specifically, we formulate visual driving world modeling and end-toend driving trajectory planning as a unified sequence modeling problem. We transform driving video frames into discrete tokens using pretrained VQ-VAEs [57]. Similarly, we convert driving trajectories into frame-to-frame relative actions, which are then quantized into discrete bins. We design a multi-modal driving language by unifying the image and action vocabularies, interleaving image and action tokens on a frame-by-frame basis. We use a Llama-like DrivingGPT architecture with frame-wise 1D rotary embeddings [48] to model the multi-modal driving language through standard next token prediction. Our DrivingGPT demonstrates strong performance across both world modeling and planning tasks. In terms of video generation, our method surpasses the strong SVD baseline [1], outperforming it in metrics such as FID and FVD. Additionally, since video generation in DrivingGPT is jointly trained with the planning task, our approach exhibits a more accurate understanding of action conditions when generating long-horizon videos, as shown in Figure 3. Experiments on the challenging NAVSIM benchmark [15] further demonstrate the effectiveness of the proposed multi-modal driving language as a training target for planning. Our DrivingGPT outperforms the prevalent visual encoder with an MLP trajectory decoder planner in terms of driving scores."
    },
    {
      "self_ref": "#/texts/38",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 2,
          "bbox": {
            "l": 70.63433074951172,
            "t": 87.8042984008789,
            "r": 266.92742919921875,
            "b": 78.83795928955078,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            49
          ]
        }
      ],
      "orig": "In summary, our key contributions are as follows:",
      "text": "In summary, our key contributions are as follows:"
    },
    {
      "self_ref": "#/texts/39",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "page_footer",
      "prov": [
        {
          "page_no": 2,
          "bbox": {
            "l": 303.8078918457031,
            "t": 57.84741973876953,
            "r": 308.2412414550781,
            "b": 51.112701416015625,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            1
          ]
        }
      ],
      "orig": "2",
      "text": "2"
    },
    {
      "self_ref": "#/texts/40",
      "parent": {
        "$ref": "#/groups/1"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 2,
          "bbox": {
            "l": 317.64849853515625,
            "t": 716.84228515625,
            "r": 553.2039794921875,
            "b": 684.4439697265625,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            150
          ]
        }
      ],
      "orig": "\u00b7 We propose a multi-modal driving language that unifies the visual world modeling and the trajectory planning problems into a sequence modeling task.",
      "text": "\u00b7 We propose a multi-modal driving language that unifies the visual world modeling and the trajectory planning problems into a sequence modeling task.",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/41",
      "parent": {
        "$ref": "#/groups/1"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 2,
          "bbox": {
            "l": 317.64849853515625,
            "t": 681.6942749023438,
            "r": 553.2537841796875,
            "b": 649.2959594726562,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            141
          ]
        }
      ],
      "orig": "\u00b7 We design a DrivingGPT model that successful learns these two tasks via next token prediction simultaneously for the first time in driving.",
      "text": "\u00b7 We design a DrivingGPT model that successful learns these two tasks via next token prediction simultaneously for the first time in driving.",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/42",
      "parent": {
        "$ref": "#/groups/1"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 2,
          "bbox": {
            "l": 317.64849853515625,
            "t": 646.5462646484375,
            "r": 553.4132690429688,
            "b": 604.4642944335938,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            194
          ]
        }
      ],
      "orig": "\u00b7 Our DrivingGPT shows strong performance against established baselines both for action-conditioned video generation and end-to-end planning on large-scale real-world nuPlan and NAVSIM datasets.",
      "text": "\u00b7 Our DrivingGPT shows strong performance against established baselines both for action-conditioned video generation and end-to-end planning on large-scale real-world nuPlan and NAVSIM datasets.",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/43",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "section_header",
      "prov": [
        {
          "page_no": 2,
          "bbox": {
            "l": 317.4532470703125,
            "t": 587.0489501953125,
            "r": 404.6783752441406,
            "b": 578.6564331054688,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            16
          ]
        }
      ],
      "orig": "2. Related Works",
      "text": "2. Related Works",
      "level": 1
    },
    {
      "self_ref": "#/texts/44",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "section_header",
      "prov": [
        {
          "page_no": 2,
          "bbox": {
            "l": 317.4363098144531,
            "t": 566.994384765625,
            "r": 519.5732421875,
            "b": 557.1752319335938,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            40
          ]
        }
      ],
      "orig": "2.1. World Models for Autonomous Driving",
      "text": "2.1. World Models for Autonomous Driving",
      "level": 1
    },
    {
      "self_ref": "#/texts/45",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 2,
          "bbox": {
            "l": 317.2998046875,
            "t": 548.8162841796875,
            "r": 554.001220703125,
            "b": 331.0241394042969,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            1067
          ]
        }
      ],
      "orig": "World models [23 , 24 , 34] have gained significant attention in autonomous driving, aiming to predict different future states based on actions. Existing work primarily focuses on generation, whether in 2D video forecasting [19 , 27 , 31 , 60 , 62 , 63 , 70] or 3D spatial predictions [21 , 65 , 74 - 76]. Among these, visual modeling has received considerable attention due to its richer and more human-like representational forms. Drive-WM [63] further explores the use of future visual feedback to guide an end-to-end planner. Except GAIA-1 which features an autogressive next token predictor with an additional diffusion image decoder, most of the previous works build on the diffusion models [1 , 46]. Although diffusion models have achieved more realistic visual qualities, they still face challenges regarding temporal consistency and longer video generation. In this paper, we innovatively explore auto-regressive video prediction, unifying planning and generation within a single model that can simultaneously output predictions of future states and actions.",
      "text": "World models [23 , 24 , 34] have gained significant attention in autonomous driving, aiming to predict different future states based on actions. Existing work primarily focuses on generation, whether in 2D video forecasting [19 , 27 , 31 , 60 , 62 , 63 , 70] or 3D spatial predictions [21 , 65 , 74 - 76]. Among these, visual modeling has received considerable attention due to its richer and more human-like representational forms. Drive-WM [63] further explores the use of future visual feedback to guide an end-to-end planner. Except GAIA-1 which features an autogressive next token predictor with an additional diffusion image decoder, most of the previous works build on the diffusion models [1 , 46]. Although diffusion models have achieved more realistic visual qualities, they still face challenges regarding temporal consistency and longer video generation. In this paper, we innovatively explore auto-regressive video prediction, unifying planning and generation within a single model that can simultaneously output predictions of future states and actions."
    },
    {
      "self_ref": "#/texts/46",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "section_header",
      "prov": [
        {
          "page_no": 2,
          "bbox": {
            "l": 317.4363098144531,
            "t": 316.8713684082031,
            "r": 520.93212890625,
            "b": 307.05218505859375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            42
          ]
        }
      ],
      "orig": "2.2. Generation with Autoregressive Models",
      "text": "2.2. Generation with Autoregressive Models",
      "level": 1
    },
    {
      "self_ref": "#/texts/47",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 2,
          "bbox": {
            "l": 317.33966064453125,
            "t": 298.6932067871094,
            "r": 554.001220703125,
            "b": 78.83882141113281,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            1102
          ]
        }
      ],
      "orig": "Early works explored the direct autoregressive generation of images at the pixel level [55 , 56]. Inspired by VQVAE [57], many methods [18 , 35 , 73] have encoded continuous images into discrete tokens. Recently, several approaches have drawn on the success of the next-token prediction paradigm used in large language models [53], applying it to image and video generation. In image generation, LlamaGen [49] employs a language model architecture to demonstrate that simple next-token prediction can produce high-quality images. Additionally, VAR [52] adopts a next-scale prediction generation paradigm, distinguishing itself from the sequence modeling approach of traditional language models. In video generation, Loong [64] proposes progressive shortto-long training, exploring the auto-regressive generation of long videos. Meanwhile, VideoPoet [33], Chameleon [51], and Emu3 [61] focus on multi-modal generation, integrating language comprehension with visual generation through the use of discrete tokens. In this paper, we adopt the multimodal auto-regressive paradigm, and simultaneously output",
      "text": "Early works explored the direct autoregressive generation of images at the pixel level [55 , 56]. Inspired by VQVAE [57], many methods [18 , 35 , 73] have encoded continuous images into discrete tokens. Recently, several approaches have drawn on the success of the next-token prediction paradigm used in large language models [53], applying it to image and video generation. In image generation, LlamaGen [49] employs a language model architecture to demonstrate that simple next-token prediction can produce high-quality images. Additionally, VAR [52] adopts a next-scale prediction generation paradigm, distinguishing itself from the sequence modeling approach of traditional language models. In video generation, Loong [64] proposes progressive shortto-long training, exploring the auto-regressive generation of long videos. Meanwhile, VideoPoet [33], Chameleon [51], and Emu3 [61] focus on multi-modal generation, integrating language comprehension with visual generation through the use of discrete tokens. In this paper, we adopt the multimodal auto-regressive paradigm, and simultaneously output"
    },
    {
      "self_ref": "#/texts/48",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 3,
          "bbox": {
            "l": 58.68928909301758,
            "t": 716.8414306640625,
            "r": 181.21929931640625,
            "b": 707.8751220703125,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            30
          ]
        }
      ],
      "orig": "video generation and planning.",
      "text": "video generation and planning."
    },
    {
      "self_ref": "#/texts/49",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "section_header",
      "prov": [
        {
          "page_no": 3,
          "bbox": {
            "l": 58.686302185058594,
            "t": 698.4425659179688,
            "r": 230.88351440429688,
            "b": 688.6234130859375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            34
          ]
        }
      ],
      "orig": "2.3. End-to-end Autonomous Driving",
      "text": "2.3. End-to-end Autonomous Driving",
      "level": 1
    },
    {
      "self_ref": "#/texts/50",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 3,
          "bbox": {
            "l": 58.54981231689453,
            "t": 680.9863891601562,
            "r": 294.6634216308594,
            "b": 414.2580261230469,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            1325
          ]
        }
      ],
      "orig": "End-to-end autonomous driving [2 , 10 , 14 , 29 , 32 , 44 , 67] has gained significant attention for its ability to directly generate vehicle motion plans from raw sensor inputs. From the evaluation benchmark, existing methods can be categorized into open-loop and closed-loop settings. For closed-loop evaluations, A broad body of research [11-13 , 26 , 28 , 30] conducts evaluations in simulators, such as CARLA [17], nuPlan [7] and Waymax [22]. Recently, developing end-toend models on open-loop benchmarks has gained growing attention. On the nuScenes [6] benchmark, UniAD [29] introduces a unified framework that integrates multiple driving tasks and directly generates planning outputs. VAD [32] advances vectorized autonomous driving, achieving improved performance. PARA-Drive [66] designs a fully parallel end-to-end autonomous vehicle architecture, achieving state-of-the-art performance in perception, prediction, and planning, while also significantly enhancing runtime efficiency. SparseDrive [50] explores the sparse representation and proposes a hierarchical planning selection strategy. In this paper, unlike previous BEV-based planning frameworks, We have innovatively explored an autoregressive model paradigm trained using world models, and evaluate it in an open-loop setting on the NAVSIM benchmark [15].",
      "text": "End-to-end autonomous driving [2 , 10 , 14 , 29 , 32 , 44 , 67] has gained significant attention for its ability to directly generate vehicle motion plans from raw sensor inputs. From the evaluation benchmark, existing methods can be categorized into open-loop and closed-loop settings. For closed-loop evaluations, A broad body of research [11-13 , 26 , 28 , 30] conducts evaluations in simulators, such as CARLA [17], nuPlan [7] and Waymax [22]. Recently, developing end-toend models on open-loop benchmarks has gained growing attention. On the nuScenes [6] benchmark, UniAD [29] introduces a unified framework that integrates multiple driving tasks and directly generates planning outputs. VAD [32] advances vectorized autonomous driving, achieving improved performance. PARA-Drive [66] designs a fully parallel end-to-end autonomous vehicle architecture, achieving state-of-the-art performance in perception, prediction, and planning, while also significantly enhancing runtime efficiency. SparseDrive [50] explores the sparse representation and proposes a hierarchical planning selection strategy. In this paper, unlike previous BEV-based planning frameworks, We have innovatively explored an autoregressive model paradigm trained using world models, and evaluate it in an open-loop setting on the NAVSIM benchmark [15]."
    },
    {
      "self_ref": "#/texts/51",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "section_header",
      "prov": [
        {
          "page_no": 3,
          "bbox": {
            "l": 58.6912841796875,
            "t": 401.5679626464844,
            "r": 240.05165100097656,
            "b": 390.8561096191406,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            35
          ]
        }
      ],
      "orig": "3. Driving as Next Token Prediction",
      "text": "3. Driving as Next Token Prediction",
      "level": 1
    },
    {
      "self_ref": "#/texts/52",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 3,
          "bbox": {
            "l": 58.52988815307617,
            "t": 381.4213562011719,
            "r": 294.45416259765625,
            "b": 280.78924560546875,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            456
          ]
        }
      ],
      "orig": "Autoregressive transformers trained for next-token prediction have demonstrated remarkable capabilities across diverse domains. In this work, we harness the power of autoregressive transformers for autonomous driving by combining world modeling and trajectory planning. Our approach converts both visual inputs and driving actions into a discrete driving language, enabling unified modeling through autoregressive transformers, as illustrated in Figure 2 .",
      "text": "Autoregressive transformers trained for next-token prediction have demonstrated remarkable capabilities across diverse domains. In this work, we harness the power of autoregressive transformers for autonomous driving by combining world modeling and trajectory planning. Our approach converts both visual inputs and driving actions into a discrete driving language, enabling unified modeling through autoregressive transformers, as illustrated in Figure 2 ."
    },
    {
      "self_ref": "#/texts/53",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "section_header",
      "prov": [
        {
          "page_no": 3,
          "bbox": {
            "l": 58.67534255981445,
            "t": 269.2934875488281,
            "r": 178.99310302734375,
            "b": 261.57843017578125,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            24
          ]
        }
      ],
      "orig": "3.1. Problem Formulation",
      "text": "3.1. Problem Formulation",
      "level": 1
    },
    {
      "self_ref": "#/texts/54",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 3,
          "bbox": {
            "l": 58.54981231689453,
            "t": 251.82833862304688,
            "r": 294.7683410644531,
            "b": 79.24641418457031,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            818
          ]
        }
      ],
      "orig": "Like many other tasks, the driving problem can be formulated as a Markov Decision Process (MDP), which is a general mathematical framework for decision-making in environments with partially random outcomes. An MDP comprises a state space S that reflects all states of the ego car and the environment, an action space A, a random transition function P(st+1|st , at) that describes the probability distribution of all possible outcomes given the state and action at time t, and a scalar reward function R(st+1|st , at) that shapes the optimal action to take under certain states. In most real-world applications, we can only perceive noisy observations o t instead of the underlying states st. Therefore, an observation probability function Z(ot|st) is introduced, and the MDP becomes a partially observable MDP (POMDP).",
      "text": "Like many other tasks, the driving problem can be formulated as a Markov Decision Process (MDP), which is a general mathematical framework for decision-making in environments with partially random outcomes. An MDP comprises a state space S that reflects all states of the ego car and the environment, an action space A, a random transition function P(st+1|st , at) that describes the probability distribution of all possible outcomes given the state and action at time t, and a scalar reward function R(st+1|st , at) that shapes the optimal action to take under certain states. In most real-world applications, we can only perceive noisy observations o t instead of the underlying states st. Therefore, an observation probability function Z(ot|st) is introduced, and the MDP becomes a partially observable MDP (POMDP)."
    },
    {
      "self_ref": "#/texts/55",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "page_footer",
      "prov": [
        {
          "page_no": 3,
          "bbox": {
            "l": 303.9375915527344,
            "t": 57.847389221191406,
            "r": 307.8130187988281,
            "b": 50.983158111572266,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            1
          ]
        }
      ],
      "orig": "3",
      "text": "3"
    },
    {
      "self_ref": "#/texts/56",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 3,
          "bbox": {
            "l": 317.3795166015625,
            "t": 717.5087280273438,
            "r": 553.5528564453125,
            "b": 649.294921875,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            296
          ]
        }
      ],
      "orig": "Both the end-to-end policy \u03c0(at|ot) that predicts future trajectories and the observation space random transition function P(ot+1|ot , at) that models driving world dynamics are of great importance in autonomous driving. We seek to unify these two challenges into a single sequence modeling task.",
      "text": "Both the end-to-end policy \u03c0(at|ot) that predicts future trajectories and the observation space random transition function P(ot+1|ot , at) that models driving world dynamics are of great importance in autonomous driving. We seek to unify these two challenges into a single sequence modeling task."
    },
    {
      "self_ref": "#/texts/57",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "section_header",
      "prov": [
        {
          "page_no": 3,
          "bbox": {
            "l": 317.42535400390625,
            "t": 639.1143798828125,
            "r": 479.21160888671875,
            "b": 629.2952270507812,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            32
          ]
        }
      ],
      "orig": "3.2. Multimodal Driving Language",
      "text": "3.2. Multimodal Driving Language",
      "level": 1
    },
    {
      "self_ref": "#/texts/58",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 3,
          "bbox": {
            "l": 317.3994445800781,
            "t": 621.5732421875,
            "r": 553.5231323242188,
            "b": 542.3208618164062,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            369
          ]
        }
      ],
      "orig": "A general driving sequence could be represented as a series of time-synchronized observation-action pairs o1 , a1 , o2 , a2 , . . . , ot , at with a time horizon of T. Here we need to tokenize both the observation o t and the action at into discrete tokens and form a multimodal driving language before we leverage autoregressive transformers for next token prediction.",
      "text": "A general driving sequence could be represented as a series of time-synchronized observation-action pairs o1 , a1 , o2 , a2 , . . . , ot , at with a time horizon of T. Here we need to tokenize both the observation o t and the action at into discrete tokens and form a multimodal driving language before we leverage autoregressive transformers for next token prediction."
    },
    {
      "self_ref": "#/texts/59",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 3,
          "bbox": {
            "l": 317.1305236816406,
            "t": 524.6509399414062,
            "r": 553.4135131835938,
            "b": 363.2968444824219,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            759
          ]
        }
      ],
      "orig": "Observation Tokenization To make our method simple, we only include the front camera image oi \u2208 R 3\u00d7H\u00d7W in our observation space, leaving more advanced sensor setups like surrounding cemaras, LiDARs and IMUs for future exploration. Although pixel-level transformers [41] have shown great potential in modeling images, we still need to strike a balance between the information loss in image compression and the limited context length of transformers when dealing with long driving sequences. To incorporate more frames into our sequence modeling, we leverage VQVAE [18] for down-sampling images oi of shape H \u00d7 W into image tokens zi = {zij |j = 1, . . . , HW/S 2 } of shape H/S \u00d7W/S and of vocabulary size D, here zij denotes the j-th token of the i-th image.",
      "text": "Observation Tokenization To make our method simple, we only include the front camera image oi \u2208 R 3\u00d7H\u00d7W in our observation space, leaving more advanced sensor setups like surrounding cemaras, LiDARs and IMUs for future exploration. Although pixel-level transformers [41] have shown great potential in modeling images, we still need to strike a balance between the information loss in image compression and the limited context length of transformers when dealing with long driving sequences. To incorporate more frames into our sequence modeling, we leverage VQVAE [18] for down-sampling images oi of shape H \u00d7 W into image tokens zi = {zij |j = 1, . . . , HW/S 2 } of shape H/S \u00d7W/S and of vocabulary size D, here zij denotes the j-th token of the i-th image."
    },
    {
      "self_ref": "#/texts/60",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 3,
          "bbox": {
            "l": 316.5626525878906,
            "t": 345.63690185546875,
            "r": 554.001220703125,
            "b": 78.83879089355469,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            1350
          ]
        }
      ],
      "orig": "Action Tokenization What set our method apart from existing driving world modeling works is the ability to generate future driving actions. Unlike most end-to-end driving planners [29 , 32] \u03c0\u03b8(at :t+N |a<t , s \u2264t ) which predicts a whole driving trajectory spanning a horizon of future N timesteps. The causal nature of our next token prediction formulation prohibit us from constructing a driving sequence with a long action horizon like o1 , a1 , a2 , . . . , aN , o2 , a2 , a3 , . . . , aN+1 , . . . as both future observations and actions gaining too much privileged information from history actions. If we use a action horizon of N, the last history action will contains all future driving actions until timestep N - 1, causing the model just learn to copy history actions instead of learning to drive based on observation. So instead of predicting a long horizon absolute driving trajectory (at , at+1 , . . . , at+N ) = (TtTt+1-\u2192t, TtTt+2-\u2192t, . . . , TtTt+N+1-\u2192t), we predict a framewise relative driving trajectory (at , at+1 , . . . , at+N ) = (TtTt+1-\u2192t, TtTt+2-\u2192t+1, . . . , TtTt+N+1-\u2192t+N ), here TiTi-\u2192j = (\u2206xij , \u2206yij , \u2206\u03b8 ij ) denotes the longitudinal translation, lateral translation and yaw rotation between timestep i and j respectively. We quantize at into action tokens by first clamping each action component between their 1st and",
      "text": "Action Tokenization What set our method apart from existing driving world modeling works is the ability to generate future driving actions. Unlike most end-to-end driving planners [29 , 32] \u03c0\u03b8(at :t+N |a<t , s \u2264t ) which predicts a whole driving trajectory spanning a horizon of future N timesteps. The causal nature of our next token prediction formulation prohibit us from constructing a driving sequence with a long action horizon like o1 , a1 , a2 , . . . , aN , o2 , a2 , a3 , . . . , aN+1 , . . . as both future observations and actions gaining too much privileged information from history actions. If we use a action horizon of N, the last history action will contains all future driving actions until timestep N - 1, causing the model just learn to copy history actions instead of learning to drive based on observation. So instead of predicting a long horizon absolute driving trajectory (at , at+1 , . . . , at+N ) = (TtTt+1-\u2192t, TtTt+2-\u2192t, . . . , TtTt+N+1-\u2192t), we predict a framewise relative driving trajectory (at , at+1 , . . . , at+N ) = (TtTt+1-\u2192t, TtTt+2-\u2192t+1, . . . , TtTt+N+1-\u2192t+N ), here TiTi-\u2192j = (\u2206xij , \u2206yij , \u2206\u03b8 ij ) denotes the longitudinal translation, lateral translation and yaw rotation between timestep i and j respectively. We quantize at into action tokens by first clamping each action component between their 1st and"
    },
    {
      "self_ref": "#/texts/61",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "caption",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 58.60759735107422,
            "t": 480.8497619628906,
            "r": 553.543701171875,
            "b": 440.4892883300781,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            499
          ]
        }
      ],
      "orig": "Figure 2. Detailed network architecture and data flow of DrivingGPT. Front camera driving images are tokenized by VQ-VAE and driving actions are tokenized via component-wise binning. Image tokens and action tokens are interleaved to form a driving language. Standard LLM architecture and next token prediction training strategy are used. The predicted image tokens are grouped and decoded back to image via VQ-VAE decoder while the predicted action tokens are unbinned to get the driving trajectory.",
      "text": "Figure 2. Detailed network architecture and data flow of DrivingGPT. Front camera driving images are tokenized by VQ-VAE and driving actions are tokenized via component-wise binning. Image tokens and action tokens are interleaved to form a driving language. Standard LLM architecture and next token prediction training strategy are used. The predicted image tokens are grouped and decoded back to image via VQ-VAE decoder while the predicted action tokens are unbinned to get the driving trajectory."
    },
    {
      "self_ref": "#/texts/62",
      "parent": {
        "$ref": "#/pictures/1"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 82.13387298583984,
            "t": 582.4160766601562,
            "r": 141.85877990722656,
            "b": 576.50341796875,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            16
          ]
        }
      ],
      "orig": "Sequence Actions",
      "text": "Sequence Actions"
    },
    {
      "self_ref": "#/texts/63",
      "parent": {
        "$ref": "#/pictures/1"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 216.17726135253906,
            "t": 582.5042724609375,
            "r": 264.7261962890625,
            "b": 577.7200317382812,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            13
          ]
        }
      ],
      "orig": "Action Tokens",
      "text": "Action Tokens"
    },
    {
      "self_ref": "#/texts/64",
      "parent": {
        "$ref": "#/pictures/1"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 85.03239440917969,
            "t": 690.3910522460938,
            "r": 140.57183837890625,
            "b": 684.54150390625,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            15
          ]
        }
      ],
      "orig": "Sequence Images",
      "text": "Sequence Images"
    },
    {
      "self_ref": "#/texts/65",
      "parent": {
        "$ref": "#/pictures/1"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 182.97276306152344,
            "t": 623.5503540039062,
            "r": 204.9613800048828,
            "b": 618.2239990234375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            6
          ]
        }
      ],
      "orig": "VQ-VAE",
      "text": "VQ-VAE"
    },
    {
      "self_ref": "#/texts/66",
      "parent": {
        "$ref": "#/pictures/1"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 181.46022033691406,
            "t": 615.8617553710938,
            "r": 206.98277282714844,
            "b": 611.0775146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            7
          ]
        }
      ],
      "orig": "Encoder",
      "text": "Encoder"
    },
    {
      "self_ref": "#/texts/67",
      "parent": {
        "$ref": "#/pictures/1"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 216.52088928222656,
            "t": 690.5738525390625,
            "r": 264.40167236328125,
            "b": 684.54150390625,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            13
          ]
        }
      ],
      "orig": "Images Tokens",
      "text": "Images Tokens"
    },
    {
      "self_ref": "#/texts/68",
      "parent": {
        "$ref": "#/pictures/1"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 272.6265869140625,
            "t": 511.8955078125,
            "r": 316.8387756347656,
            "b": 505.8946533203125,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            12
          ]
        }
      ],
      "orig": "Input Tokens",
      "text": "Input Tokens"
    },
    {
      "self_ref": "#/texts/69",
      "parent": {
        "$ref": "#/pictures/1"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 327.6520690917969,
            "t": 629.611572265625,
            "r": 334.0736999511719,
            "b": 588.1635131835938,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            10
          ]
        }
      ],
      "orig": "DrivingGPT",
      "text": "DrivingGPT"
    },
    {
      "self_ref": "#/texts/70",
      "parent": {
        "$ref": "#/pictures/1"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 307.8773498535156,
            "t": 630.9398803710938,
            "r": 318.63372802734375,
            "b": 625.613525390625,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "QKV",
      "text": "QKV"
    },
    {
      "self_ref": "#/texts/71",
      "parent": {
        "$ref": "#/pictures/1"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 444.1080322265625,
            "t": 565.3086547851562,
            "r": 541.0420532226562,
            "b": 559.3078002929688,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            26
          ]
        }
      ],
      "orig": "Generated Sequence Actions",
      "text": "Generated Sequence Actions"
    },
    {
      "self_ref": "#/texts/72",
      "parent": {
        "$ref": "#/pictures/1"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 404.1337890625,
            "t": 675.7587280273438,
            "r": 426.12939453125,
            "b": 670.432373046875,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            6
          ]
        }
      ],
      "orig": "VQ-VAE",
      "text": "VQ-VAE"
    },
    {
      "self_ref": "#/texts/73",
      "parent": {
        "$ref": "#/pictures/1"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 402.5519104003906,
            "t": 668.0701293945312,
            "r": 428.143798828125,
            "b": 663.285888671875,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            7
          ]
        }
      ],
      "orig": "Decoder",
      "text": "Decoder"
    },
    {
      "self_ref": "#/texts/74",
      "parent": {
        "$ref": "#/pictures/1"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 446.85296630859375,
            "t": 684.972412109375,
            "r": 540.118408203125,
            "b": 678.9400634765625,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            25
          ]
        }
      ],
      "orig": "Generated Sequence Images",
      "text": "Generated Sequence Images"
    },
    {
      "self_ref": "#/texts/75",
      "parent": {
        "$ref": "#/pictures/1"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 339.1831359863281,
            "t": 512.2272338867188,
            "r": 379.9410705566406,
            "b": 507.4429626464844,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            11
          ]
        }
      ],
      "orig": "Next Tokens",
      "text": "Next Tokens"
    },
    {
      "self_ref": "#/texts/76",
      "parent": {
        "$ref": "#/pictures/1"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 158.91317749023438,
            "t": 544.560546875,
            "r": 163.5593719482422,
            "b": 543.3950805664062,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            1
          ]
        }
      ],
      "orig": "\u2026",
      "text": "\u2026"
    },
    {
      "self_ref": "#/texts/77",
      "parent": {
        "$ref": "#/pictures/1"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 160.70816040039062,
            "t": 643.91357421875,
            "r": 165.35435485839844,
            "b": 642.7481079101562,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            1
          ]
        }
      ],
      "orig": "\u2026",
      "text": "\u2026"
    },
    {
      "self_ref": "#/texts/78",
      "parent": {
        "$ref": "#/pictures/1"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 239.7617645263672,
            "t": 612.9597778320312,
            "r": 240.92466735839844,
            "b": 608.3239135742188,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            1
          ]
        }
      ],
      "orig": "\u2026",
      "text": "\u2026"
    },
    {
      "self_ref": "#/texts/79",
      "parent": {
        "$ref": "#/pictures/1"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 240.69769287109375,
            "t": 530.732421875,
            "r": 241.860595703125,
            "b": 526.0965576171875,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            1
          ]
        }
      ],
      "orig": "\u2026",
      "text": "\u2026"
    },
    {
      "self_ref": "#/texts/80",
      "parent": {
        "$ref": "#/pictures/1"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 294.2750244140625,
            "t": 537.681884765625,
            "r": 295.43792724609375,
            "b": 533.0460205078125,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            1
          ]
        }
      ],
      "orig": "\u2026",
      "text": "\u2026"
    },
    {
      "self_ref": "#/texts/81",
      "parent": {
        "$ref": "#/pictures/1"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 495.5095520019531,
            "t": 610.5990600585938,
            "r": 496.6724548339844,
            "b": 605.9631958007812,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            1
          ]
        }
      ],
      "orig": "\u2026",
      "text": "\u2026"
    },
    {
      "self_ref": "#/texts/82",
      "parent": {
        "$ref": "#/pictures/1"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 358.0076904296875,
            "t": 530.9943237304688,
            "r": 359.17059326171875,
            "b": 526.3584594726562,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            1
          ]
        }
      ],
      "orig": "\u2026",
      "text": "\u2026"
    },
    {
      "self_ref": "#/texts/83",
      "parent": {
        "$ref": "#/pictures/1"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 495.5095520019531,
            "t": 529.0037841796875,
            "r": 496.6724548339844,
            "b": 524.367919921875,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            1
          ]
        }
      ],
      "orig": "\u2026",
      "text": "\u2026"
    },
    {
      "self_ref": "#/texts/84",
      "parent": {
        "$ref": "#/pictures/1"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 405.25897216796875,
            "t": 553.9232177734375,
            "r": 427.5100402832031,
            "b": 549.2271728515625,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            6
          ]
        }
      ],
      "orig": "Action",
      "text": "Action"
    },
    {
      "self_ref": "#/texts/85",
      "parent": {
        "$ref": "#/pictures/1"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 399.9181213378906,
            "t": 546.1190185546875,
            "r": 432.8724060058594,
            "b": 540.086669921875,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            9
          ]
        }
      ],
      "orig": "Unbinning",
      "text": "Unbinning"
    },
    {
      "self_ref": "#/texts/86",
      "parent": {
        "$ref": "#/pictures/1"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 184.2026824951172,
            "t": 555.28515625,
            "r": 206.38442993164062,
            "b": 550.589111328125,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            6
          ]
        }
      ],
      "orig": "Action",
      "text": "Action"
    },
    {
      "self_ref": "#/texts/87",
      "parent": {
        "$ref": "#/pictures/1"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 182.62574768066406,
            "t": 547.4102172851562,
            "r": 208.12939453125,
            "b": 541.466064453125,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            7
          ]
        }
      ],
      "orig": "Binning",
      "text": "Binning"
    },
    {
      "self_ref": "#/texts/88",
      "parent": {
        "$ref": "#/pictures/1"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 94.61797332763672,
            "t": 679.3927001953125,
            "r": 111.61851501464844,
            "b": 673.8140258789062,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            6
          ]
        }
      ],
      "orig": "\ud835\udc90\ud835\udc95 \u2208 \ud835\udc79",
      "text": "\ud835\udc90\ud835\udc95 \u2208 \ud835\udc79"
    },
    {
      "self_ref": "#/texts/89",
      "parent": {
        "$ref": "#/pictures/1"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 112.23824310302734,
            "t": 680.6876831054688,
            "r": 129.4876251220703,
            "b": 677.4179077148438,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            5
          ]
        }
      ],
      "orig": "\ud835\udfd1\u00d7\ud835\udc6f\u00d7\ud835\udc7e",
      "text": "\ud835\udfd1\u00d7\ud835\udc6f\u00d7\ud835\udc7e"
    },
    {
      "self_ref": "#/texts/90",
      "parent": {
        "$ref": "#/pictures/1"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 224.97897338867188,
            "t": 676.7734985351562,
            "r": 242.3687286376953,
            "b": 671.1809692382812,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            6
          ]
        }
      ],
      "orig": "\ud835\udc9b\ud835\udc95 \u2208 \ud835\udc75",
      "text": "\ud835\udc9b\ud835\udc95 \u2208 \ud835\udc75"
    },
    {
      "self_ref": "#/texts/91",
      "parent": {
        "$ref": "#/pictures/1"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 242.68490600585938,
            "t": 678.1535034179688,
            "r": 255.5667724609375,
            "b": 673.8256225585938,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            6
          ]
        }
      ],
      "orig": "\ud835\udc6f\ud835\udc7e/\ud835\udc7e/\ud835\udc7a",
      "text": "\ud835\udc6f\ud835\udc7e/\ud835\udc7e/\ud835\udc7a"
    },
    {
      "self_ref": "#/texts/92",
      "parent": {
        "$ref": "#/pictures/1"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 255.78514099121094,
            "t": 679.0281982421875,
            "r": 257.4725341796875,
            "b": 676.5081787109375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            1
          ]
        }
      ],
      "orig": "\ud835\udfd0",
      "text": "\ud835\udfd0"
    },
    {
      "self_ref": "#/texts/93",
      "parent": {
        "$ref": "#/pictures/1"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 92.78311920166016,
            "t": 572.147216796875,
            "r": 118.47681427001953,
            "b": 566.5545654296875,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            9
          ]
        }
      ],
      "orig": "\ud835\udc82\ud835\udc95 \u2261 \ud835\udc7b\ud835\udc95+\ud835\udfcf",
      "text": "\ud835\udc82\ud835\udc95 \u2261 \ud835\udc7b\ud835\udc95+\ud835\udfcf"
    },
    {
      "self_ref": "#/texts/94",
      "parent": {
        "$ref": "#/pictures/1"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 118.95306396484375,
            "t": 569.4978637695312,
            "r": 124.4459228515625,
            "b": 566.5545654296875,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            2
          ]
        }
      ],
      "orig": "\u2192\ud835\udc95",
      "text": "\u2192\ud835\udc95"
    },
    {
      "self_ref": "#/texts/95",
      "parent": {
        "$ref": "#/pictures/1"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 75.7998046875,
            "t": 564.5069580078125,
            "r": 87.20160675048828,
            "b": 558.6006469726562,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            4
          ]
        }
      ],
      "orig": "(\u2206\ud835\udc99\ud835\udc95",
      "text": "(\u2206\ud835\udc99\ud835\udc95"
    },
    {
      "self_ref": "#/texts/96",
      "parent": {
        "$ref": "#/pictures/1"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 87.59864044189453,
            "t": 561.9494018554688,
            "r": 100.26737976074219,
            "b": 558.6796264648438,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            5
          ]
        }
      ],
      "orig": "+\ud835\udfcf\u2192\ud835\udc95,",
      "text": "+\ud835\udfcf\u2192\ud835\udc95,"
    },
    {
      "self_ref": "#/texts/97",
      "parent": {
        "$ref": "#/pictures/1"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 101.7862548828125,
            "t": 564.2989501953125,
            "r": 116.90531921386719,
            "b": 558.651123046875,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            5
          ]
        }
      ],
      "orig": "\u2206\ud835\udc9a\ud835\udc95+\ud835\udfcf",
      "text": "\u2206\ud835\udc9a\ud835\udc95+\ud835\udfcf"
    },
    {
      "self_ref": "#/texts/98",
      "parent": {
        "$ref": "#/pictures/1"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 117.3641128540039,
            "t": 561.6229248046875,
            "r": 124.13656616210938,
            "b": 558.6796264648438,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "\u2192\ud835\udc95,",
      "text": "\u2192\ud835\udc95,"
    },
    {
      "self_ref": "#/texts/99",
      "parent": {
        "$ref": "#/pictures/1"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 125.65544891357422,
            "t": 564.3682861328125,
            "r": 132.8323211669922,
            "b": 559.9432983398438,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            2
          ]
        }
      ],
      "orig": "\u2206\ud835\udf3d",
      "text": "\u2206\ud835\udf3d"
    },
    {
      "self_ref": "#/texts/100",
      "parent": {
        "$ref": "#/pictures/1"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 133.46786499023438,
            "t": 561.9494018554688,
            "r": 146.8972625732422,
            "b": 558.6796264648438,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            5
          ]
        }
      ],
      "orig": "\ud835\udc95+\ud835\udfcf\u2192\ud835\udc95",
      "text": "\ud835\udc95+\ud835\udfcf\u2192\ud835\udc95"
    },
    {
      "self_ref": "#/texts/101",
      "parent": {
        "$ref": "#/pictures/1"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 147.30767822265625,
            "t": 564.5069580078125,
            "r": 149.24913024902344,
            "b": 558.6006469726562,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            1
          ]
        }
      ],
      "orig": ")",
      "text": ")"
    },
    {
      "self_ref": "#/texts/102",
      "parent": {
        "$ref": "#/pictures/1"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 230.6516876220703,
            "t": 571.8468627929688,
            "r": 248.4102325439453,
            "b": 566.2613525390625,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            6
          ]
        }
      ],
      "orig": "\ud835\udc92\ud835\udc95 \u2208 \ud835\udc75",
      "text": "\ud835\udc92\ud835\udc95 \u2208 \ud835\udc75"
    },
    {
      "self_ref": "#/texts/103",
      "parent": {
        "$ref": "#/pictures/1"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 248.90086364746094,
            "t": 573.1090087890625,
            "r": 251.0176544189453,
            "b": 569.851318359375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            1
          ]
        }
      ],
      "orig": "\ud835\udfd1",
      "text": "\ud835\udfd1"
    },
    {
      "self_ref": "#/texts/104",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 58.629451751708984,
            "t": 417.7030944824219,
            "r": 294.62347412109375,
            "b": 338.89947509765625,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            415
          ]
        }
      ],
      "orig": "99th percentile a \u00af t = min(max(at , a 1st ) , a 99th ), here a = {x, y, \u03b8} denotes different action components. We then obtain action tokens q t by dividing clamped action components uniformly into M bins q t = \u230a(a \u00af t - a 1st )/(a 99th - a 1st ) \u2217 (M - 1)\u230b. Since x , y , \u03b8 are of varying magnitude and units, we quantize these three action components with different vocabularies to minimize the information loss.",
      "text": "99th percentile a \u00af t = min(max(at , a 1st ) , a 99th ), here a = {x, y, \u03b8} denotes different action components. We then obtain action tokens q t by dividing clamped action components uniformly into M bins q t = \u230a(a \u00af t - a 1st )/(a 99th - a 1st ) \u2217 (M - 1)\u230b. Since x , y , \u03b8 are of varying magnitude and units, we quantize these three action components with different vocabularies to minimize the information loss."
    },
    {
      "self_ref": "#/texts/105",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 58.62939453125,
            "t": 295.9950866699219,
            "r": 294.77398681640625,
            "b": 212.02305603027344,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            376
          ]
        }
      ],
      "orig": "Unified Visual Action Sequence Modeling We construct a unified driving language given the tokenized driving sequences like z1 , q1, z2, q2, . . . , zT , qT where zt stands for images tokens {ztj} HW/S 2 j=1 and q t stands for action tokens {qtk} 3 k=1 , and then leverage an autoregressive transformer with causal attention masks for modeling driving as next token prediction.",
      "text": "Unified Visual Action Sequence Modeling We construct a unified driving language given the tokenized driving sequences like z1 , q1, z2, q2, . . . , zT , qT where zt stands for images tokens {ztj} HW/S 2 j=1 and q t stands for action tokens {qtk} 3 k=1 , and then leverage an autoregressive transformer with causal attention masks for modeling driving as next token prediction."
    },
    {
      "self_ref": "#/texts/106",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 58.529781341552734,
            "t": 204.9644317626953,
            "r": 295.2510986328125,
            "b": 78.51924896240234,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            617
          ]
        }
      ],
      "orig": "We treat the visual modality and the action modality as different foreign languages and use a unified vocabulary for driving. The visual modality has a vocabulary size of D which is the codebook size of the VQ-VAE. The action modality has a vocabulary size of 3M where the M is the bin size of each action component and 3 denotes different action components. So our multimodal driving language has a vocabulary size of D + 3M. We apply frame-wise 1D rotary embedding [48] for both the image and the action tokens. The autoregressive transformers p\u03b8 then learn to model the unified token sequence x \u2208 {z \u222aq} with stan-",
      "text": "We treat the visual modality and the action modality as different foreign languages and use a unified vocabulary for driving. The visual modality has a vocabulary size of D which is the codebook size of the VQ-VAE. The action modality has a vocabulary size of 3M where the M is the bin size of each action component and 3 denotes different action components. So our multimodal driving language has a vocabulary size of D + 3M. We apply frame-wise 1D rotary embedding [48] for both the image and the action tokens. The autoregressive transformers p\u03b8 then learn to model the unified token sequence x \u2208 {z \u222aq} with stan-"
    },
    {
      "self_ref": "#/texts/107",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 317.5188903808594,
            "t": 416.12939453125,
            "r": 408.3280029296875,
            "b": 407.1630554199219,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            18
          ]
        }
      ],
      "orig": "cross entropy loss",
      "text": "cross entropy loss"
    },
    {
      "self_ref": "#/texts/108",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "formula",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 389.17779541015625,
            "t": 398.7199401855469,
            "r": 553.0220947265625,
            "b": 377.73516845703125,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            27
          ]
        }
      ],
      "orig": "X t - log(p\u03b8(xt|x<t)) . (1)",
      "text": "X t - log(p\u03b8(xt|x<t)) . (1)"
    },
    {
      "self_ref": "#/texts/109",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 316.9410705566406,
            "t": 369.3603820800781,
            "r": 553.4132690429688,
            "b": 324.4488830566406,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            200
          ]
        }
      ],
      "orig": "Although the driving language model looks simple in its form, it explicitly incorporate both the driving world modeling p\u03b8(zt|z<t , q<t) and the end-to-end driving p\u03b8(q t |z\u2264t , q<t) as its sub-tasks.",
      "text": "Although the driving language model looks simple in its form, it explicitly incorporate both the driving world modeling p\u03b8(zt|z<t , q<t) and the end-to-end driving p\u03b8(q t |z\u2264t , q<t) as its sub-tasks."
    },
    {
      "self_ref": "#/texts/110",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 317.29962158203125,
            "t": 308.6360778808594,
            "r": 553.3035888671875,
            "b": 243.08224487304688,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            300
          ]
        }
      ],
      "orig": "Integrating Action into Trajectory Since we use the frame-to-frame relative actions in our driving language, we need to integrating them back to get the absolute driving trajectories. We perform the integration by first covert the predicted action {qtk} = (xt, yt, \u03b8t) into a 2D transformation matrix",
      "text": "Integrating Action into Trajectory Since we use the frame-to-frame relative actions in our driving language, we need to integrating them back to get the absolute driving trajectories. We perform the integration by first covert the predicted action {qtk} = (xt, yt, \u03b8t) into a 2D transformation matrix"
    },
    {
      "self_ref": "#/texts/111",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "formula",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 363.0339050292969,
            "t": 235.59542846679688,
            "r": 553.02197265625,
            "b": 199.75962829589844,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            70
          ]
        }
      ],
      "orig": "Tt Tt+1\u2192t = \uf8ee \uf8f0 cos \u03b8 t - sin \u03b8 t xt sin \u03b8 t cos \u03b8t yt 0 0 1 \uf8f9 \uf8fb . (2)",
      "text": "Tt Tt+1\u2192t = \uf8ee \uf8f0 cos \u03b8 t - sin \u03b8 t xt sin \u03b8 t cos \u03b8t yt 0 0 1 \uf8f9 \uf8fb . (2)"
    },
    {
      "self_ref": "#/texts/112",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 317.2995910644531,
            "t": 192.2843475341797,
            "r": 553.3036499023438,
            "b": 148.17001342773438,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            178
          ]
        }
      ],
      "orig": "We then obtain the absolute pose TtTt+k-\u2192t = \u03a0 k i=1 Tt Tt+i-\u2192t+i - 1 by consecutive multiplying these relative pose matrices and convert it back to absolute actions accordingly.",
      "text": "We then obtain the absolute pose TtTt+k-\u2192t = \u03a0 k i=1 Tt Tt+i-\u2192t+i - 1 by consecutive multiplying these relative pose matrices and convert it back to absolute actions accordingly."
    },
    {
      "self_ref": "#/texts/113",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "section_header",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 317.4769287109375,
            "t": 136.3639373779297,
            "r": 393.954345703125,
            "b": 125.66403198242188,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            14
          ]
        }
      ],
      "orig": "4. Experiments",
      "text": "4. Experiments",
      "level": 1
    },
    {
      "self_ref": "#/texts/114",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "section_header",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 317.4580078125,
            "t": 116.98548889160156,
            "r": 446.00592041015625,
            "b": 107.1772689819336,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            27
          ]
        }
      ],
      "orig": "4.1. Implementation Details",
      "text": "4.1. Implementation Details",
      "level": 1
    },
    {
      "self_ref": "#/texts/115",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 317.5586242675781,
            "t": 99.60004425048828,
            "r": 553.3036499023438,
            "b": 78.8380126953125,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            107
          ]
        }
      ],
      "orig": "Training. Both nuPlan and NAVSIM record camera images of 900 pixels height and 1600 pixels width. We resize",
      "text": "Training. Both nuPlan and NAVSIM record camera images of 900 pixels height and 1600 pixels width. We resize"
    },
    {
      "self_ref": "#/texts/116",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "page_footer",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 303.6283264160156,
            "t": 57.84661102294922,
            "r": 308.2111511230469,
            "b": 51.11189270019531,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            1
          ]
        }
      ],
      "orig": "4",
      "text": "4"
    },
    {
      "self_ref": "#/texts/117",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "caption",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 58.60759735107422,
            "t": 421.4717712402344,
            "r": 553.5078735351562,
            "b": 391.8512878417969,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            412
          ]
        }
      ],
      "orig": "Figure 3. Comparison of long video generation. We showcase a 64-frame (32-second) sequence generated on the navtest dataset. (a) SVD fine-tuning methods often exhibit limitations in generating long videos, frequently repeating past content, such as indefinitely remaining at a red light. Conversely, (b) our DrivingGPT demonstrates superior performance in generating long, diverse, and visually appealing videos.",
      "text": "Figure 3. Comparison of long video generation. We showcase a 64-frame (32-second) sequence generated on the navtest dataset. (a) SVD fine-tuning methods often exhibit limitations in generating long videos, frequently repeating past content, such as indefinitely remaining at a red light. Conversely, (b) our DrivingGPT demonstrates superior performance in generating long, diverse, and visually appealing videos."
    },
    {
      "self_ref": "#/texts/118",
      "parent": {
        "$ref": "#/pictures/2"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 290.54840087890625,
            "t": 713.4738159179688,
            "r": 302.2682800292969,
            "b": 705.4595947265625,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            2
          ]
        }
      ],
      "orig": "+8",
      "text": "+8"
    },
    {
      "self_ref": "#/texts/119",
      "parent": {
        "$ref": "#/pictures/2"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 158.5354766845703,
            "t": 643.199462890625,
            "r": 176.3948516845703,
            "b": 635.1961669921875,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "+16",
      "text": "+16"
    },
    {
      "self_ref": "#/texts/120",
      "parent": {
        "$ref": "#/pictures/2"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 283.69927978515625,
            "t": 642.9786376953125,
            "r": 301.69024658203125,
            "b": 635.095947265625,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "+24",
      "text": "+24"
    },
    {
      "self_ref": "#/texts/121",
      "parent": {
        "$ref": "#/pictures/2"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 161.5894012451172,
            "t": 575.25,
            "r": 179.28433227539062,
            "b": 567.2467041015625,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "+32",
      "text": "+32"
    },
    {
      "self_ref": "#/texts/122",
      "parent": {
        "$ref": "#/pictures/2"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 284.7384033203125,
            "t": 575.0291748046875,
            "r": 302.4443054199219,
            "b": 567.02587890625,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "+40",
      "text": "+40"
    },
    {
      "self_ref": "#/texts/123",
      "parent": {
        "$ref": "#/pictures/2"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 161.5894012451172,
            "t": 506.4510498046875,
            "r": 179.33914184570312,
            "b": 498.4367980957031,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "+48",
      "text": "+48"
    },
    {
      "self_ref": "#/texts/124",
      "parent": {
        "$ref": "#/pictures/2"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 284.1143493652344,
            "t": 506.4510498046875,
            "r": 301.9737548828125,
            "b": 498.44775390625,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "+56",
      "text": "+56"
    },
    {
      "self_ref": "#/texts/125",
      "parent": {
        "$ref": "#/pictures/3"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 532.9183349609375,
            "t": 712.6243896484375,
            "r": 544.6382446289062,
            "b": 704.6101684570312,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            2
          ]
        }
      ],
      "orig": "+8",
      "text": "+8"
    },
    {
      "self_ref": "#/texts/126",
      "parent": {
        "$ref": "#/pictures/3"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 412.2669982910156,
            "t": 643.0851440429688,
            "r": 430.12640380859375,
            "b": 635.0818481445312,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "+16",
      "text": "+16"
    },
    {
      "self_ref": "#/texts/127",
      "parent": {
        "$ref": "#/pictures/3"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 526.728271484375,
            "t": 643.800048828125,
            "r": 544.71923828125,
            "b": 635.9173583984375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "+24",
      "text": "+24"
    },
    {
      "self_ref": "#/texts/128",
      "parent": {
        "$ref": "#/pictures/3"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 410.8284606933594,
            "t": 575.00048828125,
            "r": 428.5234069824219,
            "b": 566.9971923828125,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "+32",
      "text": "+32"
    },
    {
      "self_ref": "#/texts/129",
      "parent": {
        "$ref": "#/pictures/3"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 527.53369140625,
            "t": 574.7796630859375,
            "r": 545.2396240234375,
            "b": 566.7763671875,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "+40",
      "text": "+40"
    },
    {
      "self_ref": "#/texts/130",
      "parent": {
        "$ref": "#/pictures/3"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 410.6470031738281,
            "t": 507.2850341796875,
            "r": 428.3967590332031,
            "b": 499.2707824707031,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "+48",
      "text": "+48"
    },
    {
      "self_ref": "#/texts/131",
      "parent": {
        "$ref": "#/pictures/3"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 526.728271484375,
            "t": 507.2850341796875,
            "r": 544.587646484375,
            "b": 499.28173828125,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "+56",
      "text": "+56"
    },
    {
      "self_ref": "#/texts/132",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 177.2340545654297,
            "t": 437.9512939453125,
            "r": 188.60879516601562,
            "b": 428.0940856933594,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "(a)",
      "text": "(a)"
    },
    {
      "self_ref": "#/texts/133",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 427.1152648925781,
            "t": 437.9512939453125,
            "r": 439.03271484375,
            "b": 428.0940856933594,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "(b)",
      "text": "(b)"
    },
    {
      "self_ref": "#/texts/134",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 58.52992630004883,
            "t": 367.491455078125,
            "r": 295.251220703125,
            "b": 114.52143859863281,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            1231
          ]
        }
      ],
      "orig": "the original image to 288\u00d7512 while keeping the aspect ratio. We the same model structure as LlamaGen [49] which features the same SwishGLU and FFN dimension design as the original Llama [53]. We use VQVAEs with spatial downsample rates of either 8 and 16 for tokenizing images, which lead to either 2304 or 576 image tokens for each front camera image. For nuPlan we use a clip horizon of 16 frames at 10Hz and for NAVSIM we use 12 frames including 4 history and 8 future frames at 2Hz by following the official evaluation protocol. We use an image vocabulary size of 16384 and an action vocabulary size of 128 per action component, so the total vocabulary for our driving language is 16768. We use the standard cross entropy loss for next token prediction. We use the AdamW optimizer with a learning rate of 10 - 4 , a weight decay of 5 \u00d7 10 - 2 and 0 . 9/0 . 95 for first/second order momentum. We clip the total norm of gradients to 1 . 0 and use a token-level dropout rate of 0 . 1 for regularization. We apply random horizon image flip as an augmentation before image tokenization and the way points and yaws in actions are flipped accordingly. Models are trained for 100k iterations by default with a total batch size of 16.",
      "text": "the original image to 288\u00d7512 while keeping the aspect ratio. We the same model structure as LlamaGen [49] which features the same SwishGLU and FFN dimension design as the original Llama [53]. We use VQVAEs with spatial downsample rates of either 8 and 16 for tokenizing images, which lead to either 2304 or 576 image tokens for each front camera image. For nuPlan we use a clip horizon of 16 frames at 10Hz and for NAVSIM we use 12 frames including 4 history and 8 future frames at 2Hz by following the official evaluation protocol. We use an image vocabulary size of 16384 and an action vocabulary size of 128 per action component, so the total vocabulary for our driving language is 16768. We use the standard cross entropy loss for next token prediction. We use the AdamW optimizer with a learning rate of 10 - 4 , a weight decay of 5 \u00d7 10 - 2 and 0 . 9/0 . 95 for first/second order momentum. We clip the total norm of gradients to 1 . 0 and use a token-level dropout rate of 0 . 1 for regularization. We apply random horizon image flip as an augmentation before image tokenization and the way points and yaws in actions are flipped accordingly. Models are trained for 100k iterations by default with a total batch size of 16."
    },
    {
      "self_ref": "#/texts/135",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 317.3795471191406,
            "t": 367.57110595703125,
            "r": 553.5230102539062,
            "b": 276.52301025390625,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            423
          ]
        }
      ],
      "orig": "Inference. We sample the image tokens with a temperature of 1 . 0 and a top-k of 2000. Since our driving language contains both image and action vocabularies, we adopt a guided sampling scheme by masking the logits of foreign vocabularies to avoid occasionally sampling tokens of other modalities when the temperature is high. For long video generation, we produce 16 frames at a time, conditioned on the previous 8 frames.",
      "text": "Inference. We sample the image tokens with a temperature of 1 . 0 and a top-k of 2000. Since our driving language contains both image and action vocabularies, we adopt a guided sampling scheme by masking the logits of foreign vocabularies to avoid occasionally sampling tokens of other modalities when the temperature is high. For long video generation, we produce 16 frames at a time, conditioned on the previous 8 frames."
    },
    {
      "self_ref": "#/texts/136",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "section_header",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 317.458251953125,
            "t": 264.6255187988281,
            "r": 434.7294616699219,
            "b": 256.91046142578125,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            25
          ]
        }
      ],
      "orig": "4.2. Datasets and Metrics",
      "text": "4.2. Datasets and Metrics",
      "level": 1
    },
    {
      "self_ref": "#/texts/137",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 317.2998352050781,
            "t": 246.515380859375,
            "r": 553.3038940429688,
            "b": 120.38900756835938,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            601
          ]
        }
      ],
      "orig": "nuPlan [7]. The dataset offers a diverse range of driving scenarios spanning 1282 hours across four cities: Singapore, Boston, Pittsburgh, and Las Vegas. Due to the large scale of the full sensor dataset, only a subset comprising 128 hours of data has been released. It supports both open-loop and closed-loop evaluation and provides rich sensor data, including LiDAR point clouds and images from 8 cameras. Similar to nuScenes [6], nuPlan provides detailed humanannotated 2D high-definition semantic maps of the driving locations. For our experiments, we focus solely on the front-view camera images.",
      "text": "nuPlan [7]. The dataset offers a diverse range of driving scenarios spanning 1282 hours across four cities: Singapore, Boston, Pittsburgh, and Las Vegas. Due to the large scale of the full sensor dataset, only a subset comprising 128 hours of data has been released. It supports both open-loop and closed-loop evaluation and provides rich sensor data, including LiDAR point clouds and images from 8 cameras. Similar to nuScenes [6], nuPlan provides detailed humanannotated 2D high-definition semantic maps of the driving locations. For our experiments, we focus solely on the front-view camera images."
    },
    {
      "self_ref": "#/texts/138",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 317.409423828125,
            "t": 99.6100082397461,
            "r": 553.5130615234375,
            "b": 78.8380126953125,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            110
          ]
        }
      ],
      "orig": "NAVSIM [15]. The NAVSIM dataset is constructed by resampling the original 10Hz data from nuPlan [7] to 2Hz. It",
      "text": "NAVSIM [15]. The NAVSIM dataset is constructed by resampling the original 10Hz data from nuPlan [7] to 2Hz. It"
    },
    {
      "self_ref": "#/texts/139",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "page_footer",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 303.8278503417969,
            "t": 57.967159271240234,
            "r": 307.8726501464844,
            "b": 50.98337936401367,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            1
          ]
        }
      ],
      "orig": "5",
      "text": "5"
    },
    {
      "self_ref": "#/texts/140",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "caption",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 65.09842681884766,
            "t": 639.0358276367188,
            "r": 546.439453125,
            "b": 630.8943481445312,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            131
          ]
        }
      ],
      "orig": "Table 1. Video generation comparison on the navtest . Our model, trained from scratch, surpasses previous methods in video quality.",
      "text": "Table 1. Video generation comparison on the navtest . Our model, trained from scratch, surpasses previous methods in video quality."
    },
    {
      "self_ref": "#/texts/141",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 58.659400939941406,
            "t": 606.5344848632812,
            "r": 294.3437194824219,
            "b": 552.6966552734375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            263
          ]
        }
      ],
      "orig": "is split into two sets: navtrain, containing 1,192 scenarios for training and validation, and navtest, comprising 136 scenarios for testing. It also support rapid testing on navmini , with 396 scenarios in total that are independent of both navtrain and navtest .",
      "text": "is split into two sets: navtrain, containing 1,192 scenarios for training and validation, and navtest, comprising 136 scenarios for testing. It also support rapid testing on navmini , with 396 scenarios in total that are independent of both navtrain and navtest ."
    },
    {
      "self_ref": "#/texts/142",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 58.65941619873047,
            "t": 532.0841674804688,
            "r": 294.7331848144531,
            "b": 405.8880615234375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            558
          ]
        }
      ],
      "orig": "Planning Metrics. We evaluate end-to-end planning performance on the NAVSIM benchmark [15] and report the PDMS. The Predictive Driver Model Score(PDMS) is a combination of five sub-metrics: No At-Fault Collision (NC), Drivable Area Compliance (DAC), Time-to-Collision (TTC), Comfort (Comf.), and Ego Progress (EP). They provide a comprehensive analysis of different aspects of driving performance. All metrics are computed after a 4-second non-reactive simulation of the planner output. We measure the performance of end-to-end planning on the navmini split.",
      "text": "Planning Metrics. We evaluate end-to-end planning performance on the NAVSIM benchmark [15] and report the PDMS. The Predictive Driver Model Score(PDMS) is a combination of five sub-metrics: No At-Fault Collision (NC), Drivable Area Compliance (DAC), Time-to-Collision (TTC), Comfort (Comf.), and Ego Progress (EP). They provide a comprehensive analysis of different aspects of driving performance. All metrics are computed after a 4-second non-reactive simulation of the planner output. We measure the performance of end-to-end planning on the navmini split."
    },
    {
      "self_ref": "#/texts/143",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 58.5498046875,
            "t": 387.25811767578125,
            "r": 294.5538330078125,
            "b": 333.38043212890625,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            230
          ]
        }
      ],
      "orig": "World Modeling Metrics. The quality of video generation is assessed using the Frechet Video Distance (FVD) [54] and the Frechet Inception Distance (FID) [25]. We select 512 videos in the navtest for fast visual quality evaluation.",
      "text": "World Modeling Metrics. The quality of video generation is assessed using the Frechet Video Distance (FVD) [54] and the Frechet Inception Distance (FID) [25]. We select 512 videos in the navtest for fast visual quality evaluation."
    },
    {
      "self_ref": "#/texts/144",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "section_header",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 58.70820236206055,
            "t": 320.6435546875,
            "r": 160.1876220703125,
            "b": 312.8736877441406,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            21
          ]
        }
      ],
      "orig": "4.3. Video Generation",
      "text": "4.3. Video Generation",
      "level": 1
    },
    {
      "self_ref": "#/texts/145",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 58.549781799316406,
            "t": 303.0071105957031,
            "r": 294.7729797363281,
            "b": 153.36903381347656,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            685
          ]
        }
      ],
      "orig": "Comparison of Generated Videos on navtest . We provide the quantitative comparison with several methods on the navtest in Table 1. As many video models only release model weights, we compare our method with their publicly available models. We found that both SVD [1] and CogvideoX [71] tend to generate subtle movements, which results in poor performance in driving scenarios. To ensure a fair comparison, we fine-tune the SVD model on the navtrain set. Previous video models typically rely on diffusion-based approaches, while our method is a pioneer in autoregressive video generation. Notably, our model, trained from scratch, surpasses previous methods in video generation quality.",
      "text": "Comparison of Generated Videos on navtest . We provide the quantitative comparison with several methods on the navtest in Table 1. As many video models only release model weights, we compare our method with their publicly available models. We found that both SVD [1] and CogvideoX [71] tend to generate subtle movements, which results in poor performance in driving scenarios. To ensure a fair comparison, we fine-tune the SVD model on the navtrain set. Previous video models typically rely on diffusion-based approaches, while our method is a pioneer in autoregressive video generation. Notably, our model, trained from scratch, surpasses previous methods in video generation quality."
    },
    {
      "self_ref": "#/texts/146",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 58.65937042236328,
            "t": 134.7490692138672,
            "r": 295.24725341796875,
            "b": 78.83901977539062,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            282
          ]
        }
      ],
      "orig": "Long Video Generation. One of the key advantages of autoregressive models is their ability to generate longduration videos by effectively leveraging historical information, resulting in more coherent video generation. In this experiment, we selected 512 video clips, each containing",
      "text": "Long Video Generation. One of the key advantages of autoregressive models is their ability to generate longduration videos by effectively leveraging historical information, resulting in more coherent video generation. In this experiment, we selected 512 video clips, each containing"
    },
    {
      "self_ref": "#/texts/147",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 317.27984619140625,
            "t": 606.5443115234375,
            "r": 553.4133911132812,
            "b": 492.13397216796875,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            538
          ]
        }
      ],
      "orig": "more than 64 frames, from the navtest dataset for evaluation. While the SVD method struggles to maintain quality when generating longer sequences, as evidenced in Table 2 , our method demonstrates a remarkable ability to produce high-quality long-term sequences. The fixed frame number training limitation of SVD leads to a significant drop in image and video quality for longer sequences. In contrast, our method consistently produces high-quality images and achieves a lower FVD score, indicating a more stable and superior performance.",
      "text": "more than 64 frames, from the navtest dataset for evaluation. While the SVD method struggles to maintain quality when generating longer sequences, as evidenced in Table 2 , our method demonstrates a remarkable ability to produce high-quality long-term sequences. The fixed frame number training limitation of SVD leads to a significant drop in image and video quality for longer sequences. In contrast, our method consistently produces high-quality images and achieves a lower FVD score, indicating a more stable and superior performance."
    },
    {
      "self_ref": "#/texts/148",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 317.2997741699219,
            "t": 488.6983337402344,
            "r": 553.52294921875,
            "b": 397.719970703125,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            459
          ]
        }
      ],
      "orig": "Moreover, compared to previous diffusion-based methods, our approach can generate more diverse and reasonable scenes. As shown in Figure 3, SVD fine-tuning methods often get stuck repeating past content when generating longer videos, such as being stuck at a red light for an extended period. In contrast, autoregressive methods exhibit significant advantages in generating long videos, leading to notable improvements in both scene content and video quality.",
      "text": "Moreover, compared to previous diffusion-based methods, our approach can generate more diverse and reasonable scenes. As shown in Figure 3, SVD fine-tuning methods often get stuck repeating past content when generating longer videos, such as being stuck at a red light for an extended period. In contrast, autoregressive methods exhibit significant advantages in generating long videos, leading to notable improvements in both scene content and video quality."
    },
    {
      "self_ref": "#/texts/149",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "caption",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 317.4024353027344,
            "t": 309.5977783203125,
            "r": 553.1359252929688,
            "b": 290.72528076171875,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            105
          ]
        }
      ],
      "orig": "Table 2. Long video generation comparison. The evaluation is conducted on the navtest set with 512 clips.",
      "text": "Table 2. Long video generation comparison. The evaluation is conducted on the navtest set with 512 clips."
    },
    {
      "self_ref": "#/texts/150",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 317.3695373535156,
            "t": 255.84716796875,
            "r": 554.001220703125,
            "b": 164.7891082763672,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            420
          ]
        }
      ],
      "orig": "Mitigating Object Hallucination. Beyond long video generation, another advantage of our method lies in its mitigation of object hallucination phenomena. As depicted in Figure 4, diffusion-based methods, due to their lack of historical information, often suffer from the sudden appearance (red box) and gradual disappearance (green box) of objects. In contrast, our autoregressive approach maintains superior consistency.",
      "text": "Mitigating Object Hallucination. Beyond long video generation, another advantage of our method lies in its mitigation of object hallucination phenomena. As depicted in Figure 4, diffusion-based methods, due to their lack of historical information, often suffer from the sudden appearance (red box) and gradual disappearance (green box) of objects. In contrast, our autoregressive approach maintains superior consistency."
    },
    {
      "self_ref": "#/texts/151",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "section_header",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 317.4582214355469,
            "t": 152.80958557128906,
            "r": 433.98419189453125,
            "b": 142.9904022216797,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            24
          ]
        }
      ],
      "orig": "4.4. End-to-end Planning",
      "text": "4.4. End-to-end Planning",
      "level": 1
    },
    {
      "self_ref": "#/texts/152",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 317.3695373535156,
            "t": 134.66844177246094,
            "r": 553.3037719726562,
            "b": 78.83808898925781,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            271
          ]
        }
      ],
      "orig": "Our DrivingGPT's ability to jointly predict future images and driving actions allows for end-to-end planning performance evaluation. To rigorously evaluate the performance of our planner, we choose the more challenging NAVSIM benchmark which is curated for providing more",
      "text": "Our DrivingGPT's ability to jointly predict future images and driving actions allows for end-to-end planning performance evaluation. To rigorously evaluate the performance of our planner, we choose the more challenging NAVSIM benchmark which is curated for providing more"
    },
    {
      "self_ref": "#/texts/153",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "page_footer",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 303.84771728515625,
            "t": 57.926387786865234,
            "r": 308.1715087890625,
            "b": 50.98245620727539,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            1
          ]
        }
      ],
      "orig": "6",
      "text": "6"
    },
    {
      "self_ref": "#/texts/154",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "caption",
      "prov": [
        {
          "page_no": 7,
          "bbox": {
            "l": 58.60759735107422,
            "t": 524.0968017578125,
            "r": 553.068603515625,
            "b": 494.4762878417969,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            335
          ]
        }
      ],
      "orig": "Figure 4. Object hallucination. Top: Diffusion-based methods often exhibit object hallucination phenomena. For instance, when comparing models fine-tuned with SVD, we observe the sudden appearance (red box) and gradual disappearance (green box) of objects. Bottom: In contrast, our autoregressive approach maintains better consistency.",
      "text": "Figure 4. Object hallucination. Top: Diffusion-based methods often exhibit object hallucination phenomena. For instance, when comparing models fine-tuned with SVD, we observe the sudden appearance (red box) and gradual disappearance (green box) of objects. Bottom: In contrast, our autoregressive approach maintains better consistency."
    },
    {
      "self_ref": "#/texts/155",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "caption",
      "prov": [
        {
          "page_no": 7,
          "bbox": {
            "l": 58.652427673339844,
            "t": 415.90972900390625,
            "r": 553.07080078125,
            "b": 397.020263671875,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            254
          ]
        }
      ],
      "orig": "Table 3. End-to-end planning performance on the NAVSIM benchmark. We show the no at-fault collision (NC), drivable area compliance (DAC), time-to-collision (TTC), comfort (Comf.), and ego progress (EP) subscores, and the PDM Score (PDMS), as percentages.",
      "text": "Table 3. End-to-end planning performance on the NAVSIM benchmark. We show the no at-fault collision (NC), drivable area compliance (DAC), time-to-collision (TTC), comfort (Comf.), and ego progress (EP) subscores, and the PDM Score (PDMS), as percentages."
    },
    {
      "self_ref": "#/texts/156",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 7,
          "bbox": {
            "l": 57.8126106262207,
            "t": 381.1644287109375,
            "r": 295.25128173828125,
            "b": 137.87803649902344,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            1152
          ]
        }
      ],
      "orig": "diverse driving maneuvers than previous nuScenes and nuPlan benchmarks. Furthermore, in light of recent discussion [37] of using ego status will provide too much privileged information for the planner, we deliberately choose to exclude it from our driving language. Following the NAVSIM setting [15], we condition on the past 2 seconds of observations and actions to predict 4-second future trajectories. As shown in Table 3, our DrivingGPT achieves a non-trivial performance when comparing with constant velocity and constant velocity constant yaw rate baselines. Besides, our DrivingGPT compare favorably against a simple yet solid end-to-end planner baseline implemented with a ResNet-50 visual encoder and a MLP trajectory decoder. The baseline only uses front camera image and make no use of ego status as well. The results highlights the potential for jointly learning world modeling and the planning given considering that our DrivingGPT could only learn representation by reconstructing highly compressed image tokens of the driving environment. We demonstrate trajectories generated under challenging driving scenes by DrivingGPT in Figure 5 .",
      "text": "diverse driving maneuvers than previous nuScenes and nuPlan benchmarks. Furthermore, in light of recent discussion [37] of using ego status will provide too much privileged information for the planner, we deliberately choose to exclude it from our driving language. Following the NAVSIM setting [15], we condition on the past 2 seconds of observations and actions to predict 4-second future trajectories. As shown in Table 3, our DrivingGPT achieves a non-trivial performance when comparing with constant velocity and constant velocity constant yaw rate baselines. Besides, our DrivingGPT compare favorably against a simple yet solid end-to-end planner baseline implemented with a ResNet-50 visual encoder and a MLP trajectory decoder. The baseline only uses front camera image and make no use of ego status as well. The results highlights the potential for jointly learning world modeling and the planning given considering that our DrivingGPT could only learn representation by reconstructing highly compressed image tokens of the driving environment. We demonstrate trajectories generated under challenging driving scenes by DrivingGPT in Figure 5 ."
    },
    {
      "self_ref": "#/texts/157",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "section_header",
      "prov": [
        {
          "page_no": 7,
          "bbox": {
            "l": 58.708248138427734,
            "t": 128.71347045898438,
            "r": 148.40684509277344,
            "b": 118.89429473876953,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            19
          ]
        }
      ],
      "orig": "4.5. Ablation Study",
      "text": "4.5. Ablation Study",
      "level": 1
    },
    {
      "self_ref": "#/texts/158",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 7,
          "bbox": {
            "l": 58.5299186706543,
            "t": 111.31607055664062,
            "r": 294.7730407714844,
            "b": 78.83802795410156,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            167
          ]
        }
      ],
      "orig": "Comparison of Different Visual Tokenizers. The quality of the visual tokenizer significantly impacts the upper bound of the world model's visual prediction quality. As",
      "text": "Comparison of Different Visual Tokenizers. The quality of the visual tokenizer significantly impacts the upper bound of the world model's visual prediction quality. As"
    },
    {
      "self_ref": "#/texts/159",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "caption",
      "prov": [
        {
          "page_no": 7,
          "bbox": {
            "l": 317.4024353027344,
            "t": 318.978759765625,
            "r": 553.9519653320312,
            "b": 280.4743347167969,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            205
          ]
        }
      ],
      "orig": "Table 4. Comparison of different visual tokenizers. The evaluations are conducted on the navtest dataset with an image size of 512\u00d7288, and a spatial downsampling rate of 16 is applied across all encoders.",
      "text": "Table 4. Comparison of different visual tokenizers. The evaluations are conducted on the navtest dataset with an image size of 512\u00d7288, and a spatial downsampling rate of 16 is applied across all encoders."
    },
    {
      "self_ref": "#/texts/160",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 7,
          "bbox": {
            "l": 317.3795166015625,
            "t": 253.04345703125,
            "r": 553.5230102539062,
            "b": 199.24546813964844,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            260
          ]
        }
      ],
      "orig": "shown in Table 4, we evaluate several state-of-the-art discrete visual tokenizers on the navtest (NAVSIM test set), a dataset comprising 12,146 video samples. Based on our evaluation, we select LlameGen [49] as the optimal visual tokenizer for our world model.",
      "text": "shown in Table 4, we evaluate several state-of-the-art discrete visual tokenizers on the navtest (NAVSIM test set), a dataset comprising 12,146 video samples. Based on our evaluation, we select LlameGen [49] as the optimal visual tokenizer for our world model."
    },
    {
      "self_ref": "#/texts/161",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "section_header",
      "prov": [
        {
          "page_no": 7,
          "bbox": {
            "l": 317.38946533203125,
            "t": 181.62210083007812,
            "r": 552.955078125,
            "b": 172.68565368652344,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            49
          ]
        }
      ],
      "orig": "Does DrivingGPT Learn or Copy Planning Solutions?",
      "text": "Does DrivingGPT Learn or Copy Planning Solutions?",
      "level": 1
    },
    {
      "self_ref": "#/texts/162",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 7,
          "bbox": {
            "l": 317.2798767089844,
            "t": 169.81643676757812,
            "r": 553.5130615234375,
            "b": 78.83807373046875,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            464
          ]
        }
      ],
      "orig": "Autoregressive transformers are well-known as powerful fitting machines. In this section, we tries to answer the question that does DrivingGPT truly learn to drive or just cut corners by copying or extrapolating history driving maneuvers. We gradually replace the predicted actions(pred.) by DrivingGPT with future actions estimated solely from history actions. We simply copy the last history action as general driving trajectories do not involve any action input",
      "text": "Autoregressive transformers are well-known as powerful fitting machines. In this section, we tries to answer the question that does DrivingGPT truly learn to drive or just cut corners by copying or extrapolating history driving maneuvers. We gradually replace the predicted actions(pred.) by DrivingGPT with future actions estimated solely from history actions. We simply copy the last history action as general driving trajectories do not involve any action input"
    },
    {
      "self_ref": "#/texts/163",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "page_footer",
      "prov": [
        {
          "page_no": 7,
          "bbox": {
            "l": 303.708251953125,
            "t": 57.70719528198242,
            "r": 307.9822082519531,
            "b": 51.04221725463867,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            1
          ]
        }
      ],
      "orig": "7",
      "text": "7"
    },
    {
      "self_ref": "#/texts/164",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 8,
          "bbox": {
            "l": 79.44156646728516,
            "t": 597.16357421875,
            "r": 156.62400817871094,
            "b": 589.9984130859375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            25
          ]
        }
      ],
      "orig": "(a) Unprotected left turn",
      "text": "(a) Unprotected left turn"
    },
    {
      "self_ref": "#/texts/165",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 8,
          "bbox": {
            "l": 205.4585723876953,
            "t": 597.16357421875,
            "r": 281.4056396484375,
            "b": 589.990478515625,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            24
          ]
        }
      ],
      "orig": "(b) Large curvature turn",
      "text": "(b) Large curvature turn"
    },
    {
      "self_ref": "#/texts/166",
      "parent": {
        "$ref": "#/pictures/7"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 8,
          "bbox": {
            "l": 332.3995666503906,
            "t": 597.16357421875,
            "r": 405.126708984375,
            "b": 589.990478515625,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            24
          ]
        }
      ],
      "orig": "(c) Merging into traffic",
      "text": "(c) Merging into traffic"
    },
    {
      "self_ref": "#/texts/167",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "caption",
      "prov": [
        {
          "page_no": 8,
          "bbox": {
            "l": 58.60759735107422,
            "t": 577.6527709960938,
            "r": 553.3196411132812,
            "b": 548.0313110351562,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            310
          ]
        }
      ],
      "orig": "Figure 5. DrivingGPT planning results in complex driving scenes: (a) Unprotected left turn; (b) Large curvature turn; (c) Merging into traffic; (d) Take better path than human. The red rectangle denotes the ego car, the blue line is the generated trajectory, and the brown line is the human driving trajectory.",
      "text": "Figure 5. DrivingGPT planning results in complex driving scenes: (a) Unprotected left turn; (b) Large curvature turn; (c) Merging into traffic; (d) Take better path than human. The red rectangle denotes the ego car, the blue line is the generated trajectory, and the brown line is the human driving trajectory."
    },
    {
      "self_ref": "#/texts/168",
      "parent": {
        "$ref": "#/pictures/8"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 8,
          "bbox": {
            "l": 463.3025817871094,
            "t": 597.16357421875,
            "r": 525.1744384765625,
            "b": 589.9984130859375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            20
          ]
        }
      ],
      "orig": "(d) Take better path",
      "text": "(d) Take better path"
    },
    {
      "self_ref": "#/texts/169",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "caption",
      "prov": [
        {
          "page_no": 8,
          "bbox": {
            "l": 58.652427673339844,
            "t": 458.7177734375,
            "r": 553.363037109375,
            "b": 418.3572998046875,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            521
          ]
        }
      ],
      "orig": "Table 5. Comparison of planning performance when replacing predicted actions with copied history actions for different action components. Here x , y , \u03b8 denotes the longitudinal, lateral and yaw components respectively. Pred stands for using DrivingGPTprediction and copy stands for using the action value of the last history frame. We show the no at-fault collision (NC), drivable area compliance (DAC), time-to-collision (TTC), comfort (Comf.), and ego progress (EP) subscores, and the PDM Score (PDMS), as percentages.",
      "text": "Table 5. Comparison of planning performance when replacing predicted actions with copied history actions for different action components. Here x , y , \u03b8 denotes the longitudinal, lateral and yaw components respectively. Pred stands for using DrivingGPTprediction and copy stands for using the action value of the last history frame. We show the no at-fault collision (NC), drivable area compliance (DAC), time-to-collision (TTC), comfort (Comf.), and ego progress (EP) subscores, and the PDM Score (PDMS), as percentages."
    },
    {
      "self_ref": "#/texts/170",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "caption",
      "prov": [
        {
          "page_no": 8,
          "bbox": {
            "l": 58.61656188964844,
            "t": 342.5517578125,
            "r": 294.3414611816406,
            "b": 312.9312744140625,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            181
          ]
        }
      ],
      "orig": "Table 6. Effect of training data curation on planning performance. The results suggest that data quality plays a more important role than data quantity in driving language modeling.",
      "text": "Table 6. Effect of training data curation on planning performance. The results suggest that data quality plays a more important role than data quantity in driving language modeling."
    },
    {
      "self_ref": "#/texts/171",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 8,
          "bbox": {
            "l": 58.659385681152344,
            "t": 287.5582580566406,
            "r": 294.77301025390625,
            "b": 184.81407165527344,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            481
          ]
        }
      ],
      "orig": "change. As shown in Table 5, our DrivingGPT consistently outperform all the variants that simply copy any x , y and \u03b8 history actions. One may notice that copying the previous longitudinal action x gives the worst planning results which is due to that the NAVSIM benchmark contains a lot of scenes where the ego vehicle is just start to accelerate from a stop and go. Experiment results suggest that our DrivingGPT truly learns how to drive instead of just copying history actions.",
      "text": "change. As shown in Table 5, our DrivingGPT consistently outperform all the variants that simply copy any x , y and \u03b8 history actions. One may notice that copying the previous longitudinal action x gives the worst planning results which is due to that the NAVSIM benchmark contains a lot of scenes where the ego vehicle is just start to accelerate from a stop and go. Experiment results suggest that our DrivingGPT truly learns how to drive instead of just copying history actions."
    },
    {
      "self_ref": "#/texts/172",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 8,
          "bbox": {
            "l": 58.62949752807617,
            "t": 181.6121063232422,
            "r": 294.7630920410156,
            "b": 78.83804321289062,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            519
          ]
        }
      ],
      "orig": "Training Data Curation for Planning. Data quality plays the central role when training autoregressive transformers on other tasks like language modeling. So in this section, we study the influence of driving data quality and quantity on the performance of end-to-end planning. As shown in Table 6, models trained on high quality data like NAVSIM with only 100k driving sequences outperform those trained on 650k nuPlan driving sequences. The results suggest that data quality plays a more important role than data quan-",
      "text": "Training Data Curation for Planning. Data quality plays the central role when training autoregressive transformers on other tasks like language modeling. So in this section, we study the influence of driving data quality and quantity on the performance of end-to-end planning. As shown in Table 6, models trained on high quality data like NAVSIM with only 100k driving sequences outperform those trained on 650k nuPlan driving sequences. The results suggest that data quality plays a more important role than data quan-"
    },
    {
      "self_ref": "#/texts/173",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 8,
          "bbox": {
            "l": 317.2798767089844,
            "t": 393.99737548828125,
            "r": 553.5130615234375,
            "b": 349.8830261230469,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            190
          ]
        }
      ],
      "orig": "tity in driving language modeling. We hypothesize this is because general driving contains too many trajectories that involve minimum action change and thus provides little information gain.",
      "text": "tity in driving language modeling. We hypothesize this is because general driving contains too many trajectories that involve minimum action change and thus provides little information gain."
    },
    {
      "self_ref": "#/texts/174",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "caption",
      "prov": [
        {
          "page_no": 8,
          "bbox": {
            "l": 317.4093933105469,
            "t": 346.5290832519531,
            "r": 552.6251831054688,
            "b": 337.60260009765625,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            50
          ]
        }
      ],
      "orig": "Position Embedding for Actions. Unlike GAIA-1 [27]",
      "text": "Position Embedding for Actions. Unlike GAIA-1 [27]"
    },
    {
      "self_ref": "#/texts/175",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "caption",
      "prov": [
        {
          "page_no": 8,
          "bbox": {
            "l": 317.4024353027344,
            "t": 269.68975830078125,
            "r": 553.0863037109375,
            "b": 250.9168701171875,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            102
          ]
        }
      ],
      "orig": "Table 7. Effect of apply position embedding to tokens of different modalities on planning performance.",
      "text": "Table 7. Effect of apply position embedding to tokens of different modalities on planning performance."
    },
    {
      "self_ref": "#/texts/176",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 8,
          "bbox": {
            "l": 317.4093933105469,
            "t": 233.32545471191406,
            "r": 553.52294921875,
            "b": 177.49510192871094,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            281
          ]
        }
      ],
      "orig": "and similar methods that use zero position embedding for actions in autoregressive transformers for video generation, we discovered that applying 1D rotary embeddings to both image and action tokens is crucial for achieving strong planning performance, as demonstrated in Table 7 .",
      "text": "and similar methods that use zero position embedding for actions in autoregressive transformers for video generation, we discovered that applying 1D rotary embeddings to both image and action tokens is crucial for achieving strong planning performance, as demonstrated in Table 7 ."
    },
    {
      "self_ref": "#/texts/177",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "section_header",
      "prov": [
        {
          "page_no": 8,
          "bbox": {
            "l": 317.51300048828125,
            "t": 162.23402404785156,
            "r": 386.1358642578125,
            "b": 153.75778198242188,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            13
          ]
        }
      ],
      "orig": "5. Conclusion",
      "text": "5. Conclusion",
      "level": 1
    },
    {
      "self_ref": "#/texts/178",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 8,
          "bbox": {
            "l": 317.3795166015625,
            "t": 146.38442993164062,
            "r": 553.4134521484375,
            "b": 78.83807373046875,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            340
          ]
        }
      ],
      "orig": "In this work, we propose a novel multi-modal driving language that effectively unifies the visual world modeling and trajectory planning into a sequence modeling task. We design a DrivingGPT that could jointly learn to generate image and action tokens for both tasks. Experiments and ablation studies on large-scale nuPlan and NAVSIM bench-",
      "text": "In this work, we propose a novel multi-modal driving language that effectively unifies the visual world modeling and trajectory planning into a sequence modeling task. We design a DrivingGPT that could jointly learn to generate image and action tokens for both tasks. Experiments and ablation studies on large-scale nuPlan and NAVSIM bench-"
    },
    {
      "self_ref": "#/texts/179",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "page_footer",
      "prov": [
        {
          "page_no": 8,
          "bbox": {
            "l": 304.06689453125,
            "t": 57.84667205810547,
            "r": 307.9423522949219,
            "b": 50.98244094848633,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            1
          ]
        }
      ],
      "orig": "8",
      "text": "8"
    },
    {
      "self_ref": "#/texts/180",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 9,
          "bbox": {
            "l": 58.589664459228516,
            "t": 716.8414306640625,
            "r": 295.2512512207031,
            "b": 649.2951049804688,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            329
          ]
        }
      ],
      "orig": "marks demonstrates the effectiveness of the proposed DrivingGPT on action-conditioned video generation and endto-end planning. DrivingGPT clearly shows the viability of unified learning of world modeling and planning with a single model, setting a stepping stone for the future exploration of differentiable model-based planning.",
      "text": "marks demonstrates the effectiveness of the proposed DrivingGPT on action-conditioned video generation and endto-end planning. DrivingGPT clearly shows the viability of unified learning of world modeling and planning with a single model, setting a stepping stone for the future exploration of differentiable model-based planning."
    },
    {
      "self_ref": "#/texts/181",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "page_footer",
      "prov": [
        {
          "page_no": 9,
          "bbox": {
            "l": 303.8078918457031,
            "t": 57.846717834472656,
            "r": 308.08184814453125,
            "b": 50.90278625488281,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            1
          ]
        }
      ],
      "orig": "9",
      "text": "9"
    },
    {
      "self_ref": "#/texts/182",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "section_header",
      "prov": [
        {
          "page_no": 10,
          "bbox": {
            "l": 58.81083679199219,
            "t": 718.2980346679688,
            "r": 113.70911407470703,
            "b": 709.881591796875,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            10
          ]
        }
      ],
      "orig": "References",
      "text": "References",
      "level": 1
    },
    {
      "self_ref": "#/texts/183",
      "parent": {
        "$ref": "#/groups/2"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 10,
          "bbox": {
            "l": 63.77204513549805,
            "t": 698.447998046875,
            "r": 294.572021484375,
            "b": 647.5358276367188,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            290
          ]
        }
      ],
      "orig": "[1] Andreas Blattmann, Tim Dockhorn, Sumith Kulal, Daniel Mendelevitch, Maciej Kilian, Dominik Lorenz, Yam Levi, Zion English, Vikram Voleti, Adam Letts, et al. Stable video diffusion: Scaling latent video diffusion models to large datasets. arXiv preprint arXiv:2311.15127, 2023. 1 , 2 , 6",
      "text": "[1] Andreas Blattmann, Tim Dockhorn, Sumith Kulal, Daniel Mendelevitch, Maciej Kilian, Dominik Lorenz, Yam Levi, Zion English, Vikram Voleti, Adam Letts, et al. Stable video diffusion: Scaling latent video diffusion models to large datasets. arXiv preprint arXiv:2311.15127, 2023. 1 , 2 , 6",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/184",
      "parent": {
        "$ref": "#/groups/2"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 10,
          "bbox": {
            "l": 63.77204513549805,
            "t": 642.8729858398438,
            "r": 294.91058349609375,
            "b": 592.53466796875,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            255
          ]
        }
      ],
      "orig": "[2] Mariusz Bojarski, Davide Del Testa, Daniel Dworakowski, Bernhard Firner, Beat Flepp, Prasoon Goyal, Lawrence D Jackel, Mathew Monfort, Urs Muller, Jiakai Zhang, et al. End to end learning for self-driving cars. arXiv preprint arXiv:1604.07316, 2016. 3",
      "text": "[2] Mariusz Bojarski, Davide Del Testa, Daniel Dworakowski, Bernhard Firner, Beat Flepp, Prasoon Goyal, Lawrence D Jackel, Mathew Monfort, Urs Muller, Jiakai Zhang, et al. End to end learning for self-driving cars. arXiv preprint arXiv:1604.07316, 2016. 3",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/185",
      "parent": {
        "$ref": "#/groups/2"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 10,
          "bbox": {
            "l": 63.77204513549805,
            "t": 587.2979736328125,
            "r": 294.61199951171875,
            "b": 536.3858032226562,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            269
          ]
        }
      ],
      "orig": "[3] Anthony Brohan, Noah Brown, Justice Carbajal, Yevgen Chebotar, Joseph Dabis, Chelsea Finn, Keerthana Gopalakrishnan, Karol Hausman, Alex Herzog, Jasmine Hsu, et al. Rt-1: Robotics transformer for real-world control at scale. arXiv preprint arXiv:2212.06817, 2022. 2",
      "text": "[3] Anthony Brohan, Noah Brown, Justice Carbajal, Yevgen Chebotar, Joseph Dabis, Chelsea Finn, Keerthana Gopalakrishnan, Karol Hausman, Alex Herzog, Jasmine Hsu, et al. Rt-1: Robotics transformer for real-world control at scale. arXiv preprint arXiv:2212.06817, 2022. 2",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/186",
      "parent": {
        "$ref": "#/groups/2"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 10,
          "bbox": {
            "l": 63.77204513549805,
            "t": 531.7229614257812,
            "r": 294.61199951171875,
            "b": 480.8108215332031,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            281
          ]
        }
      ],
      "orig": "[4] Anthony Brohan, Noah Brown, Justice Carbajal, Yevgen Chebotar, Xi Chen, Krzysztof Choromanski, Tianli Ding, Danny Driess, Avinava Dubey, Chelsea Finn, et al. Rt-2: Vision-language-action models transfer web knowledge to robotic control. arXiv preprint arXiv:2307.15818, 2023. 2",
      "text": "[4] Anthony Brohan, Noah Brown, Justice Carbajal, Yevgen Chebotar, Xi Chen, Krzysztof Choromanski, Tianli Ding, Danny Driess, Avinava Dubey, Chelsea Finn, et al. Rt-2: Vision-language-action models transfer web knowledge to robotic control. arXiv preprint arXiv:2307.15818, 2023. 2",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/187",
      "parent": {
        "$ref": "#/groups/2"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 10,
          "bbox": {
            "l": 63.77204513549805,
            "t": 476.1928405761719,
            "r": 294.1278076171875,
            "b": 457.455810546875,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            96
          ]
        }
      ],
      "orig": "[5] Tom B Brown. Language models are few-shot learners. arXiv preprint arXiv:2005.14165, 2020. 2",
      "text": "[5] Tom B Brown. Language models are few-shot learners. arXiv preprint arXiv:2005.14165, 2020. 2",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/188",
      "parent": {
        "$ref": "#/groups/2"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 10,
          "bbox": {
            "l": 63.77204513549805,
            "t": 452.80096435546875,
            "r": 296.0635070800781,
            "b": 391.02423095703125,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            322
          ]
        }
      ],
      "orig": "[6] Holger Caesar, Varun Bankiti, Alex H Lang, Sourabh Vora, Venice Erin Liong, Qiang Xu, Anush Krishnan, Yu Pan, Giancarlo Baldan, and Oscar Beijbom. nuscenes: A multimodal dataset for autonomous driving. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 11621-11631, 2020. 3 , 5",
      "text": "[6] Holger Caesar, Varun Bankiti, Alex H Lang, Sourabh Vora, Venice Erin Liong, Qiang Xu, Anush Krishnan, Yu Pan, Giancarlo Baldan, and Oscar Beijbom. nuscenes: A multimodal dataset for autonomous driving. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 11621-11631, 2020. 3 , 5",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/189",
      "parent": {
        "$ref": "#/groups/2"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 10,
          "bbox": {
            "l": 63.77204513549805,
            "t": 386.4779968261719,
            "r": 294.90826416015625,
            "b": 336.1396484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            252
          ]
        }
      ],
      "orig": "[7] Holger Caesar, Juraj Kabzan, Kok Seang Tan, Whye Kit Fong, Eric Wolff, Alex Lang, Luke Fletcher, Oscar Beijbom, and Sammy Omari. nuplan: A closed-loop ml-based planning benchmark for autonomous vehicles. arXiv preprint arXiv:2106.11810, 2021. 3 , 5",
      "text": "[7] Holger Caesar, Juraj Kabzan, Kok Seang Tan, Whye Kit Fong, Eric Wolff, Alex Lang, Luke Fletcher, Oscar Beijbom, and Sammy Omari. nuplan: A closed-loop ml-based planning benchmark for autonomous vehicles. arXiv preprint arXiv:2106.11810, 2021. 3 , 5",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/190",
      "parent": {
        "$ref": "#/groups/2"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 10,
          "bbox": {
            "l": 63.77204513549805,
            "t": 330.90301513671875,
            "r": 294.6168212890625,
            "b": 279.9908447265625,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            266
          ]
        }
      ],
      "orig": "[8] Chi-Lam Cheang, Guangzeng Chen, Ya Jing, Tao Kong, Hang Li, Yifeng Li, Yuxiao Liu, Hongtao Wu, Jiafeng Xu, Yichu Yang, et al. Gr-2: A generative video-language-action model with web-scale knowledge for robot manipulation. arXiv preprint arXiv:2410.06158, 2024. 2",
      "text": "[8] Chi-Lam Cheang, Guangzeng Chen, Ya Jing, Tao Kong, Hang Li, Yifeng Li, Yuxiao Liu, Hongtao Wu, Jiafeng Xu, Yichu Yang, et al. Gr-2: A generative video-language-action model with web-scale knowledge for robot manipulation. arXiv preprint arXiv:2410.06158, 2024. 2",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/191",
      "parent": {
        "$ref": "#/groups/2"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 10,
          "bbox": {
            "l": 63.77204513549805,
            "t": 275.3280334472656,
            "r": 294.75970458984375,
            "b": 224.3979034423828,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            279
          ]
        }
      ],
      "orig": "[9] Lili Chen, Kevin Lu, Aravind Rajeswaran, Kimin Lee, Aditya Grover, Misha Laskin, Pieter Abbeel, Aravind Srinivas, and Igor Mordatch. Decision transformer: Reinforcement learning via sequence modeling. Advances in neural information processing systems, 34:15084-15097, 2021. 2",
      "text": "[9] Lili Chen, Kevin Lu, Aravind Rajeswaran, Kimin Lee, Aditya Grover, Misha Laskin, Pieter Abbeel, Aravind Srinivas, and Igor Mordatch. Decision transformer: Reinforcement learning via sequence modeling. Advances in neural information processing systems, 34:15084-15097, 2021. 2",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/192",
      "parent": {
        "$ref": "#/groups/2"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 10,
          "bbox": {
            "l": 59.28902816772461,
            "t": 219.75303649902344,
            "r": 294.3836975097656,
            "b": 179.5718536376953,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            220
          ]
        }
      ],
      "orig": "[10] Li Chen, Penghao Wu, Kashyap Chitta, Bernhard Jaeger, Andreas Geiger, and Hongyang Li. End-to-end autonomous driving: Challenges and frontiers. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2024. 3",
      "text": "[10] Li Chen, Penghao Wu, Kashyap Chitta, Bernhard Jaeger, Andreas Geiger, and Hongyang Li. End-to-end autonomous driving: Challenges and frontiers. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2024. 3",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/193",
      "parent": {
        "$ref": "#/groups/2"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 10,
          "bbox": {
            "l": 59.28902816772461,
            "t": 174.91802978515625,
            "r": 294.4823303222656,
            "b": 125.7184066772461,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            233
          ]
        }
      ],
      "orig": "[11] Shaoyu Chen, Bo Jiang, Hao Gao, Bencheng Liao, Qing Xu, Qian Zhang, Chang Huang, Wenyu Liu, and Xinggang Wang. Vadv2: End-to-end vectorized autonomous driving via probabilistic planning. arXiv preprint arXiv:2402.13243 , 2024. 3",
      "text": "[11] Shaoyu Chen, Bo Jiang, Hao Gao, Bencheng Liao, Qing Xu, Qian Zhang, Chang Huang, Wenyu Liu, and Xinggang Wang. Vadv2: End-to-end vectorized autonomous driving via probabilistic planning. arXiv preprint arXiv:2402.13243 , 2024. 3",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/194",
      "parent": {
        "$ref": "#/groups/2"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 10,
          "bbox": {
            "l": 59.28903579711914,
            "t": 119.34302520751953,
            "r": 294.46746826171875,
            "b": 79.05426788330078,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            222
          ]
        }
      ],
      "orig": "[12] Kashyap Chitta, Aditya Prakash, and Andreas Geiger. Neat: Neural attention fields for end-to-end autonomous driving. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 15793-15803, 2021.",
      "text": "[12] Kashyap Chitta, Aditya Prakash, and Andreas Geiger. Neat: Neural attention fields for end-to-end autonomous driving. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 15793-15803, 2021.",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/195",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "page_footer",
      "prov": [
        {
          "page_no": 10,
          "bbox": {
            "l": 302.123779296875,
            "t": 57.84776306152344,
            "r": 310.741455078125,
            "b": 50.9835319519043,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            2
          ]
        }
      ],
      "orig": "10",
      "text": "10"
    },
    {
      "self_ref": "#/texts/196",
      "parent": {
        "$ref": "#/groups/3"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 10,
          "bbox": {
            "l": 318.0390319824219,
            "t": 716.1610107421875,
            "r": 553.3668212890625,
            "b": 665.2408447265625,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            271
          ]
        }
      ],
      "orig": "[13] Kashyap Chitta, Aditya Prakash, Bernhard Jaeger, Zehao Yu, Katrin Renz, and Andreas Geiger. Transfuser: Imitation with transformer-based sensor fusion for autonomous driving. IEEE Transactions on Pattern Analysis and Machine Intelligence, 45(11):12878-12895, 2022. 3",
      "text": "[13] Kashyap Chitta, Aditya Prakash, Bernhard Jaeger, Zehao Yu, Katrin Renz, and Andreas Geiger. Transfuser: Imitation with transformer-based sensor fusion for autonomous driving. IEEE Transactions on Pattern Analysis and Machine Intelligence, 45(11):12878-12895, 2022. 3",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/197",
      "parent": {
        "$ref": "#/groups/3"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 10,
          "bbox": {
            "l": 318.0390319824219,
            "t": 661.9912109375,
            "r": 553.5103149414062,
            "b": 611.6527099609375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            261
          ]
        }
      ],
      "orig": "[14] Felipe Codevilla, Matthias Muller, Antonio L \u00a8 opez, Vladlen ' ' Koltun, and Alexey Dosovitskiy. End-to-end driving via conditional imitation learning. In 2018 IEEE international conference on robotics and automation (ICRA), pages 4693- 4700. IEEE, 2018. 3",
      "text": "[14] Felipe Codevilla, Matthias Muller, Antonio L \u00a8 opez, Vladlen ' ' Koltun, and Alexey Dosovitskiy. End-to-end driving via conditional imitation learning. In 2018 IEEE international conference on robotics and automation (ICRA), pages 4693- 4700. IEEE, 2018. 3",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/198",
      "parent": {
        "$ref": "#/groups/3"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 10,
          "bbox": {
            "l": 318.0390319824219,
            "t": 607.8659057617188,
            "r": 553.5192260742188,
            "b": 546.7427368164062,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            297
          ]
        }
      ],
      "orig": "[15] Daniel Dauner, Marcel Hallgarten, Tianyu Li, Xinshuo Weng, Zhiyu Huang, Zetong Yang, Hongyang Li, Igor Gilitschenski, Boris Ivanovic, Marco Pavone, et al. Navsim: Data-driven non-reactive autonomous vehicle simulation and benchmarking. arXiv preprint arXiv:2406.15349, 2024. 2 , 3 , 5 , 6 , 7",
      "text": "[15] Daniel Dauner, Marcel Hallgarten, Tianyu Li, Xinshuo Weng, Zhiyu Huang, Zetong Yang, Hongyang Li, Igor Gilitschenski, Boris Ivanovic, Marco Pavone, et al. Navsim: Data-driven non-reactive autonomous vehicle simulation and benchmarking. arXiv preprint arXiv:2406.15349, 2024. 2 , 3 , 5 , 6 , 7",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/199",
      "parent": {
        "$ref": "#/groups/3"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 10,
          "bbox": {
            "l": 318.0390319824219,
            "t": 542.9200439453125,
            "r": 553.658203125,
            "b": 514.0517578125,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            141
          ]
        }
      ],
      "orig": "[16] Jacob Devlin. Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805, 2018. 2",
      "text": "[16] Jacob Devlin. Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805, 2018. 2",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/200",
      "parent": {
        "$ref": "#/groups/3"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 10,
          "bbox": {
            "l": 318.0390319824219,
            "t": 510.2201232910156,
            "r": 553.0709228515625,
            "b": 470.62176513671875,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            188
          ]
        }
      ],
      "orig": "[17] Alexey Dosovitskiy, German Ros, Felipe Codevilla, Antonio Lopez, and Vladlen Koltun. Carla: An open urban driving simulator. In Conference on robot learning, pages 1-16. PMLR, 2017. 3",
      "text": "[17] Alexey Dosovitskiy, German Ros, Felipe Codevilla, Antonio Lopez, and Vladlen Koltun. Carla: An open urban driving simulator. In Conference on robot learning, pages 1-16. PMLR, 2017. 3",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/201",
      "parent": {
        "$ref": "#/groups/3"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 10,
          "bbox": {
            "l": 318.03900146484375,
            "t": 466.78912353515625,
            "r": 553.2681884765625,
            "b": 426.5003662109375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            225
          ]
        }
      ],
      "orig": "[18] Patrick Esser, Robin Rombach, and Bjorn Ommer. Taming transformers for high-resolution image synthesis. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 12873-12883, 2021. 2 , 3",
      "text": "[18] Patrick Esser, Robin Rombach, and Bjorn Ommer. Taming transformers for high-resolution image synthesis. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 12873-12883, 2021. 2 , 3",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/202",
      "parent": {
        "$ref": "#/groups/3"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 10,
          "bbox": {
            "l": 318.0389709472656,
            "t": 423.3581237792969,
            "r": 553.277099609375,
            "b": 372.4379577636719,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            281
          ]
        }
      ],
      "orig": "[19] Shenyuan Gao, Jiazhi Yang, Li Chen, Kashyap Chitta, Yihang Qiu, Andreas Geiger, Jun Zhang, and Hongyang Li. Vista: A generalizable driving world model with high fidelity and versatile controllability. In Advances in Neural Information Processing Systems (NeurIPS), 2024. 1 , 2",
      "text": "[19] Shenyuan Gao, Jiazhi Yang, Li Chen, Kashyap Chitta, Yihang Qiu, Andreas Geiger, Jun Zhang, and Hongyang Li. Vista: A generalizable driving world model with high fidelity and versatile controllability. In Advances in Neural Information Processing Systems (NeurIPS), 2024. 1 , 2",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/203",
      "parent": {
        "$ref": "#/groups/3"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 10,
          "bbox": {
            "l": 318.0389709472656,
            "t": 369.1881103515625,
            "r": 553.7088623046875,
            "b": 318.15936279296875,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            261
          ]
        }
      ],
      "orig": "[20] Songwei Ge, Thomas Hayes, Harry Yang, Xi Yin, Guan Pang, David Jacobs, Jia-Bin Huang, and Devi Parikh. Long video generation with time-agnostic vqgan and timesensitive transformer. In European Conference on Computer Vision, pages 102-118. Springer, 2022. 2",
      "text": "[20] Songwei Ge, Thomas Hayes, Harry Yang, Xi Yin, Guan Pang, David Jacobs, Jia-Bin Huang, and Devi Parikh. Long video generation with time-agnostic vqgan and timesensitive transformer. In European Conference on Computer Vision, pages 102-118. Springer, 2022. 2",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/204",
      "parent": {
        "$ref": "#/groups/3"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 10,
          "bbox": {
            "l": 318.0389709472656,
            "t": 315.01812744140625,
            "r": 553.277099609375,
            "b": 274.845947265625,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            228
          ]
        }
      ],
      "orig": "[21] Songen Gu, Wei Yin, Bu Jin, Xiaoyang Guo, Junming Wang, Haodong Li, Qian Zhang, and Xiaoxiao Long. Dome: Taming diffusion model into high-fidelity controllable occupancy world model. arXiv preprint arXiv:2410.10429, 2024. 2",
      "text": "[21] Songen Gu, Wei Yin, Bu Jin, Xiaoyang Guo, Junming Wang, Haodong Li, Qian Zhang, and Xiaoxiao Long. Dome: Taming diffusion model into high-fidelity controllable occupancy world model. arXiv preprint arXiv:2410.10429, 2024. 2",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/205",
      "parent": {
        "$ref": "#/groups/3"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 10,
          "bbox": {
            "l": 318.0389709472656,
            "t": 271.5871276855469,
            "r": 553.3667602539062,
            "b": 211.64849853515625,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            288
          ]
        }
      ],
      "orig": "[22] Cole Gulino, Justin Fu, Wenjie Luo, George Tucker, Eli Bronstein, Yiren Lu, Jean Harb, Xinlei Pan, Yan Wang, Xiangyu Chen, et al. Waymax: An accelerated, data-driven simulator for large-scale autonomous driving research. Advances in Neural Information Processing Systems, 36, 2024. 3",
      "text": "[22] Cole Gulino, Justin Fu, Wenjie Luo, George Tucker, Eli Bronstein, Yiren Lu, Jean Harb, Xinlei Pan, Yan Wang, Xiangyu Chen, et al. Waymax: An accelerated, data-driven simulator for large-scale autonomous driving research. Advances in Neural Information Processing Systems, 36, 2024. 3",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/206",
      "parent": {
        "$ref": "#/groups/3"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 10,
          "bbox": {
            "l": 318.0389709472656,
            "t": 206.67710876464844,
            "r": 553.3389282226562,
            "b": 187.98390197753906,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            94
          ]
        }
      ],
      "orig": "[23] David Ha and Jurgen Schmidhuber. World models. \u00a8 arXiv preprint arXiv:1803.10122, 2018. 2",
      "text": "[23] David Ha and Jurgen Schmidhuber. World models. \u00a8 arXiv preprint arXiv:1803.10122, 2018. 2",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/207",
      "parent": {
        "$ref": "#/groups/3"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 10,
          "bbox": {
            "l": 318.0389709472656,
            "t": 184.72610473632812,
            "r": 553.0709228515625,
            "b": 155.17633056640625,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            172
          ]
        }
      ],
      "orig": "[24] Danijar Hafner, Timothy Lillicrap, Jimmy Ba, and Mohammad Norouzi. Dream to control: Learning behaviors by latent imagination. arXiv preprint arXiv:1912.01603, 2019. 2",
      "text": "[24] Danijar Hafner, Timothy Lillicrap, Jimmy Ba, and Mohammad Norouzi. Dream to control: Learning behaviors by latent imagination. arXiv preprint arXiv:1912.01603, 2019. 2",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/208",
      "parent": {
        "$ref": "#/groups/3"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 10,
          "bbox": {
            "l": 318.0389709472656,
            "t": 152.07992553710938,
            "r": 553.4833374023438,
            "b": 101.69674682617188,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            242
          ]
        }
      ],
      "orig": "[25] Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter. Gans trained by a two time-scale update rule converge to a local nash equilibrium. Advances in neural information processing systems , 30, 2017. 6",
      "text": "[25] Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter. Gans trained by a two time-scale update rule converge to a local nash equilibrium. Advances in neural information processing systems , 30, 2017. 6",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/209",
      "parent": {
        "$ref": "#/groups/3"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 10,
          "bbox": {
            "l": 318.0389709472656,
            "t": 97.87306213378906,
            "r": 553.2724609375,
            "b": 79.7447509765625,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            116
          ]
        }
      ],
      "orig": "[26] Anthony Hu, Gianluca Corrado, Nicolas Griffiths, Zachary Murez, Corina Gurau, Hudson Yeo, Alex Kendall, Roberto",
      "text": "[26] Anthony Hu, Gianluca Corrado, Nicolas Griffiths, Zachary Murez, Corina Gurau, Hudson Yeo, Alex Kendall, Roberto",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/210",
      "parent": {
        "$ref": "#/groups/3"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 11,
          "bbox": {
            "l": 78.59832763671875,
            "t": 716.1610107421875,
            "r": 294.4823303222656,
            "b": 686.7198486328125,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            152
          ]
        }
      ],
      "orig": "Cipolla, and Jamie Shotton. Model-based imitation learning for urban driving. Advances in Neural Information Processing Systems, 35:20703-20716, 2022. 3",
      "text": "Cipolla, and Jamie Shotton. Model-based imitation learning for urban driving. Advances in Neural Information Processing Systems, 35:20703-20716, 2022. 3",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/211",
      "parent": {
        "$ref": "#/groups/3"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 11,
          "bbox": {
            "l": 59.28904724121094,
            "t": 682.6439819335938,
            "r": 294.3209533691406,
            "b": 632.3056640625,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            228
          ]
        }
      ],
      "orig": "[27] Anthony Hu, Lloyd Russell, Hudson Yeo, Zak Murez, George Fedoseev, Alex Kendall, Jamie Shotton, and Gianluca Corrado. Gaia-1: A generative world model for autonomous driving. arXiv preprint arXiv:2309.17080, 2023. 1 , 2 , 8",
      "text": "[27] Anthony Hu, Lloyd Russell, Hudson Yeo, Zak Murez, George Fedoseev, Alex Kendall, Jamie Shotton, and Gianluca Corrado. Gaia-1: A generative world model for autonomous driving. arXiv preprint arXiv:2309.17080, 2023. 1 , 2 , 8",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/212",
      "parent": {
        "$ref": "#/groups/3"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 11,
          "bbox": {
            "l": 59.28903579711914,
            "t": 627.6480102539062,
            "r": 294.6167907714844,
            "b": 576.6193237304688,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            246
          ]
        }
      ],
      "orig": "[28] Shengchao Hu, Li Chen, Penghao Wu, Hongyang Li, Junchi Yan, and Dacheng Tao. St-p3: End-to-end vision-based autonomous driving via spatial-temporal feature learning. In European Conference on Computer Vision, pages 533-549. Springer, 2022. 3",
      "text": "[28] Shengchao Hu, Li Chen, Penghao Wu, Hongyang Li, Junchi Yan, and Dacheng Tao. St-p3: End-to-end vision-based autonomous driving via spatial-temporal feature learning. In European Conference on Computer Vision, pages 533-549. Springer, 2022. 3",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/213",
      "parent": {
        "$ref": "#/groups/3"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 11,
          "bbox": {
            "l": 59.28903579711914,
            "t": 572.6510009765625,
            "r": 294.6168212890625,
            "b": 532.3623046875,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            201
          ]
        }
      ],
      "orig": "[29] Yihan Hu, Jiazhi Yang, Li Chen, Keyu Li, Chonghao Sima, Xizhou Zhu, Siqi Chai, Senyao Du, Tianwei Lin, Wenhai Wang, et al. Planning-oriented autonomous driving. In CVPR, pages 17853-17862, 2023. 3",
      "text": "[29] Yihan Hu, Jiazhi Yang, Li Chen, Keyu Li, Chonghao Sima, Xizhou Zhu, Siqi Chai, Senyao Du, Tianwei Lin, Wenhai Wang, et al. Planning-oriented autonomous driving. In CVPR, pages 17853-17862, 2023. 3",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/214",
      "parent": {
        "$ref": "#/groups/3"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 11,
          "bbox": {
            "l": 59.28903579711914,
            "t": 528.3939819335938,
            "r": 294.5443115234375,
            "b": 488.1052551269531,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            202
          ]
        }
      ],
      "orig": "[30] Bernhard Jaeger, Kashyap Chitta, and Andreas Geiger. Hidden biases of end-to-end driving models. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 8240-8249, 2023. 3",
      "text": "[30] Bernhard Jaeger, Kashyap Chitta, and Andreas Geiger. Hidden biases of end-to-end driving models. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 8240-8249, 2023. 3",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/215",
      "parent": {
        "$ref": "#/groups/3"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 11,
          "bbox": {
            "l": 59.289031982421875,
            "t": 484.1380310058594,
            "r": 294.4776916503906,
            "b": 443.9658508300781,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            210
          ]
        }
      ],
      "orig": "[31] Fan Jia, Weixin Mao, Yingfei Liu, Yucheng Zhao, Yuqing Wen, Chi Zhang, Xiangyu Zhang, and Tiancai Wang. Adriver-i: A general world model for autonomous driving. arXiv preprint arXiv:2311.13549, 2023. 1 , 2",
      "text": "[31] Fan Jia, Weixin Mao, Yingfei Liu, Yucheng Zhao, Yuqing Wen, Chi Zhang, Xiangyu Zhang, and Tiancai Wang. Adriver-i: A general world model for autonomous driving. arXiv preprint arXiv:2311.13549, 2023. 1 , 2",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/216",
      "parent": {
        "$ref": "#/groups/3"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 11,
          "bbox": {
            "l": 59.28902816772461,
            "t": 439.88104248046875,
            "r": 294.747802734375,
            "b": 389.5426940917969,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            241
          ]
        }
      ],
      "orig": "[32] Bo Jiang, Shaoyu Chen, Qing Xu, Bencheng Liao, Jiajie Chen, Helong Zhou, Qian Zhang, Wenyu Liu, Chang Huang, and Xinggang Wang. Vad: Vectorized scene representation for efficient autonomous driving. In ICCV, V, pages 8340- 8350, 2023. 3",
      "text": "[32] Bo Jiang, Shaoyu Chen, Qing Xu, Bencheng Liao, Jiajie Chen, Helong Zhou, Qian Zhang, Wenyu Liu, Chang Huang, and Xinggang Wang. Vad: Vectorized scene representation for efficient autonomous driving. In ICCV, V, pages 8340- 8350, 2023. 3",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/217",
      "parent": {
        "$ref": "#/groups/3"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 11,
          "bbox": {
            "l": 59.28902053833008,
            "t": 384.8840637207031,
            "r": 294.3209228515625,
            "b": 334.54571533203125,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            239
          ]
        }
      ],
      "orig": "[33] Dan Kondratyuk, Lijun Yu, Xiuye Gu, Jose Lezama, Jonathan Huang, Grant Schindler, Rachel Hornung, Vighnesh Birodkar, Jimmy Yan, Ming-Chang Chiu, et al. Videopoet: A large language model for zero-shot video generation. In ICML, 2024. 2",
      "text": "[33] Dan Kondratyuk, Lijun Yu, Xiuye Gu, Jose Lezama, Jonathan Huang, Grant Schindler, Rachel Hornung, Vighnesh Birodkar, Jimmy Yan, Ming-Chang Chiu, et al. Videopoet: A large language model for zero-shot video generation. In ICML, 2024. 2",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/218",
      "parent": {
        "$ref": "#/groups/3"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 11,
          "bbox": {
            "l": 59.28902053833008,
            "t": 329.8880920410156,
            "r": 294.3162841796875,
            "b": 301.02874755859375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            128
          ]
        }
      ],
      "orig": "[34] Yann LeCun. A path towards autonomous machine intelligence version 0.9. 2, 2022-06-27. Open Review, 62(1):1-62, 2022. 1 , 2",
      "text": "[34] Yann LeCun. A path towards autonomous machine intelligence version 0.9. 2, 2022-06-27. Open Review, 62(1):1-62, 2022. 1 , 2",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/219",
      "parent": {
        "$ref": "#/groups/3"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 11,
          "bbox": {
            "l": 59.289005279541016,
            "t": 296.41595458984375,
            "r": 294.6659851074219,
            "b": 246.03277587890625,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            245
          ]
        }
      ],
      "orig": "[35] Doyup Lee, Chiheon Kim, Saehoon Kim, Minsu Cho, and Wook-Shin Han. Autoregressive image generation using residual quantization. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 11523-11532, 2022. 2",
      "text": "[35] Doyup Lee, Chiheon Kim, Saehoon Kim, Minsu Cho, and Wook-Shin Han. Autoregressive image generation using residual quantization. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 11523-11532, 2022. 2",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/220",
      "parent": {
        "$ref": "#/groups/3"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 11,
          "bbox": {
            "l": 59.289005279541016,
            "t": 241.38308715820312,
            "r": 294.5181884765625,
            "b": 190.34535217285156,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            278
          ]
        }
      ],
      "orig": "[36] Yuheng Li, Haotian Liu, Qingyang Wu, Fangzhou Mu, Jianwei Yang, Jianfeng Gao, Chunyuan Li, and Yong Jae Lee. Gligen: Open-set grounded text-to-image generation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 22511-22521, 2023. 1",
      "text": "[36] Yuheng Li, Haotian Liu, Qingyang Wu, Fangzhou Mu, Jianwei Yang, Jianfeng Gao, Chunyuan Li, and Yong Jae Lee. Gligen: Open-set grounded text-to-image generation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 22511-22521, 2023. 1",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/221",
      "parent": {
        "$ref": "#/groups/3"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 11,
          "bbox": {
            "l": 59.288997650146484,
            "t": 186.37811279296875,
            "r": 296.05584716796875,
            "b": 135.34933471679688,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            272
          ]
        }
      ],
      "orig": "[37] Zhiqi Li, Zhiding Yu, Shiyi Lan, Jiahan Li, Jan Kautz, Tong Lu, and Jose M Alvarez. Is ego status all you need for openloop end-to-end autonomous driving? In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 14864-14873, 2024. 7",
      "text": "[37] Zhiqi Li, Zhiding Yu, Shiyi Lan, Jiahan Li, Jan Kautz, Tong Lu, and Jose M Alvarez. Is ego status all you need for openloop end-to-end autonomous driving? In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 14864-14873, 2024. 7",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/222",
      "parent": {
        "$ref": "#/groups/3"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 11,
          "bbox": {
            "l": 59.28898239135742,
            "t": 131.38108825683594,
            "r": 294.5210876464844,
            "b": 101.93993377685547,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            151
          ]
        }
      ],
      "orig": "[38] Haotian Liu, Chunyuan Li, Qingyang Wu, and Yong Jae Lee. Visual instruction tuning. Advances in neural information processing systems, 36, 2024. 2",
      "text": "[38] Haotian Liu, Chunyuan Li, Qingyang Wu, and Yong Jae Lee. Visual instruction tuning. Advances in neural information processing systems, 36, 2024. 2",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/223",
      "parent": {
        "$ref": "#/groups/3"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 11,
          "bbox": {
            "l": 59.28898239135742,
            "t": 97.86409759521484,
            "r": 294.6121520996094,
            "b": 79.05433654785156,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            110
          ]
        }
      ],
      "orig": "[39] Zhuoyan Luo, Fengyuan Shi, Yixiao Ge, Yujiu Yang, Limin Wang, and Ying Shan. Open-magvit2: An open-source",
      "text": "[39] Zhuoyan Luo, Fengyuan Shi, Yixiao Ge, Yujiu Yang, Limin Wang, and Ying Shan. Open-magvit2: An open-source",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/224",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "page_footer",
      "prov": [
        {
          "page_no": 11,
          "bbox": {
            "l": 302.1247863769531,
            "t": 57.847808837890625,
            "r": 309.9255065917969,
            "b": 51.11309051513672,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            2
          ]
        }
      ],
      "orig": "11",
      "text": "11"
    },
    {
      "self_ref": "#/texts/225",
      "parent": {
        "$ref": "#/groups/4"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 11,
          "bbox": {
            "l": 337.2137756347656,
            "t": 716.162109375,
            "r": 553.0708618164062,
            "b": 697.4689331054688,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            104
          ]
        }
      ],
      "orig": "project toward democratizing auto-regressive visual generation. arXiv preprint arXiv:2409.04410, 2024. 7",
      "text": "project toward democratizing auto-regressive visual generation. arXiv preprint arXiv:2409.04410, 2024. 7",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/226",
      "parent": {
        "$ref": "#/groups/4"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 11,
          "bbox": {
            "l": 318.0389709472656,
            "t": 693.4771118164062,
            "r": 553.474365234375,
            "b": 642.56494140625,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            267
          ]
        }
      ],
      "orig": "[40] Abby O'Neill, Abdul Rehman, Abhinav Gupta, Abhiram Maddukuri, Abhishek Gupta, Abhishek Padalkar, Abraham Lee, Acorn Pooley, Agrim Gupta, Ajay Mandlekar, et al. Open x-embodiment: Robotic learning datasets and rt-x models. arXiv preprint arXiv:2310.08864, 2023. 2",
      "text": "[40] Abby O'Neill, Abdul Rehman, Abhinav Gupta, Abhiram Maddukuri, Abhishek Gupta, Abhishek Padalkar, Abraham Lee, Acorn Pooley, Agrim Gupta, Ajay Mandlekar, et al. Open x-embodiment: Robotic learning datasets and rt-x models. arXiv preprint arXiv:2310.08864, 2023. 2",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/227",
      "parent": {
        "$ref": "#/groups/4"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 11,
          "bbox": {
            "l": 318.0389709472656,
            "t": 638.5731201171875,
            "r": 553.2635498046875,
            "b": 598.284423828125,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            213
          ]
        }
      ],
      "orig": "[41] Niki Parmar, Ashish Vaswani, Jakob Uszkoreit, Lukasz Kaiser, Noam Shazeer, Alexander Ku, and Dustin Tran. Image transformer. In International conference on machine learning, pages 4055-4064. PMLR, 2018. 2 , 3",
      "text": "[41] Niki Parmar, Ashish Vaswani, Jakob Uszkoreit, Lukasz Kaiser, Noam Shazeer, Alexander Ku, and Dustin Tran. Image transformer. In International conference on machine learning, pages 4055-4064. PMLR, 2018. 2 , 3",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/228",
      "parent": {
        "$ref": "#/groups/4"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 11,
          "bbox": {
            "l": 318.0389709472656,
            "t": 594.4091186523438,
            "r": 553.1290283203125,
            "b": 555.9495239257812,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            183
          ]
        }
      ],
      "orig": "[42] William Peebles and Saining Xie. Scalable diffusion models with transformers. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 4195-4205, 2023. 1",
      "text": "[42] William Peebles and Saining Xie. Scalable diffusion models with transformers. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 4195-4205, 2023. 1",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/229",
      "parent": {
        "$ref": "#/groups/4"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 11,
          "bbox": {
            "l": 318.0389709472656,
            "t": 550.2451171875,
            "r": 553.4833374023438,
            "b": 510.0550231933594,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            218
          ]
        }
      ],
      "orig": "[43] Ethan Perez, Florian Strub, Harm De Vries, Vincent Dumoulin, and Aaron Courville. Film: Visual reasoning with a general conditioning layer. In Proceedings of the AAAI conference on artificial intelligence, 2018. 1",
      "text": "[43] Ethan Perez, Florian Strub, Harm De Vries, Vincent Dumoulin, and Aaron Courville. Film: Visual reasoning with a general conditioning layer. In Proceedings of the AAAI conference on artificial intelligence, 2018. 1",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/230",
      "parent": {
        "$ref": "#/groups/4"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 11,
          "bbox": {
            "l": 318.0389709472656,
            "t": 506.0811462402344,
            "r": 553.0708618164062,
            "b": 456.88153076171875,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            232
          ]
        }
      ],
      "orig": "[44] Aditya Prakash, Kashyap Chitta, and Andreas Geiger. Multimodal fusion transformer for end-to-end autonomous driving. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 7077-7087, 2021. 3",
      "text": "[44] Aditya Prakash, Kashyap Chitta, and Andreas Geiger. Multimodal fusion transformer for end-to-end autonomous driving. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 7077-7087, 2021. 3",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/231",
      "parent": {
        "$ref": "#/groups/4"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 11,
          "bbox": {
            "l": 318.0389709472656,
            "t": 451.22198486328125,
            "r": 553.0452880859375,
            "b": 410.8883972167969,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            235
          ]
        }
      ],
      "orig": "[45] Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray, Chelsea Voss, Alec Radford, Mark Chen, and Ilya Sutskever. Zero-shot text-to-image generation. In International conference on machine learning, pages 8821-8831. Pmlr, 2021. 2",
      "text": "[45] Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray, Chelsea Voss, Alec Radford, Mark Chen, and Ilya Sutskever. Zero-shot text-to-image generation. In International conference on machine learning, pages 8821-8831. Pmlr, 2021. 2",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/232",
      "parent": {
        "$ref": "#/groups/4"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 11,
          "bbox": {
            "l": 318.0389709472656,
            "t": 407.0221252441406,
            "r": 554.8062744140625,
            "b": 355.9844055175781,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            267
          ]
        }
      ],
      "orig": "[46] Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bjorn Ommer. High-resolution image \u00a8 synthesis with latent diffusion models. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 10684-10695, 2022. 1 , 2",
      "text": "[46] Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bjorn Ommer. High-resolution image \u00a8 synthesis with latent diffusion models. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 10684-10695, 2022. 1 , 2",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/233",
      "parent": {
        "$ref": "#/groups/4"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 11,
          "bbox": {
            "l": 318.03900146484375,
            "t": 352.1093444824219,
            "r": 553.4205932617188,
            "b": 312.51080322265625,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            207
          ]
        }
      ],
      "orig": "[47] Anian Ruoss, Gregoire Del ' ' etang, Sourabh Medapati, Jordi ' ' Grau-Moya, Li Kevin Wenliang, Elliot Catt, John Reid, and Tim Genewein. Grandmaster-level chess without search. arXiv:2402.04494, 2024. 2",
      "text": "[47] Anian Ruoss, Gregoire Del ' ' etang, Sourabh Medapati, Jordi ' ' Grau-Moya, Li Kevin Wenliang, Elliot Catt, John Reid, and Tim Genewein. Grandmaster-level chess without search. arXiv:2402.04494, 2024. 2",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/234",
      "parent": {
        "$ref": "#/groups/4"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 11,
          "bbox": {
            "l": 318.03900146484375,
            "t": 307.9451599121094,
            "r": 553.384765625,
            "b": 268.3468017578125,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            182
          ]
        }
      ],
      "orig": "[48] Jianlin Su, Murtadha Ahmed, Yu Lu, Shengfeng Pan, Wen Bo, and Yunfeng Liu. Roformer: Enhanced transformer with rotary position embedding. Neurocomputing, 568:127063, 2024. 2 , 4",
      "text": "[48] Jianlin Su, Murtadha Ahmed, Yu Lu, Shengfeng Pan, Wen Bo, and Yunfeng Liu. Roformer: Enhanced transformer with rotary position embedding. Neurocomputing, 568:127063, 2024. 2 , 4",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/235",
      "parent": {
        "$ref": "#/groups/4"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 11,
          "bbox": {
            "l": 318.03900146484375,
            "t": 263.7811584472656,
            "r": 553.3389282226562,
            "b": 223.60894775390625,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            222
          ]
        }
      ],
      "orig": "[49] Peize Sun, Yi Jiang, Shoufa Chen, Shilong Zhang, Bingyue Peng, Ping Luo, and Zehuan Yuan. Autoregressive model beats diffusion: Llama for scalable image generation. arXiv preprint arXiv:2406.06525, 2024. 2 , 5 , 7 , 1",
      "text": "[49] Peize Sun, Yi Jiang, Shoufa Chen, Shilong Zhang, Bingyue Peng, Ping Luo, and Zehuan Yuan. Autoregressive model beats diffusion: Llama for scalable image generation. arXiv preprint arXiv:2406.06525, 2024. 2 , 5 , 7 , 1",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/236",
      "parent": {
        "$ref": "#/groups/4"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 11,
          "bbox": {
            "l": 318.0389709472656,
            "t": 219.6619873046875,
            "r": 553.3389282226562,
            "b": 179.4449462890625,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            198
          ]
        }
      ],
      "orig": "[50] Wenchao Sun, Xuewu Lin, Yining Shi, Chuang Zhang, Haoran Wu, and Sifa Zheng. Sparsedrive: End-to-end autonomous driving via sparse scene representation. arXiv preprint arXiv:2405.19620, 2024. 3",
      "text": "[50] Wenchao Sun, Xuewu Lin, Yining Shi, Chuang Zhang, Haoran Wu, and Sifa Zheng. Sparsedrive: End-to-end autonomous driving via sparse scene representation. arXiv preprint arXiv:2405.19620, 2024. 3",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/237",
      "parent": {
        "$ref": "#/groups/4"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 11,
          "bbox": {
            "l": 318.0389709472656,
            "t": 175.49798583984375,
            "r": 553.3621826171875,
            "b": 147.84909057617188,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            116
          ]
        }
      ],
      "orig": "[51] Chameleon Team. Chameleon: Mixed-modal early-fusion foundation models. arXiv preprint arXiv:2405.09818, 2024. 2",
      "text": "[51] Chameleon Team. Chameleon: Mixed-modal early-fusion foundation models. arXiv preprint arXiv:2405.09818, 2024. 2",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/238",
      "parent": {
        "$ref": "#/groups/4"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 11,
          "bbox": {
            "l": 318.0389709472656,
            "t": 142.07296752929688,
            "r": 553.6607055664062,
            "b": 102.42979431152344,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            194
          ]
        }
      ],
      "orig": "[52] Keyu Tian, Yi Jiang, Zehuan Yuan, Bingyue Peng, and Liwei Wang. Visual autoregressive modeling: Scalable image generation via next-scale prediction. arXiv preprint arXiv:2404.02905, 2024. 2",
      "text": "[52] Keyu Tian, Yi Jiang, Zehuan Yuan, Bingyue Peng, and Liwei Wang. Visual autoregressive modeling: Scalable image generation via next-scale prediction. arXiv preprint arXiv:2404.02905, 2024. 2",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/239",
      "parent": {
        "$ref": "#/groups/4"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 11,
          "bbox": {
            "l": 318.0389709472656,
            "t": 97.90897369384766,
            "r": 553.5145263671875,
            "b": 79.06434631347656,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            119
          ]
        }
      ],
      "orig": "[53] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothee Lacroix, Baptiste ' '",
      "text": "[53] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothee Lacroix, Baptiste ' '",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/240",
      "parent": {
        "$ref": "#/groups/4"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 12,
          "bbox": {
            "l": 78.5265884399414,
            "t": 716.1611938476562,
            "r": 294.13262939453125,
            "b": 686.7288208007812,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            158
          ]
        }
      ],
      "orig": "Roziere, Naman Goyal, Eric Hambro, Faisal Azhar, et al. ' ' Llama: Open and efficient foundation language models. arXiv preprint arXiv:2302.13971, 2023. 2 , 5",
      "text": "Roziere, Naman Goyal, Eric Hambro, Faisal Azhar, et al. ' ' Llama: Open and efficient foundation language models. arXiv preprint arXiv:2302.13971, 2023. 2 , 5",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/241",
      "parent": {
        "$ref": "#/groups/4"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 12,
          "bbox": {
            "l": 59.28902816772461,
            "t": 682.6888427734375,
            "r": 294.500244140625,
            "b": 642.3552856445312,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            229
          ]
        }
      ],
      "orig": "[54] Thomas Unterthiner, Sjoerd Van Steenkiste, Karol Kurach, Raphael Marinier, Marcin Michalski, and Sylvain Gelly. Towards accurate generative models of video: A new metric & challenges. arXiv preprint arXiv:1812.01717, 2018. 6",
      "text": "[54] Thomas Unterthiner, Sjoerd Van Steenkiste, Karol Kurach, Raphael Marinier, Marcin Michalski, and Sylvain Gelly. Towards accurate generative models of video: A new metric & challenges. arXiv preprint arXiv:1812.01717, 2018. 6",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/242",
      "parent": {
        "$ref": "#/groups/4"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 12,
          "bbox": {
            "l": 59.28902816772461,
            "t": 638.4318237304688,
            "r": 294.5186767578125,
            "b": 598.205810546875,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            209
          ]
        }
      ],
      "orig": "[55] Aaron Van den Oord, Nal Kalchbrenner, Lasse Espeholt, Oriol Vinyals, Alex Graves, et al. Conditional image generation with pixelcnn decoders. Advances in neural information processing systems, 29, 2016. 2",
      "text": "[55] Aaron Van den Oord, Nal Kalchbrenner, Lasse Espeholt, Oriol Vinyals, Alex Graves, et al. Conditional image generation with pixelcnn decoders. Advances in neural information processing systems, 29, 2016. 2",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/243",
      "parent": {
        "$ref": "#/groups/4"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 12,
          "bbox": {
            "l": 59.28901290893555,
            "t": 594.1758422851562,
            "r": 294.5273742675781,
            "b": 554.5326538085938,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            180
          ]
        }
      ],
      "orig": "[56] Aaron Van Den Oord, Nal Kalchbrenner, and Koray \u00a8 Kavukcuoglu. Pixel recurrent neural networks. In International conference on machine learning, pages 1747-1756. PMLR, 2016. 2",
      "text": "[56] Aaron Van Den Oord, Nal Kalchbrenner, and Koray \u00a8 Kavukcuoglu. Pixel recurrent neural networks. In International conference on machine learning, pages 1747-1756. PMLR, 2016. 2",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/244",
      "parent": {
        "$ref": "#/groups/4"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 12,
          "bbox": {
            "l": 59.28902053833008,
            "t": 549.9188232421875,
            "r": 294.56732177734375,
            "b": 520.4318237304688,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            150
          ]
        }
      ],
      "orig": "[57] Aaron Van Den Oord, Oriol Vinyals, et al. Neural discrete representation learning. Advances in neural information processing systems, 30, 2017. 2",
      "text": "[57] Aaron Van Den Oord, Oriol Vinyals, et al. Neural discrete representation learning. Advances in neural information processing systems, 30, 2017. 2",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/245",
      "parent": {
        "$ref": "#/groups/4"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 12,
          "bbox": {
            "l": 59.28902053833008,
            "t": 516.40185546875,
            "r": 294.7591552734375,
            "b": 497.6459045410156,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            101
          ]
        }
      ],
      "orig": "[58] A Vaswani. Attention is all you need. Advances in Neural Information Processing Systems, 2017. 2",
      "text": "[58] A Vaswani. Attention is all you need. Advances in Neural Information Processing Systems, 2017. 2",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/246",
      "parent": {
        "$ref": "#/groups/4"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 12,
          "bbox": {
            "l": 59.28901290893555,
            "t": 493.6238708496094,
            "r": 294.7333984375,
            "b": 442.55029296875,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            281
          ]
        }
      ],
      "orig": "[59] Wenhui Wang, Hangbo Bao, Li Dong, Johan Bjorck, Zhiliang Peng, Qiang Liu, Kriti Aggarwal, Owais Khan Mohammed, Saksham Singhal, Subhojit Som, et al. Image as a foreign language: Beit pretraining for all vision and visionlanguage tasks. arXiv preprint arXiv:2208.10442, 2022. 2",
      "text": "[59] Wenhui Wang, Hangbo Bao, Li Dong, Johan Bjorck, Zhiliang Peng, Qiang Liu, Kriti Aggarwal, Owais Khan Mohammed, Saksham Singhal, Subhojit Som, et al. Image as a foreign language: Beit pretraining for all vision and visionlanguage tasks. arXiv preprint arXiv:2208.10442, 2022. 2",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/247",
      "parent": {
        "$ref": "#/groups/4"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 12,
          "bbox": {
            "l": 59.28901290893555,
            "t": 438.592041015625,
            "r": 294.9147644042969,
            "b": 398.9847106933594,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            202
          ]
        }
      ],
      "orig": "[60] Xiaofeng Wang, Zheng Zhu, Guan Huang, Xinze Chen, Jiagang Zhu, and Jiwen Lu. Drivedreamer: Towards real-worlddriven world models for autonomous driving. arXiv preprint arXiv:2309.09777, 2023. 1 , 2",
      "text": "[60] Xiaofeng Wang, Zheng Zhu, Guan Huang, Xinze Chen, Jiagang Zhu, and Jiwen Lu. Drivedreamer: Towards real-worlddriven world models for autonomous driving. arXiv preprint arXiv:2309.09777, 2023. 1 , 2",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/248",
      "parent": {
        "$ref": "#/groups/4"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 12,
          "bbox": {
            "l": 59.28901290893555,
            "t": 394.3350524902344,
            "r": 294.6121826171875,
            "b": 354.0373229980469,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            223
          ]
        }
      ],
      "orig": "[61] Xinlong Wang, Xiaosong Zhang, Zhengxiong Luo, Quan Sun, Yufeng Cui, Jinsheng Wang, Fan Zhang, Yueze Wang, Zhen Li, Qiying Yu, et al. Emu3: Next-token prediction is all you need. arXiv preprint arXiv:2409.18869, 2024. 2",
      "text": "[61] Xinlong Wang, Xiaosong Zhang, Zhengxiong Luo, Quan Sun, Yufeng Cui, Jinsheng Wang, Fan Zhang, Yueze Wang, Zhen Li, Qiying Yu, et al. Emu3: Next-token prediction is all you need. arXiv preprint arXiv:2409.18869, 2024. 2",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/249",
      "parent": {
        "$ref": "#/groups/4"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 12,
          "bbox": {
            "l": 59.28901290893555,
            "t": 350.07806396484375,
            "r": 294.6705627441406,
            "b": 300.8694763183594,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            234
          ]
        }
      ],
      "orig": "[62] Yuqi Wang, Ke Cheng, Jiawei He, Qitai Wang, Hengchen Dai, Yuntao Chen, Fei Xia, and Zhaoxiang Zhang. Drivingdojo dataset: Advancing interactive and knowledge-enriched driving world model. arXiv preprint arXiv:2410.10738 , 2024. 2",
      "text": "[62] Yuqi Wang, Ke Cheng, Jiawei He, Qitai Wang, Hengchen Dai, Yuntao Chen, Fei Xia, and Zhaoxiang Zhang. Drivingdojo dataset: Advancing interactive and knowledge-enriched driving world model. arXiv preprint arXiv:2410.10738 , 2024. 2",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/250",
      "parent": {
        "$ref": "#/groups/4"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 12,
          "bbox": {
            "l": 59.289005279541016,
            "t": 295.0810852050781,
            "r": 294.500244140625,
            "b": 233.99476623535156,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            306
          ]
        }
      ],
      "orig": "[63] Yuqi Wang, Jiawei He, Lue Fan, Hongxin Li, Yuntao Chen, and Zhaoxiang Zhang. Driving into the future: Multiview visual forecasting and planning with world model for autonomous driving. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 14749-14759, 2024. 1 , 2",
      "text": "[63] Yuqi Wang, Jiawei He, Lue Fan, Hongxin Li, Yuntao Chen, and Zhaoxiang Zhang. Driving into the future: Multiview visual forecasting and planning with world model for autonomous driving. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 14749-14759, 2024. 1 , 2",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/251",
      "parent": {
        "$ref": "#/groups/4"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 12,
          "bbox": {
            "l": 59.289005279541016,
            "t": 229.34507751464844,
            "r": 294.3209228515625,
            "b": 189.04734802246094,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            230
          ]
        }
      ],
      "orig": "[64] Yuqing Wang, Tianwei Xiong, Daquan Zhou, Zhijie Lin, Yang Zhao, Bingyi Kang, Jiashi Feng, and Xihui Liu. Loong: Generating minute-level long videos with autoregressive language models. arXiv preprint arXiv:2410.02757, 2024. 2",
      "text": "[64] Yuqing Wang, Tianwei Xiong, Daquan Zhou, Zhijie Lin, Yang Zhao, Bingyi Kang, Jiashi Feng, and Xihui Liu. Loong: Generating minute-level long videos with autoregressive language models. arXiv preprint arXiv:2410.02757, 2024. 2",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/252",
      "parent": {
        "$ref": "#/groups/4"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 12,
          "bbox": {
            "l": 59.288997650146484,
            "t": 185.1239471435547,
            "r": 294.61676025390625,
            "b": 135.99705505371094,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            214
          ]
        }
      ],
      "orig": "[65] Julong Wei, Shanshuai Yuan, Pengfei Li, Qingda Hu, Zhongxue Gan, and Wenchao Ding. Occllama: An occupancy-language-action generative world model for autonomous driving. arXiv preprint arXiv:2409.03272, 2024. 2",
      "text": "[65] Julong Wei, Shanshuai Yuan, Pengfei Li, Qingda Hu, Zhongxue Gan, and Wenchao Ding. Occllama: An occupancy-language-action generative world model for autonomous driving. arXiv preprint arXiv:2409.03272, 2024. 2",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/253",
      "parent": {
        "$ref": "#/groups/4"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 12,
          "bbox": {
            "l": 59.28897476196289,
            "t": 130.09207153320312,
            "r": 295.0523376464844,
            "b": 79.05435180664062,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            257
          ]
        }
      ],
      "orig": "[66] Xinshuo Weng, Boris Ivanovic, Yan Wang, Yue Wang, and Marco Pavone. Para-drive: Parallelized architecture for realtime autonomous driving. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 15449-15458, 2024. 3",
      "text": "[66] Xinshuo Weng, Boris Ivanovic, Yan Wang, Yue Wang, and Marco Pavone. Para-drive: Parallelized architecture for realtime autonomous driving. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 15449-15458, 2024. 3",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/254",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "page_footer",
      "prov": [
        {
          "page_no": 12,
          "bbox": {
            "l": 302.123779296875,
            "t": 57.84680938720703,
            "r": 310.7314758300781,
            "b": 51.112091064453125,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            2
          ]
        }
      ],
      "orig": "12",
      "text": "12"
    },
    {
      "self_ref": "#/texts/255",
      "parent": {
        "$ref": "#/groups/5"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 12,
          "bbox": {
            "l": 318.0389709472656,
            "t": 716.1710815429688,
            "r": 553.5191650390625,
            "b": 665.8237915039062,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            253
          ]
        }
      ],
      "orig": "[67] Penghao Wu, Xiaosong Jia, Li Chen, Junchi Yan, Hongyang Li, and Yu Qiao. Trajectory-guided control prediction for end-to-end autonomous driving: A simple yet strong baseline. Advances in Neural Information Processing Systems , 35:6119-6132, 2022. 3",
      "text": "[67] Penghao Wu, Xiaosong Jia, Li Chen, Junchi Yan, Hongyang Li, and Yu Qiao. Trajectory-guided control prediction for end-to-end autonomous driving: A simple yet strong baseline. Advances in Neural Information Processing Systems , 35:6119-6132, 2022. 3",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/256",
      "parent": {
        "$ref": "#/groups/5"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 12,
          "bbox": {
            "l": 318.0389709472656,
            "t": 661.47607421875,
            "r": 553.3389282226562,
            "b": 610.554931640625,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            254
          ]
        }
      ],
      "orig": "[68] Jiannan Xiang, Guangyi Liu, Yi Gu, Qiyue Gao, Yuting Ning, Yuheng Zha, Zeyu Feng, Tianhua Tao, Shibo Hao, Yemin Shi, et al. Pandora: Towards general world model with natural language actions and video states. arXiv preprint arXiv:2406.09455, 2024. 2",
      "text": "[68] Jiannan Xiang, Guangyi Liu, Yi Gu, Qiyue Gao, Yuting Ning, Yuheng Zha, Zeyu Feng, Tianhua Tao, Shibo Hao, Yemin Shi, et al. Pandora: Towards general world model with natural language actions and video states. arXiv preprint arXiv:2406.09455, 2024. 2",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/257",
      "parent": {
        "$ref": "#/groups/5"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 12,
          "bbox": {
            "l": 318.0389709472656,
            "t": 606.7810668945312,
            "r": 553.4158935546875,
            "b": 577.3399047851562,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            166
          ]
        }
      ],
      "orig": "[69] Wilson Yan, Yunzhi Zhang, Pieter Abbeel, and Aravind Srinivas. Videogpt: Video generation using vq-vae and transformers. arXiv preprint arXiv:2104.10157, 2021. 2",
      "text": "[69] Wilson Yan, Yunzhi Zhang, Pieter Abbeel, and Aravind Srinivas. Videogpt: Video generation using vq-vae and transformers. arXiv preprint arXiv:2104.10157, 2021. 2",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/258",
      "parent": {
        "$ref": "#/groups/5"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 12,
          "bbox": {
            "l": 318.0389709472656,
            "t": 573.5570678710938,
            "r": 553.7052001953125,
            "b": 511.8969421386719,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            326
          ]
        }
      ],
      "orig": "[70] Jiazhi Yang, Shenyuan Gao, Yihang Qiu, Li Chen, Tianyu Li, Bo Dai, Kashyap Chitta, Penghao Wu, Jia Zeng, Ping Luo, Jun Zhang, Andreas Geiger, Yu Qiao, and Hongyang Li. Generalized Predictive Model for Autonomous Driving. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2024. 2",
      "text": "[70] Jiazhi Yang, Shenyuan Gao, Yihang Qiu, Li Chen, Tianyu Li, Bo Dai, Kashyap Chitta, Penghao Wu, Jia Zeng, Ping Luo, Jun Zhang, Andreas Geiger, Yu Qiao, and Hongyang Li. Generalized Predictive Model for Autonomous Driving. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2024. 2",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/259",
      "parent": {
        "$ref": "#/groups/5"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 12,
          "bbox": {
            "l": 318.0389709472656,
            "t": 508.12310791015625,
            "r": 553.6654052734375,
            "b": 457.7847595214844,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            253
          ]
        }
      ],
      "orig": "[71] Zhuoyi Yang, Jiayan Teng, Wendi Zheng, Ming Ding, Shiyu Huang, Jiazheng Xu, Yuanming Yang, Wenyi Hong, Xiaohan Zhang, Guanyu Feng, et al. Cogvideox: Text-to-video diffusion models with an expert transformer. arXiv preprint arXiv:2408.06072, 2024. 6",
      "text": "[71] Zhuoyi Yang, Jiayan Teng, Wendi Zheng, Ming Ding, Shiyu Huang, Jiazheng Xu, Yuanming Yang, Wenyi Hong, Xiaohan Zhang, Guanyu Feng, et al. Cogvideox: Text-to-video diffusion models with an expert transformer. arXiv preprint arXiv:2408.06072, 2024. 6",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/260",
      "parent": {
        "$ref": "#/groups/5"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 12,
          "bbox": {
            "l": 318.0389709472656,
            "t": 453.4281311035156,
            "r": 553.3389282226562,
            "b": 402.5159606933594,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            273
          ]
        }
      ],
      "orig": "[72] Jiahui Yu, Yuanzhong Xu, Jing Yu Koh, Thang Luong, Gunjan Baid, Zirui Wang, Vijay Vasudevan, Alexander Ku, Yinfei Yang, Burcu Karagol Ayan, et al. Scaling autoregressive models for content-rich text-to-image generation. arXiv preprint arXiv:2206.10789, 2(3):5, 2022. 2",
      "text": "[72] Jiahui Yu, Yuanzhong Xu, Jing Yu Koh, Thang Luong, Gunjan Baid, Zirui Wang, Vijay Vasudevan, Alexander Ku, Yinfei Yang, Burcu Karagol Ayan, et al. Scaling autoregressive models for content-rich text-to-image generation. arXiv preprint arXiv:2206.10789, 2(3):5, 2022. 2",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/261",
      "parent": {
        "$ref": "#/groups/5"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 12,
          "bbox": {
            "l": 318.0389709472656,
            "t": 398.73333740234375,
            "r": 553.384765625,
            "b": 347.82196044921875,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            268
          ]
        }
      ],
      "orig": "[73] Lijun Yu, Jose Lezama, Nitesh B Gundavarapu, Luca Ver- ' ' sari, Kihyuk Sohn, David Minnen, Yong Cheng, Vighnesh Birodkar, Agrim Gupta, Xiuye Gu, et al. Language model beats diffusion-tokenizer is key to visual generation. arXiv preprint arXiv:2310.05737, 2023. 2",
      "text": "[73] Lijun Yu, Jose Lezama, Nitesh B Gundavarapu, Luca Ver- ' ' sari, Kihyuk Sohn, David Minnen, Yong Cheng, Vighnesh Birodkar, Agrim Gupta, Xiuye Gu, et al. Language model beats diffusion-tokenizer is key to visual generation. arXiv preprint arXiv:2310.05737, 2023. 2",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/262",
      "parent": {
        "$ref": "#/groups/5"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 12,
          "bbox": {
            "l": 318.0389709472656,
            "t": 344.0391540527344,
            "r": 553.4205932617188,
            "b": 304.4407958984375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            196
          ]
        }
      ],
      "orig": "[74] Lunjun Zhang, Yuwen Xiong, Ze Yang, Sergio Casas, Rui Hu, and Raquel Urtasun. Copilot4d: Learning unsupervised world models for autonomous driving via discrete diffusion. In ICLR, 2024. 1 , 2",
      "text": "[74] Lunjun Zhang, Yuwen Xiong, Ze Yang, Sergio Casas, Rui Hu, and Raquel Urtasun. Copilot4d: Learning unsupervised world models for autonomous driving via discrete diffusion. In ICLR, 2024. 1 , 2",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/263",
      "parent": {
        "$ref": "#/groups/5"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 12,
          "bbox": {
            "l": 318.0389709472656,
            "t": 300.1289978027344,
            "r": 553.6617431640625,
            "b": 249.74581909179688,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            242
          ]
        }
      ],
      "orig": "[75] Yumeng Zhang, Shi Gong, Kaixin Xiong, Xiaoqing Ye, Xiao Tan, Fan Wang, Jizhou Huang, Hua Wu, and Haifeng Wang. Bevworld: A multimodal world model for autonomous driving via unified bev latent space. arXiv preprint arXiv:2407.05679, 2024.",
      "text": "[75] Yumeng Zhang, Shi Gong, Kaixin Xiong, Xiaoqing Ye, Xiao Tan, Fan Wang, Jizhou Huang, Hua Wu, and Haifeng Wang. Bevworld: A multimodal world model for autonomous driving via unified bev latent space. arXiv preprint arXiv:2407.05679, 2024.",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/264",
      "parent": {
        "$ref": "#/groups/5"
      },
      "children": [],
      "label": "list_item",
      "prov": [
        {
          "page_no": 12,
          "bbox": {
            "l": 318.0389709472656,
            "t": 245.3981170654297,
            "r": 553.4833374023438,
            "b": 205.21694946289062,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            199
          ]
        }
      ],
      "orig": "[76] Wenzhao Zheng, Weiliang Chen, Yuanhui Huang, Borui Zhang, Yueqi Duan, and Jiwen Lu. Occworld: Learning a 3d occupancy world model for autonomous driving. arXiv preprint arXiv:2311.16038, 2023. 2",
      "text": "[76] Wenzhao Zheng, Weiliang Chen, Yuanhui Huang, Borui Zhang, Yueqi Duan, and Jiwen Lu. Occworld: Learning a 3d occupancy world model for autonomous driving. arXiv preprint arXiv:2311.16038, 2023. 2",
      "enumerated": false,
      "marker": "-"
    },
    {
      "self_ref": "#/texts/265",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "section_header",
      "prov": [
        {
          "page_no": 13,
          "bbox": {
            "l": 61.370845794677734,
            "t": 720.0292358398438,
            "r": 550.5046997070312,
            "b": 689.60107421875,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            101
          ]
        }
      ],
      "orig": "DrivingGPT: Unifying Driving World Modeling and Planning with Multi-modal Autoregressive Transformers",
      "text": "DrivingGPT: Unifying Driving World Modeling and Planning with Multi-modal Autoregressive Transformers",
      "level": 1
    },
    {
      "self_ref": "#/texts/266",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "section_header",
      "prov": [
        {
          "page_no": 13,
          "bbox": {
            "l": 237.0745391845703,
            "t": 677.592529296875,
            "r": 375.2284240722656,
            "b": 664.6809692382812,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            22
          ]
        }
      ],
      "orig": "Supplementary Material",
      "text": "Supplementary Material",
      "level": 1
    },
    {
      "self_ref": "#/texts/267",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "section_header",
      "prov": [
        {
          "page_no": 13,
          "bbox": {
            "l": 58.60759735107422,
            "t": 648.653076171875,
            "r": 294.19677734375,
            "b": 626.5556640625,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            46
          ]
        }
      ],
      "orig": "A. Refining Video Generation with SVD Decoder.",
      "text": "A. Refining Video Generation with SVD Decoder.",
      "level": 1
    },
    {
      "self_ref": "#/texts/268",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 13,
          "bbox": {
            "l": 58.69925308227539,
            "t": 614.8255004882812,
            "r": 294.77301025390625,
            "b": 547.2891235351562,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            340
          ]
        }
      ],
      "orig": "Since independently decoding each frame-token to pixel space leads to temporally inconsistent video outputs, we further employ a video diffusion decoder [1] conditioned on frame-tokens to enable high-resolution and temporally consistent generation. As shown in Figure 6, we present four 32-second, 1024\u00d7576 examples from the NuPlan dataset.",
      "text": "Since independently decoding each frame-token to pixel space leads to temporally inconsistent video outputs, we further employ a video diffusion decoder [1] conditioned on frame-tokens to enable high-resolution and temporally consistent generation. As shown in Figure 6, we present four 32-second, 1024\u00d7576 examples from the NuPlan dataset."
    },
    {
      "self_ref": "#/texts/269",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 13,
          "bbox": {
            "l": 58.54979705810547,
            "t": 544.5294799804688,
            "r": 294.76300048828125,
            "b": 500.4151306152344,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            211
          ]
        }
      ],
      "orig": "During training, our video diffusion model is conditioned on image tokens generated by discretizing the input images. During inference, the model is conditioned on the predicted image tokens from the DrivingGPT.",
      "text": "During training, our video diffusion model is conditioned on image tokens generated by discretizing the input images. During inference, the model is conditioned on the predicted image tokens from the DrivingGPT."
    },
    {
      "self_ref": "#/texts/270",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 13,
          "bbox": {
            "l": 58.549781799316406,
            "t": 497.66546630859375,
            "r": 294.6036071777344,
            "b": 244.6954345703125,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            1240
          ]
        }
      ],
      "orig": "During the inference, we first leverage the autoregressive nature of DrivingGPT for generating tokens for long video sequences beyond the training context length. We generate 64 frames in total for each video clip which spans 32 seconds. We predict tokens of the next 8 frames by conditioning on tokens of the last 8 frames of generated video and repeat the procedure until all 64 frames are generated. After obtaining tokens for the generated video clips, we use the VQ-VAE decoder [49] for converting the discrete tokens into continuous convolutional features. Since our autoregressive transformer models the driving video at a resolution of 288 \u00d7 512 while the SVD decoder models the driving video at a resolution of 576 \u00d7 1024, we upsample the convolutional features from the VQ-VAE decoder to align with the resolution of SVD. The convolutional features are dimensionally reduced to 4 dimensions using convolutional layers, which is then concatenated with the Gaussian noise as the conditional input to the denoising UNet. During the refinement stage, we decode 16 consecutive frames with the fine-tuned SVD decoder once, and then repeat this decoding process four times consecutively, ultimately generating a total video of 64 frames.",
      "text": "During the inference, we first leverage the autoregressive nature of DrivingGPT for generating tokens for long video sequences beyond the training context length. We generate 64 frames in total for each video clip which spans 32 seconds. We predict tokens of the next 8 frames by conditioning on tokens of the last 8 frames of generated video and repeat the procedure until all 64 frames are generated. After obtaining tokens for the generated video clips, we use the VQ-VAE decoder [49] for converting the discrete tokens into continuous convolutional features. Since our autoregressive transformer models the driving video at a resolution of 288 \u00d7 512 while the SVD decoder models the driving video at a resolution of 576 \u00d7 1024, we upsample the convolutional features from the VQ-VAE decoder to align with the resolution of SVD. The convolutional features are dimensionally reduced to 4 dimensions using convolutional layers, which is then concatenated with the Gaussian noise as the conditional input to the denoising UNet. During the refinement stage, we decode 16 consecutive frames with the fine-tuned SVD decoder once, and then repeat this decoding process four times consecutively, ultimately generating a total video of 64 frames."
    },
    {
      "self_ref": "#/texts/271",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "section_header",
      "prov": [
        {
          "page_no": 13,
          "bbox": {
            "l": 58.691253662109375,
            "t": 229.46694946289062,
            "r": 294.54339599609375,
            "b": 207.30975341796875,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            57
          ]
        }
      ],
      "orig": "B. The Effect of Sampling Parameters on Video Generation.",
      "text": "B. The Effect of Sampling Parameters on Video Generation.",
      "level": 1
    },
    {
      "self_ref": "#/texts/272",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 13,
          "bbox": {
            "l": 58.62948226928711,
            "t": 195.639404296875,
            "r": 294.76300048828125,
            "b": 106.69340515136719,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            432
          ]
        }
      ],
      "orig": "As shown in Figure 7, we compare the impact of different sampling parameters, top-k, on generation. We find that the smaller the value of k, the smoother the image becomes; for example, the road appears flatter without cracks, and the shape of the car is smoother. Conversely, when k is larger, the image contains more detailed information; the cracks in the road are more pronounced, and the shape of the car is somewhat distorted.",
      "text": "As shown in Figure 7, we compare the impact of different sampling parameters, top-k, on generation. We find that the smaller the value of k, the smoother the image becomes; for example, the road appears flatter without cracks, and the shape of the car is smoother. Conversely, when k is larger, the image contains more detailed information; the cracks in the road are more pronounced, and the shape of the car is somewhat distorted."
    },
    {
      "self_ref": "#/texts/273",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "page_footer",
      "prov": [
        {
          "page_no": 13,
          "bbox": {
            "l": 304.61480712890625,
            "t": 57.846641540527344,
            "r": 307.4342346191406,
            "b": 51.11192321777344,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            1
          ]
        }
      ],
      "orig": "1",
      "text": "1"
    },
    {
      "self_ref": "#/texts/274",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "caption",
      "prov": [
        {
          "page_no": 14,
          "bbox": {
            "l": 58.580726623535156,
            "t": 185.8887481689453,
            "r": 553.3197021484375,
            "b": 156.25828552246094,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            288
          ]
        }
      ],
      "orig": "Figure 6. Visualization of long video generation refined by SVD decoder. We present four 32-second, 1024\u00d7576 examples from the NuPlan dataset. The predicted discrete tokens are of lower resolution, but by leveraging the SVD decoder, we can decode them to generate high-resolution outputs.",
      "text": "Figure 6. Visualization of long video generation refined by SVD decoder. We present four 32-second, 1024\u00d7576 examples from the NuPlan dataset. The predicted discrete tokens are of lower resolution, but by leveraging the SVD decoder, we can decode them to generate high-resolution outputs."
    },
    {
      "self_ref": "#/texts/275",
      "parent": {
        "$ref": "#/pictures/9"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 14,
          "bbox": {
            "l": 242.0680694580078,
            "t": 600.6682739257812,
            "r": 254.8157196044922,
            "b": 594.9097290039062,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "+4s",
      "text": "+4s"
    },
    {
      "self_ref": "#/texts/276",
      "parent": {
        "$ref": "#/pictures/9"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 14,
          "bbox": {
            "l": 340.3387145996094,
            "t": 600.6682739257812,
            "r": 353.0863952636719,
            "b": 594.90185546875,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "+8s",
      "text": "+8s"
    },
    {
      "self_ref": "#/texts/277",
      "parent": {
        "$ref": "#/pictures/9"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 14,
          "bbox": {
            "l": 433.857177734375,
            "t": 600.9569702148438,
            "r": 450.9434814453125,
            "b": 595.1984252929688,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            4
          ]
        }
      ],
      "orig": "+12s",
      "text": "+12s"
    },
    {
      "self_ref": "#/texts/278",
      "parent": {
        "$ref": "#/pictures/9"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 14,
          "bbox": {
            "l": 530.783203125,
            "t": 600.6682739257812,
            "r": 547.8695068359375,
            "b": 594.9097290039062,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            4
          ]
        }
      ],
      "orig": "+16s",
      "text": "+16s"
    },
    {
      "self_ref": "#/texts/279",
      "parent": {
        "$ref": "#/pictures/9"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 14,
          "bbox": {
            "l": 242.0680694580078,
            "t": 545.9695434570312,
            "r": 259.15435791015625,
            "b": 540.2109985351562,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            4
          ]
        }
      ],
      "orig": "+20s",
      "text": "+20s"
    },
    {
      "self_ref": "#/texts/280",
      "parent": {
        "$ref": "#/pictures/9"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 14,
          "bbox": {
            "l": 338.8802490234375,
            "t": 545.9695434570312,
            "r": 355.966552734375,
            "b": 540.2109985351562,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            4
          ]
        }
      ],
      "orig": "+24s",
      "text": "+24s"
    },
    {
      "self_ref": "#/texts/281",
      "parent": {
        "$ref": "#/pictures/9"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 14,
          "bbox": {
            "l": 433.110595703125,
            "t": 545.9695434570312,
            "r": 450.1968994140625,
            "b": 540.203125,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            4
          ]
        }
      ],
      "orig": "+28s",
      "text": "+28s"
    },
    {
      "self_ref": "#/texts/282",
      "parent": {
        "$ref": "#/pictures/9"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 14,
          "bbox": {
            "l": 530.3529052734375,
            "t": 545.9695434570312,
            "r": 547.439208984375,
            "b": 540.2109985351562,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            4
          ]
        }
      ],
      "orig": "+32s",
      "text": "+32s"
    },
    {
      "self_ref": "#/texts/283",
      "parent": {
        "$ref": "#/pictures/9"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 14,
          "bbox": {
            "l": 143.10447692871094,
            "t": 573.31884765625,
            "r": 155.8521270751953,
            "b": 567.560302734375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "+0s",
      "text": "+0s"
    },
    {
      "self_ref": "#/texts/284",
      "parent": {
        "$ref": "#/pictures/9"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 14,
          "bbox": {
            "l": 143.10447692871094,
            "t": 457.17120361328125,
            "r": 155.8521270751953,
            "b": 451.4126892089844,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "+0s",
      "text": "+0s"
    },
    {
      "self_ref": "#/texts/285",
      "parent": {
        "$ref": "#/pictures/9"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 14,
          "bbox": {
            "l": 241.72059631347656,
            "t": 489.2026062011719,
            "r": 254.46824645996094,
            "b": 483.444091796875,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "+4s",
      "text": "+4s"
    },
    {
      "self_ref": "#/texts/286",
      "parent": {
        "$ref": "#/pictures/9"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 14,
          "bbox": {
            "l": 339.99127197265625,
            "t": 489.2025451660156,
            "r": 352.73895263671875,
            "b": 483.4361267089844,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "+8s",
      "text": "+8s"
    },
    {
      "self_ref": "#/texts/287",
      "parent": {
        "$ref": "#/pictures/9"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 14,
          "bbox": {
            "l": 433.14105224609375,
            "t": 489.04156494140625,
            "r": 450.22735595703125,
            "b": 483.2830505371094,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            4
          ]
        }
      ],
      "orig": "+12s",
      "text": "+12s"
    },
    {
      "self_ref": "#/texts/288",
      "parent": {
        "$ref": "#/pictures/9"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 14,
          "bbox": {
            "l": 530.435791015625,
            "t": 489.2026062011719,
            "r": 547.5220947265625,
            "b": 483.444091796875,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            4
          ]
        }
      ],
      "orig": "+16s",
      "text": "+16s"
    },
    {
      "self_ref": "#/texts/289",
      "parent": {
        "$ref": "#/pictures/9"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 14,
          "bbox": {
            "l": 242.0680694580078,
            "t": 433.74774169921875,
            "r": 259.15435791015625,
            "b": 427.9892272949219,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            4
          ]
        }
      ],
      "orig": "+20s",
      "text": "+20s"
    },
    {
      "self_ref": "#/texts/290",
      "parent": {
        "$ref": "#/pictures/9"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 14,
          "bbox": {
            "l": 338.8802490234375,
            "t": 433.74774169921875,
            "r": 355.966552734375,
            "b": 427.9892272949219,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            4
          ]
        }
      ],
      "orig": "+24s",
      "text": "+24s"
    },
    {
      "self_ref": "#/texts/291",
      "parent": {
        "$ref": "#/pictures/9"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 14,
          "bbox": {
            "l": 433.110595703125,
            "t": 433.74774169921875,
            "r": 450.1968994140625,
            "b": 427.9813232421875,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            4
          ]
        }
      ],
      "orig": "+28s",
      "text": "+28s"
    },
    {
      "self_ref": "#/texts/292",
      "parent": {
        "$ref": "#/pictures/9"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 14,
          "bbox": {
            "l": 530.3529052734375,
            "t": 433.74774169921875,
            "r": 547.439208984375,
            "b": 427.9892272949219,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            4
          ]
        }
      ],
      "orig": "+32s",
      "text": "+32s"
    },
    {
      "self_ref": "#/texts/293",
      "parent": {
        "$ref": "#/pictures/9"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 14,
          "bbox": {
            "l": 143.1991729736328,
            "t": 345.1980285644531,
            "r": 155.9468231201172,
            "b": 339.43951416015625,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "+0s",
      "text": "+0s"
    },
    {
      "self_ref": "#/texts/294",
      "parent": {
        "$ref": "#/pictures/9"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 14,
          "bbox": {
            "l": 241.72059631347656,
            "t": 376.4331359863281,
            "r": 254.46824645996094,
            "b": 370.67462158203125,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "+4s",
      "text": "+4s"
    },
    {
      "self_ref": "#/texts/295",
      "parent": {
        "$ref": "#/pictures/9"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 14,
          "bbox": {
            "l": 339.99127197265625,
            "t": 376.43310546875,
            "r": 352.73895263671875,
            "b": 370.66668701171875,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "+8s",
      "text": "+8s"
    },
    {
      "self_ref": "#/texts/296",
      "parent": {
        "$ref": "#/pictures/9"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 14,
          "bbox": {
            "l": 433.857177734375,
            "t": 376.53857421875,
            "r": 450.9434814453125,
            "b": 370.7800598144531,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            4
          ]
        }
      ],
      "orig": "+12s",
      "text": "+12s"
    },
    {
      "self_ref": "#/texts/297",
      "parent": {
        "$ref": "#/pictures/9"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 14,
          "bbox": {
            "l": 530.435791015625,
            "t": 376.4331359863281,
            "r": 547.5220947265625,
            "b": 370.67462158203125,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            4
          ]
        }
      ],
      "orig": "+16s",
      "text": "+16s"
    },
    {
      "self_ref": "#/texts/298",
      "parent": {
        "$ref": "#/pictures/9"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 14,
          "bbox": {
            "l": 241.8107147216797,
            "t": 322.7823486328125,
            "r": 258.8970031738281,
            "b": 317.0238342285156,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            4
          ]
        }
      ],
      "orig": "+20s",
      "text": "+20s"
    },
    {
      "self_ref": "#/texts/299",
      "parent": {
        "$ref": "#/pictures/9"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 14,
          "bbox": {
            "l": 338.6229248046875,
            "t": 322.7823486328125,
            "r": 355.709228515625,
            "b": 317.0238342285156,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            4
          ]
        }
      ],
      "orig": "+24s",
      "text": "+24s"
    },
    {
      "self_ref": "#/texts/300",
      "parent": {
        "$ref": "#/pictures/9"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 14,
          "bbox": {
            "l": 432.8532409667969,
            "t": 322.7823486328125,
            "r": 449.9395446777344,
            "b": 317.01593017578125,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            4
          ]
        }
      ],
      "orig": "+28s",
      "text": "+28s"
    },
    {
      "self_ref": "#/texts/301",
      "parent": {
        "$ref": "#/pictures/9"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 14,
          "bbox": {
            "l": 530.095703125,
            "t": 322.7823486328125,
            "r": 547.1820068359375,
            "b": 317.0238342285156,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            4
          ]
        }
      ],
      "orig": "+32s",
      "text": "+32s"
    },
    {
      "self_ref": "#/texts/302",
      "parent": {
        "$ref": "#/pictures/9"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 14,
          "bbox": {
            "l": 240.42965698242188,
            "t": 209.51272583007812,
            "r": 257.51593017578125,
            "b": 203.7541961669922,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            4
          ]
        }
      ],
      "orig": "+20s",
      "text": "+20s"
    },
    {
      "self_ref": "#/texts/303",
      "parent": {
        "$ref": "#/pictures/9"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 14,
          "bbox": {
            "l": 337.2418518066406,
            "t": 209.51272583007812,
            "r": 354.3281555175781,
            "b": 203.7541961669922,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            4
          ]
        }
      ],
      "orig": "+24s",
      "text": "+24s"
    },
    {
      "self_ref": "#/texts/304",
      "parent": {
        "$ref": "#/pictures/9"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 14,
          "bbox": {
            "l": 431.47216796875,
            "t": 209.51272583007812,
            "r": 448.5584716796875,
            "b": 203.74630737304688,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            4
          ]
        }
      ],
      "orig": "+28s",
      "text": "+28s"
    },
    {
      "self_ref": "#/texts/305",
      "parent": {
        "$ref": "#/pictures/9"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 14,
          "bbox": {
            "l": 528.7144775390625,
            "t": 209.51272583007812,
            "r": 545.80078125,
            "b": 203.7541961669922,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            4
          ]
        }
      ],
      "orig": "+32s",
      "text": "+32s"
    },
    {
      "self_ref": "#/texts/306",
      "parent": {
        "$ref": "#/pictures/9"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 14,
          "bbox": {
            "l": 242.28855895996094,
            "t": 264.8580322265625,
            "r": 255.0362091064453,
            "b": 259.0995178222656,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "+4s",
      "text": "+4s"
    },
    {
      "self_ref": "#/texts/307",
      "parent": {
        "$ref": "#/pictures/9"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 14,
          "bbox": {
            "l": 340.5592041015625,
            "t": 264.8579406738281,
            "r": 353.306884765625,
            "b": 259.0915222167969,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "+8s",
      "text": "+8s"
    },
    {
      "self_ref": "#/texts/308",
      "parent": {
        "$ref": "#/pictures/9"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 14,
          "bbox": {
            "l": 434.42510986328125,
            "t": 264.96343994140625,
            "r": 451.51141357421875,
            "b": 259.2049255371094,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            4
          ]
        }
      ],
      "orig": "+12s",
      "text": "+12s"
    },
    {
      "self_ref": "#/texts/309",
      "parent": {
        "$ref": "#/pictures/9"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 14,
          "bbox": {
            "l": 531.003662109375,
            "t": 264.8580322265625,
            "r": 548.0899658203125,
            "b": 259.0995178222656,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            4
          ]
        }
      ],
      "orig": "+16s",
      "text": "+16s"
    },
    {
      "self_ref": "#/texts/310",
      "parent": {
        "$ref": "#/pictures/9"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 14,
          "bbox": {
            "l": 141.9048309326172,
            "t": 233.22482299804688,
            "r": 154.65248107910156,
            "b": 227.46629333496094,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "+0s",
      "text": "+0s"
    },
    {
      "self_ref": "#/texts/311",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "page_footer",
      "prov": [
        {
          "page_no": 14,
          "bbox": {
            "l": 303.80792236328125,
            "t": 57.846710205078125,
            "r": 308.24127197265625,
            "b": 51.11199188232422,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            1
          ]
        }
      ],
      "orig": "2",
      "text": "2"
    },
    {
      "self_ref": "#/texts/312",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 15,
          "bbox": {
            "l": 71.1943359375,
            "t": 629.9597778320312,
            "r": 88.46080780029297,
            "b": 622.0894775390625,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "K=1",
      "text": "K=1"
    },
    {
      "self_ref": "#/texts/313",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 15,
          "bbox": {
            "l": 71.1943359375,
            "t": 547.7996826171875,
            "r": 90.02610778808594,
            "b": 539.841796875,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "K=5",
      "text": "K=5"
    },
    {
      "self_ref": "#/texts/314",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 15,
          "bbox": {
            "l": 71.1943359375,
            "t": 465.70526123046875,
            "r": 96.10888671875,
            "b": 457.71453857421875,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            4
          ]
        }
      ],
      "orig": "K=25",
      "text": "K=25"
    },
    {
      "self_ref": "#/texts/315",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 15,
          "bbox": {
            "l": 67.91067504882812,
            "t": 382.9038391113281,
            "r": 98.90800476074219,
            "b": 374.9131164550781,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            5
          ]
        }
      ],
      "orig": "K=125",
      "text": "K=125"
    },
    {
      "self_ref": "#/texts/316",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 15,
          "bbox": {
            "l": 68.76538848876953,
            "t": 299.4282531738281,
            "r": 99.76272583007812,
            "b": 291.4375305175781,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            5
          ]
        }
      ],
      "orig": "K=625",
      "text": "K=625"
    },
    {
      "self_ref": "#/texts/317",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 15,
          "bbox": {
            "l": 66.26295471191406,
            "t": 217.97520446777344,
            "r": 103.25550079345703,
            "b": 209.98451232910156,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            6
          ]
        }
      ],
      "orig": "K=2000",
      "text": "K=2000"
    },
    {
      "self_ref": "#/texts/318",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "caption",
      "prov": [
        {
          "page_no": 15,
          "bbox": {
            "l": 58.544830322265625,
            "t": 159.0487823486328,
            "r": 553.4183349609375,
            "b": 118.6972427368164,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            499
          ]
        }
      ],
      "orig": "Figure 7. Visualization of video generation under different sampling parameters. we compare the impact of different sampling parameters, such as top-k, on generation. We find that the smaller the value of k, the smoother the image becomes; for example, the road appears flatter without cracks, and the shape of the car is smoother. Conversely, when k is larger, the image contains more detailed information; the cracks in the road are more pronounced, and the shape of the car is somewhat distorted.",
      "text": "Figure 7. Visualization of video generation under different sampling parameters. we compare the impact of different sampling parameters, such as top-k, on generation. We find that the smaller the value of k, the smoother the image becomes; for example, the road appears flatter without cracks, and the shape of the car is smoother. Conversely, when k is larger, the image contains more detailed information; the cracks in the road are more pronounced, and the shape of the car is somewhat distorted."
    },
    {
      "self_ref": "#/texts/319",
      "parent": {
        "$ref": "#/pictures/10"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 15,
          "bbox": {
            "l": 193.2434539794922,
            "t": 677.0411987304688,
            "r": 211.9307403564453,
            "b": 669.2037353515625,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "T+4",
      "text": "T+4"
    },
    {
      "self_ref": "#/texts/320",
      "parent": {
        "$ref": "#/pictures/10"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 15,
          "bbox": {
            "l": 324.0911865234375,
            "t": 677.10498046875,
            "r": 342.80035400390625,
            "b": 669.1142578125,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "T+6",
      "text": "T+6"
    },
    {
      "self_ref": "#/texts/321",
      "parent": {
        "$ref": "#/pictures/10"
      },
      "children": [],
      "label": "text",
      "prov": [
        {
          "page_no": 15,
          "bbox": {
            "l": 470.5843811035156,
            "t": 677.10498046875,
            "r": 489.3154296875,
            "b": 669.1142578125,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "T+8",
      "text": "T+8"
    },
    {
      "self_ref": "#/texts/322",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "page_footer",
      "prov": [
        {
          "page_no": 15,
          "bbox": {
            "l": 303.9374084472656,
            "t": 57.846702575683594,
            "r": 307.8128356933594,
            "b": 50.98247146606445,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            1
          ]
        }
      ],
      "orig": "3",
      "text": "3"
    }
  ],
  "pictures": [
    {
      "self_ref": "#/pictures/0",
      "parent": {
        "$ref": "#/body"
      },
      "children": [
        {
          "$ref": "#/texts/6"
        },
        {
          "$ref": "#/texts/7"
        },
        {
          "$ref": "#/texts/8"
        },
        {
          "$ref": "#/texts/9"
        },
        {
          "$ref": "#/texts/10"
        },
        {
          "$ref": "#/texts/11"
        },
        {
          "$ref": "#/texts/12"
        },
        {
          "$ref": "#/texts/13"
        },
        {
          "$ref": "#/texts/14"
        },
        {
          "$ref": "#/texts/15"
        },
        {
          "$ref": "#/texts/16"
        },
        {
          "$ref": "#/texts/17"
        },
        {
          "$ref": "#/texts/18"
        },
        {
          "$ref": "#/texts/19"
        },
        {
          "$ref": "#/texts/20"
        },
        {
          "$ref": "#/texts/21"
        },
        {
          "$ref": "#/texts/22"
        },
        {
          "$ref": "#/texts/23"
        },
        {
          "$ref": "#/texts/24"
        },
        {
          "$ref": "#/texts/25"
        },
        {
          "$ref": "#/texts/26"
        },
        {
          "$ref": "#/texts/27"
        },
        {
          "$ref": "#/texts/28"
        }
      ],
      "label": "picture",
      "prov": [
        {
          "page_no": 1,
          "bbox": {
            "l": 65.25471496582031,
            "t": 549.0750732421875,
            "r": 544.9888305664062,
            "b": 378.83782958984375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            496
          ]
        }
      ],
      "captions": [
        {
          "$ref": "#/texts/5"
        }
      ],
      "references": [],
      "footnotes": [],
      "annotations": []
    },
    {
      "self_ref": "#/pictures/1",
      "parent": {
        "$ref": "#/body"
      },
      "children": [
        {
          "$ref": "#/texts/62"
        },
        {
          "$ref": "#/texts/63"
        },
        {
          "$ref": "#/texts/64"
        },
        {
          "$ref": "#/texts/65"
        },
        {
          "$ref": "#/texts/66"
        },
        {
          "$ref": "#/texts/67"
        },
        {
          "$ref": "#/texts/68"
        },
        {
          "$ref": "#/texts/69"
        },
        {
          "$ref": "#/texts/70"
        },
        {
          "$ref": "#/texts/71"
        },
        {
          "$ref": "#/texts/72"
        },
        {
          "$ref": "#/texts/73"
        },
        {
          "$ref": "#/texts/74"
        },
        {
          "$ref": "#/texts/75"
        },
        {
          "$ref": "#/texts/76"
        },
        {
          "$ref": "#/texts/77"
        },
        {
          "$ref": "#/texts/78"
        },
        {
          "$ref": "#/texts/79"
        },
        {
          "$ref": "#/texts/80"
        },
        {
          "$ref": "#/texts/81"
        },
        {
          "$ref": "#/texts/82"
        },
        {
          "$ref": "#/texts/83"
        },
        {
          "$ref": "#/texts/84"
        },
        {
          "$ref": "#/texts/85"
        },
        {
          "$ref": "#/texts/86"
        },
        {
          "$ref": "#/texts/87"
        },
        {
          "$ref": "#/texts/88"
        },
        {
          "$ref": "#/texts/89"
        },
        {
          "$ref": "#/texts/90"
        },
        {
          "$ref": "#/texts/91"
        },
        {
          "$ref": "#/texts/92"
        },
        {
          "$ref": "#/texts/93"
        },
        {
          "$ref": "#/texts/94"
        },
        {
          "$ref": "#/texts/95"
        },
        {
          "$ref": "#/texts/96"
        },
        {
          "$ref": "#/texts/97"
        },
        {
          "$ref": "#/texts/98"
        },
        {
          "$ref": "#/texts/99"
        },
        {
          "$ref": "#/texts/100"
        },
        {
          "$ref": "#/texts/101"
        },
        {
          "$ref": "#/texts/102"
        },
        {
          "$ref": "#/texts/103"
        }
      ],
      "label": "picture",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 60.96649932861328,
            "t": 699.2562255859375,
            "r": 548.1210327148438,
            "b": 505.87628173828125,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            499
          ]
        }
      ],
      "captions": [
        {
          "$ref": "#/texts/61"
        }
      ],
      "references": [],
      "footnotes": [],
      "annotations": []
    },
    {
      "self_ref": "#/pictures/2",
      "parent": {
        "$ref": "#/body"
      },
      "children": [
        {
          "$ref": "#/texts/118"
        },
        {
          "$ref": "#/texts/119"
        },
        {
          "$ref": "#/texts/120"
        },
        {
          "$ref": "#/texts/121"
        },
        {
          "$ref": "#/texts/122"
        },
        {
          "$ref": "#/texts/123"
        },
        {
          "$ref": "#/texts/124"
        }
      ],
      "label": "picture",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 57.525543212890625,
            "t": 718.1295776367188,
            "r": 304.3444519042969,
            "b": 443.1994323730469,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            412
          ]
        }
      ],
      "captions": [
        {
          "$ref": "#/texts/117"
        }
      ],
      "references": [],
      "footnotes": [],
      "annotations": []
    },
    {
      "self_ref": "#/pictures/3",
      "parent": {
        "$ref": "#/body"
      },
      "children": [
        {
          "$ref": "#/texts/125"
        },
        {
          "$ref": "#/texts/126"
        },
        {
          "$ref": "#/texts/127"
        },
        {
          "$ref": "#/texts/128"
        },
        {
          "$ref": "#/texts/129"
        },
        {
          "$ref": "#/texts/130"
        },
        {
          "$ref": "#/texts/131"
        }
      ],
      "label": "picture",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 309.6220397949219,
            "t": 718.1196899414062,
            "r": 553.99365234375,
            "b": 433.6649169921875,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            0
          ]
        }
      ],
      "captions": [],
      "references": [],
      "footnotes": [],
      "annotations": []
    },
    {
      "self_ref": "#/pictures/4",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "picture",
      "prov": [
        {
          "page_no": 7,
          "bbox": {
            "l": 57.111263275146484,
            "t": 720.7886352539062,
            "r": 554.148681640625,
            "b": 535.4454956054688,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            335
          ]
        }
      ],
      "captions": [
        {
          "$ref": "#/texts/154"
        }
      ],
      "references": [],
      "footnotes": [],
      "annotations": []
    },
    {
      "self_ref": "#/pictures/5",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "picture",
      "prov": [
        {
          "page_no": 8,
          "bbox": {
            "l": 61.86454772949219,
            "t": 718.041015625,
            "r": 177.6021270751953,
            "b": 601.6832885742188,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            0
          ]
        }
      ],
      "captions": [],
      "references": [],
      "footnotes": [],
      "annotations": []
    },
    {
      "self_ref": "#/pictures/6",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "picture",
      "prov": [
        {
          "page_no": 8,
          "bbox": {
            "l": 187.5245361328125,
            "t": 717.489501953125,
            "r": 302.9590148925781,
            "b": 601.7793579101562,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            0
          ]
        }
      ],
      "captions": [],
      "references": [],
      "footnotes": [],
      "annotations": []
    },
    {
      "self_ref": "#/pictures/7",
      "parent": {
        "$ref": "#/body"
      },
      "children": [
        {
          "$ref": "#/texts/166"
        }
      ],
      "label": "picture",
      "prov": [
        {
          "page_no": 8,
          "bbox": {
            "l": 312.63623046875,
            "t": 718.2891845703125,
            "r": 427.8100280761719,
            "b": 589.8529663085938,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            0
          ]
        }
      ],
      "captions": [],
      "references": [],
      "footnotes": [],
      "annotations": []
    },
    {
      "self_ref": "#/pictures/8",
      "parent": {
        "$ref": "#/body"
      },
      "children": [
        {
          "$ref": "#/texts/168"
        }
      ],
      "label": "picture",
      "prov": [
        {
          "page_no": 8,
          "bbox": {
            "l": 437.6222839355469,
            "t": 718.2706909179688,
            "r": 554.0065307617188,
            "b": 590.3636474609375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            310
          ]
        }
      ],
      "captions": [
        {
          "$ref": "#/texts/167"
        }
      ],
      "references": [],
      "footnotes": [],
      "annotations": []
    },
    {
      "self_ref": "#/pictures/9",
      "parent": {
        "$ref": "#/body"
      },
      "children": [
        {
          "$ref": "#/texts/275"
        },
        {
          "$ref": "#/texts/276"
        },
        {
          "$ref": "#/texts/277"
        },
        {
          "$ref": "#/texts/278"
        },
        {
          "$ref": "#/texts/279"
        },
        {
          "$ref": "#/texts/280"
        },
        {
          "$ref": "#/texts/281"
        },
        {
          "$ref": "#/texts/282"
        },
        {
          "$ref": "#/texts/283"
        },
        {
          "$ref": "#/texts/284"
        },
        {
          "$ref": "#/texts/285"
        },
        {
          "$ref": "#/texts/286"
        },
        {
          "$ref": "#/texts/287"
        },
        {
          "$ref": "#/texts/288"
        },
        {
          "$ref": "#/texts/289"
        },
        {
          "$ref": "#/texts/290"
        },
        {
          "$ref": "#/texts/291"
        },
        {
          "$ref": "#/texts/292"
        },
        {
          "$ref": "#/texts/293"
        },
        {
          "$ref": "#/texts/294"
        },
        {
          "$ref": "#/texts/295"
        },
        {
          "$ref": "#/texts/296"
        },
        {
          "$ref": "#/texts/297"
        },
        {
          "$ref": "#/texts/298"
        },
        {
          "$ref": "#/texts/299"
        },
        {
          "$ref": "#/texts/300"
        },
        {
          "$ref": "#/texts/301"
        },
        {
          "$ref": "#/texts/302"
        },
        {
          "$ref": "#/texts/303"
        },
        {
          "$ref": "#/texts/304"
        },
        {
          "$ref": "#/texts/305"
        },
        {
          "$ref": "#/texts/306"
        },
        {
          "$ref": "#/texts/307"
        },
        {
          "$ref": "#/texts/308"
        },
        {
          "$ref": "#/texts/309"
        },
        {
          "$ref": "#/texts/310"
        }
      ],
      "label": "picture",
      "prov": [
        {
          "page_no": 14,
          "bbox": {
            "l": 57.79072189331055,
            "t": 645.6195068359375,
            "r": 552.60498046875,
            "b": 199.36407470703125,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            288
          ]
        }
      ],
      "captions": [
        {
          "$ref": "#/texts/274"
        }
      ],
      "references": [],
      "footnotes": [],
      "annotations": []
    },
    {
      "self_ref": "#/pictures/10",
      "parent": {
        "$ref": "#/body"
      },
      "children": [
        {
          "$ref": "#/texts/319"
        },
        {
          "$ref": "#/texts/320"
        },
        {
          "$ref": "#/texts/321"
        }
      ],
      "label": "picture",
      "prov": [
        {
          "page_no": 15,
          "bbox": {
            "l": 113.73458099365234,
            "t": 678.7901000976562,
            "r": 554.05908203125,
            "b": 170.087158203125,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            499
          ]
        }
      ],
      "captions": [
        {
          "$ref": "#/texts/318"
        }
      ],
      "references": [],
      "footnotes": [],
      "annotations": []
    }
  ],
  "tables": [
    {
      "self_ref": "#/tables/0",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "table",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 150.40708923339844,
            "t": 720.6463623046875,
            "r": 461.4490661621094,
            "b": 650.050537109375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            0
          ]
        }
      ],
      "captions": [
        {
          "$ref": "#/texts/140"
        }
      ],
      "references": [],
      "footnotes": [],
      "data": {
        "table_cells": [
          {
            "bbox": {
              "l": 176.11248779296875,
              "t": 715.1280517578125,
              "r": 419.4689636230469,
              "b": 706.181640625,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 0,
            "end_row_offset_idx": 1,
            "start_col_offset_idx": 0,
            "end_col_offset_idx": 1,
            "text": "Model Type Fine-tune Dataset FVD\u2193",
            "column_header": true,
            "row_header": false,
            "row_section": false
          },
          {
            "bbox": {
              "l": 432.8634033203125,
              "t": 715.1280517578125,
              "r": 454.6719665527344,
              "b": 706.3011474609375,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 0,
            "end_row_offset_idx": 1,
            "start_col_offset_idx": 1,
            "end_col_offset_idx": 2,
            "text": "FID\u2193",
            "column_header": true,
            "row_header": false,
            "row_section": false
          },
          {
            "bbox": {
              "l": 172.93443298339844,
              "t": 698.3103637695312,
              "r": 454.7364807128906,
              "b": 689.9517822265625,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 1,
            "end_row_offset_idx": 2,
            "start_col_offset_idx": 0,
            "end_col_offset_idx": 1,
            "text": "SVD [1] Diffusion - 483.76 27.80",
            "column_header": false,
            "row_header": false,
            "row_section": false
          },
          {
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 1,
            "end_row_offset_idx": 2,
            "start_col_offset_idx": 1,
            "end_col_offset_idx": 2,
            "text": "",
            "column_header": false,
            "row_header": false,
            "row_section": false
          },
          {
            "bbox": {
              "l": 157.29795837402344,
              "t": 686.5844116210938,
              "r": 454.43243408203125,
              "b": 677.6181030273438,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 2,
            "end_row_offset_idx": 3,
            "start_col_offset_idx": 0,
            "end_col_offset_idx": 1,
            "text": "CogvideoX [71] Diffusion - 848.87 31.78",
            "column_header": false,
            "row_header": false,
            "row_section": false
          },
          {
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 2,
            "end_row_offset_idx": 3,
            "start_col_offset_idx": 1,
            "end_col_offset_idx": 2,
            "text": "",
            "column_header": false,
            "row_header": false,
            "row_section": false
          },
          {
            "bbox": {
              "l": 172.93443298339844,
              "t": 674.918212890625,
              "r": 454.29815673828125,
              "b": 666.519775390625,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 3,
            "end_row_offset_idx": 4,
            "start_col_offset_idx": 0,
            "end_col_offset_idx": 1,
            "text": "SVD [1] Diffusion navtrain 227.54 24.03",
            "column_header": false,
            "row_header": false,
            "row_section": false
          },
          {
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 3,
            "end_row_offset_idx": 4,
            "start_col_offset_idx": 1,
            "end_col_offset_idx": 2,
            "text": "",
            "column_header": false,
            "row_header": false,
            "row_section": false
          },
          {
            "bbox": {
              "l": 164.91041564941406,
              "t": 663.1524047851562,
              "r": 359.5596923828125,
              "b": 654.1860961914062,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 4,
            "end_row_offset_idx": 5,
            "start_col_offset_idx": 0,
            "end_col_offset_idx": 1,
            "text": "DrivingGPT Autoregressive navtrain",
            "column_header": false,
            "row_header": false,
            "row_section": false
          },
          {
            "bbox": {
              "l": 393.8595886230469,
              "t": 663.2022094726562,
              "r": 454.701171875,
              "b": 656.2283935546875,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 4,
            "end_row_offset_idx": 5,
            "start_col_offset_idx": 1,
            "end_col_offset_idx": 2,
            "text": "142.61 12.78",
            "column_header": false,
            "row_header": false,
            "row_section": false
          }
        ],
        "num_rows": 5,
        "num_cols": 2,
        "grid": [
          [
            {
              "bbox": {
                "l": 176.11248779296875,
                "t": 715.1280517578125,
                "r": 419.4689636230469,
                "b": 706.181640625,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 0,
              "end_row_offset_idx": 1,
              "start_col_offset_idx": 0,
              "end_col_offset_idx": 1,
              "text": "Model Type Fine-tune Dataset FVD\u2193",
              "column_header": true,
              "row_header": false,
              "row_section": false
            },
            {
              "bbox": {
                "l": 432.8634033203125,
                "t": 715.1280517578125,
                "r": 454.6719665527344,
                "b": 706.3011474609375,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 0,
              "end_row_offset_idx": 1,
              "start_col_offset_idx": 1,
              "end_col_offset_idx": 2,
              "text": "FID\u2193",
              "column_header": true,
              "row_header": false,
              "row_section": false
            }
          ],
          [
            {
              "bbox": {
                "l": 172.93443298339844,
                "t": 698.3103637695312,
                "r": 454.7364807128906,
                "b": 689.9517822265625,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 1,
              "end_row_offset_idx": 2,
              "start_col_offset_idx": 0,
              "end_col_offset_idx": 1,
              "text": "SVD [1] Diffusion - 483.76 27.80",
              "column_header": false,
              "row_header": false,
              "row_section": false
            },
            {
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 1,
              "end_row_offset_idx": 2,
              "start_col_offset_idx": 1,
              "end_col_offset_idx": 2,
              "text": "",
              "column_header": false,
              "row_header": false,
              "row_section": false
            }
          ],
          [
            {
              "bbox": {
                "l": 157.29795837402344,
                "t": 686.5844116210938,
                "r": 454.43243408203125,
                "b": 677.6181030273438,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 2,
              "end_row_offset_idx": 3,
              "start_col_offset_idx": 0,
              "end_col_offset_idx": 1,
              "text": "CogvideoX [71] Diffusion - 848.87 31.78",
              "column_header": false,
              "row_header": false,
              "row_section": false
            },
            {
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 2,
              "end_row_offset_idx": 3,
              "start_col_offset_idx": 1,
              "end_col_offset_idx": 2,
              "text": "",
              "column_header": false,
              "row_header": false,
              "row_section": false
            }
          ],
          [
            {
              "bbox": {
                "l": 172.93443298339844,
                "t": 674.918212890625,
                "r": 454.29815673828125,
                "b": 666.519775390625,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 3,
              "end_row_offset_idx": 4,
              "start_col_offset_idx": 0,
              "end_col_offset_idx": 1,
              "text": "SVD [1] Diffusion navtrain 227.54 24.03",
              "column_header": false,
              "row_header": false,
              "row_section": false
            },
            {
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 3,
              "end_row_offset_idx": 4,
              "start_col_offset_idx": 1,
              "end_col_offset_idx": 2,
              "text": "",
              "column_header": false,
              "row_header": false,
              "row_section": false
            }
          ],
          [
            {
              "bbox": {
                "l": 164.91041564941406,
                "t": 663.1524047851562,
                "r": 359.5596923828125,
                "b": 654.1860961914062,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 4,
              "end_row_offset_idx": 5,
              "start_col_offset_idx": 0,
              "end_col_offset_idx": 1,
              "text": "DrivingGPT Autoregressive navtrain",
              "column_header": false,
              "row_header": false,
              "row_section": false
            },
            {
              "bbox": {
                "l": 393.8595886230469,
                "t": 663.2022094726562,
                "r": 454.701171875,
                "b": 656.2283935546875,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 4,
              "end_row_offset_idx": 5,
              "start_col_offset_idx": 1,
              "end_col_offset_idx": 2,
              "text": "142.61 12.78",
              "column_header": false,
              "row_header": false,
              "row_section": false
            }
          ]
        ]
      }
    },
    {
      "self_ref": "#/tables/1",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "table",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 318.5674743652344,
            "t": 384.4740295410156,
            "r": 553.8386840820312,
            "b": 320.3151550292969,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            0
          ]
        }
      ],
      "captions": [
        {
          "$ref": "#/texts/149"
        }
      ],
      "references": [],
      "footnotes": [],
      "data": {
        "table_cells": [
          {
            "bbox": {
              "l": 335.6002197265625,
              "t": 380.2478332519531,
              "r": 548.1788330078125,
              "b": 374.28094482421875,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 0,
            "end_row_offset_idx": 1,
            "start_col_offset_idx": 0,
            "end_col_offset_idx": 1,
            "text": "Model Metric 16 Frames 32 Frames 64 Frames",
            "column_header": true,
            "row_header": false,
            "row_section": false
          },
          {
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 0,
            "end_row_offset_idx": 1,
            "start_col_offset_idx": 1,
            "end_col_offset_idx": 2,
            "text": "",
            "column_header": false,
            "row_header": false,
            "row_section": false
          },
          {
            "bbox": {
              "l": 385.2585754394531,
              "t": 365.99957275390625,
              "r": 538.4734497070312,
              "b": 360.05810546875,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 1,
            "end_row_offset_idx": 2,
            "start_col_offset_idx": 0,
            "end_col_offset_idx": 1,
            "text": "FID 30.48 35.57 46.45",
            "column_header": false,
            "row_header": false,
            "row_section": false
          },
          {
            "bbox": {
              "l": 338.8375244140625,
              "t": 361.0497741699219,
              "r": 355.22100830078125,
              "b": 355.03204345703125,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 2,
            "col_span": 1,
            "start_row_offset_idx": 1,
            "end_row_offset_idx": 3,
            "start_col_offset_idx": 1,
            "end_col_offset_idx": 2,
            "text": "SVD",
            "column_header": false,
            "row_header": true,
            "row_section": false
          },
          {
            "bbox": {
              "l": 383.6098327636719,
              "t": 355.998291015625,
              "r": 542.774658203125,
              "b": 350.02294921875,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 2,
            "end_row_offset_idx": 3,
            "start_col_offset_idx": 0,
            "end_col_offset_idx": 1,
            "text": "FVD 418.93 786.68 1079.28",
            "column_header": false,
            "row_header": false,
            "row_section": false
          },
          {
            "bbox": {
              "l": 385.258544921875,
              "t": 341.809326171875,
              "r": 538.473388671875,
              "b": 335.86785888671875,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 3,
            "end_row_offset_idx": 4,
            "start_col_offset_idx": 0,
            "end_col_offset_idx": 1,
            "text": "FID 15.04 16.30 20.45",
            "column_header": false,
            "row_header": false,
            "row_section": false
          },
          {
            "bbox": {
              "l": 324.5727844238281,
              "t": 336.8510437011719,
              "r": 369.31591796875,
              "b": 329.2568359375,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 2,
            "col_span": 1,
            "start_row_offset_idx": 3,
            "end_row_offset_idx": 5,
            "start_col_offset_idx": 1,
            "end_col_offset_idx": 2,
            "text": "DrivingGPT",
            "column_header": false,
            "row_header": true,
            "row_section": false
          },
          {
            "bbox": {
              "l": 383.60980224609375,
              "t": 331.8419494628906,
              "r": 540.5963134765625,
              "b": 325.83270263671875,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 4,
            "end_row_offset_idx": 5,
            "start_col_offset_idx": 0,
            "end_col_offset_idx": 1,
            "text": "FVD 278.11 454.28 506.95",
            "column_header": false,
            "row_header": false,
            "row_section": false
          }
        ],
        "num_rows": 5,
        "num_cols": 2,
        "grid": [
          [
            {
              "bbox": {
                "l": 335.6002197265625,
                "t": 380.2478332519531,
                "r": 548.1788330078125,
                "b": 374.28094482421875,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 0,
              "end_row_offset_idx": 1,
              "start_col_offset_idx": 0,
              "end_col_offset_idx": 1,
              "text": "Model Metric 16 Frames 32 Frames 64 Frames",
              "column_header": true,
              "row_header": false,
              "row_section": false
            },
            {
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 0,
              "end_row_offset_idx": 1,
              "start_col_offset_idx": 1,
              "end_col_offset_idx": 2,
              "text": "",
              "column_header": false,
              "row_header": false,
              "row_section": false
            }
          ],
          [
            {
              "bbox": {
                "l": 385.2585754394531,
                "t": 365.99957275390625,
                "r": 538.4734497070312,
                "b": 360.05810546875,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 1,
              "end_row_offset_idx": 2,
              "start_col_offset_idx": 0,
              "end_col_offset_idx": 1,
              "text": "FID 30.48 35.57 46.45",
              "column_header": false,
              "row_header": false,
              "row_section": false
            },
            {
              "bbox": {
                "l": 338.8375244140625,
                "t": 361.0497741699219,
                "r": 355.22100830078125,
                "b": 355.03204345703125,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 2,
              "col_span": 1,
              "start_row_offset_idx": 1,
              "end_row_offset_idx": 3,
              "start_col_offset_idx": 1,
              "end_col_offset_idx": 2,
              "text": "SVD",
              "column_header": false,
              "row_header": true,
              "row_section": false
            }
          ],
          [
            {
              "bbox": {
                "l": 383.6098327636719,
                "t": 355.998291015625,
                "r": 542.774658203125,
                "b": 350.02294921875,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 2,
              "end_row_offset_idx": 3,
              "start_col_offset_idx": 0,
              "end_col_offset_idx": 1,
              "text": "FVD 418.93 786.68 1079.28",
              "column_header": false,
              "row_header": false,
              "row_section": false
            },
            {
              "bbox": {
                "l": 338.8375244140625,
                "t": 361.0497741699219,
                "r": 355.22100830078125,
                "b": 355.03204345703125,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 2,
              "col_span": 1,
              "start_row_offset_idx": 1,
              "end_row_offset_idx": 3,
              "start_col_offset_idx": 1,
              "end_col_offset_idx": 2,
              "text": "SVD",
              "column_header": false,
              "row_header": true,
              "row_section": false
            }
          ],
          [
            {
              "bbox": {
                "l": 385.258544921875,
                "t": 341.809326171875,
                "r": 538.473388671875,
                "b": 335.86785888671875,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 3,
              "end_row_offset_idx": 4,
              "start_col_offset_idx": 0,
              "end_col_offset_idx": 1,
              "text": "FID 15.04 16.30 20.45",
              "column_header": false,
              "row_header": false,
              "row_section": false
            },
            {
              "bbox": {
                "l": 324.5727844238281,
                "t": 336.8510437011719,
                "r": 369.31591796875,
                "b": 329.2568359375,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 2,
              "col_span": 1,
              "start_row_offset_idx": 3,
              "end_row_offset_idx": 5,
              "start_col_offset_idx": 1,
              "end_col_offset_idx": 2,
              "text": "DrivingGPT",
              "column_header": false,
              "row_header": true,
              "row_section": false
            }
          ],
          [
            {
              "bbox": {
                "l": 383.60980224609375,
                "t": 331.8419494628906,
                "r": 540.5963134765625,
                "b": 325.83270263671875,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 4,
              "end_row_offset_idx": 5,
              "start_col_offset_idx": 0,
              "end_col_offset_idx": 1,
              "text": "FVD 278.11 454.28 506.95",
              "column_header": false,
              "row_header": false,
              "row_section": false
            },
            {
              "bbox": {
                "l": 324.5727844238281,
                "t": 336.8510437011719,
                "r": 369.31591796875,
                "b": 329.2568359375,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 2,
              "col_span": 1,
              "start_row_offset_idx": 3,
              "end_row_offset_idx": 5,
              "start_col_offset_idx": 1,
              "end_col_offset_idx": 2,
              "text": "DrivingGPT",
              "column_header": false,
              "row_header": true,
              "row_section": false
            }
          ]
        ]
      }
    },
    {
      "self_ref": "#/tables/2",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "table",
      "prov": [
        {
          "page_no": 7,
          "bbox": {
            "l": 138.6023406982422,
            "t": 481.3292541503906,
            "r": 472.59649658203125,
            "b": 427.0238952636719,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            0
          ]
        }
      ],
      "captions": [
        {
          "$ref": "#/texts/155"
        }
      ],
      "references": [],
      "footnotes": [],
      "data": {
        "table_cells": [
          {
            "bbox": {
              "l": 145.2815399169922,
              "t": 476.2032775878906,
              "r": 174.84375,
              "b": 470.0254211425781,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 0,
            "end_row_offset_idx": 1,
            "start_col_offset_idx": 0,
            "end_col_offset_idx": 1,
            "text": "Method",
            "column_header": true,
            "row_header": false,
            "row_section": false
          },
          {
            "bbox": {
              "l": 255.2024688720703,
              "t": 476.36468505859375,
              "r": 312.122314453125,
              "b": 468.4114685058594,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 0,
            "end_row_offset_idx": 1,
            "start_col_offset_idx": 1,
            "end_col_offset_idx": 2,
            "text": "NC \u2191  DAC \u2191",
            "column_header": true,
            "row_header": false,
            "row_section": false
          },
          {
            "bbox": {
              "l": 324.5069580078125,
              "t": 476.36468505859375,
              "r": 349.3623046875,
              "b": 468.4114685058594,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 0,
            "end_row_offset_idx": 1,
            "start_col_offset_idx": 2,
            "end_col_offset_idx": 3,
            "text": "TTC \u2191",
            "column_header": true,
            "row_header": false,
            "row_section": false
          },
          {
            "bbox": {
              "l": 361.9073791503906,
              "t": 476.36468505859375,
              "r": 392.22332763671875,
              "b": 468.4114685058594,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 0,
            "end_row_offset_idx": 1,
            "start_col_offset_idx": 3,
            "end_col_offset_idx": 4,
            "text": "Comf. \u2191",
            "column_header": true,
            "row_header": false,
            "row_section": false
          },
          {
            "bbox": {
              "l": 404.4734802246094,
              "t": 476.36468505859375,
              "r": 422.486328125,
              "b": 468.4114685058594,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 0,
            "end_row_offset_idx": 1,
            "start_col_offset_idx": 4,
            "end_col_offset_idx": 5,
            "text": "EP \u2191",
            "column_header": true,
            "row_header": false,
            "row_section": false
          },
          {
            "bbox": {
              "l": 434.7364501953125,
              "t": 476.36468505859375,
              "r": 466.6922912597656,
              "b": 468.4114685058594,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 0,
            "end_row_offset_idx": 1,
            "start_col_offset_idx": 5,
            "end_col_offset_idx": 6,
            "text": "PDMS \u2191",
            "column_header": true,
            "row_header": false,
            "row_section": false
          },
          {
            "bbox": {
              "l": 145.4070587158203,
              "t": 460.5240478515625,
              "r": 208.94297790527344,
              "b": 452.45428466796875,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 1,
            "end_row_offset_idx": 2,
            "start_col_offset_idx": 0,
            "end_col_offset_idx": 1,
            "text": "Constant Velocity",
            "column_header": false,
            "row_header": true,
            "row_section": false
          },
          {
            "bbox": {
              "l": 257.4168701171875,
              "t": 460.53302001953125,
              "r": 307.01898193359375,
              "b": 454.2117004394531,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 1,
            "end_row_offset_idx": 2,
            "start_col_offset_idx": 1,
            "end_col_offset_idx": 2,
            "text": "66.7 63.9",
            "column_header": false,
            "row_header": false,
            "row_section": false
          },
          {
            "bbox": {
              "l": 329.13360595703125,
              "t": 460.5688781738281,
              "r": 344.4930419921875,
              "b": 454.2834167480469,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 1,
            "end_row_offset_idx": 2,
            "start_col_offset_idx": 2,
            "end_col_offset_idx": 3,
            "text": "45.2",
            "column_header": false,
            "row_header": false,
            "row_section": false
          },
          {
            "bbox": {
              "l": 367.41680908203125,
              "t": 460.5688781738281,
              "r": 386.7931823730469,
              "b": 454.2923889160156,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 1,
            "end_row_offset_idx": 2,
            "start_col_offset_idx": 3,
            "end_col_offset_idx": 4,
            "text": "100.0",
            "column_header": false,
            "row_header": false,
            "row_section": false
          },
          {
            "bbox": {
              "l": 405.906982421875,
              "t": 460.53302001953125,
              "r": 421.0422668457031,
              "b": 454.2834167480469,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 1,
            "end_row_offset_idx": 2,
            "start_col_offset_idx": 4,
            "end_col_offset_idx": 5,
            "text": "23.6",
            "column_header": false,
            "row_header": false,
            "row_section": false
          },
          {
            "bbox": {
              "l": 443.1419677734375,
              "t": 460.4612731933594,
              "r": 458.34002685546875,
              "b": 454.3103332519531,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 1,
            "end_row_offset_idx": 2,
            "start_col_offset_idx": 5,
            "end_col_offset_idx": 6,
            "text": "24.2",
            "column_header": false,
            "row_header": false,
            "row_section": false
          },
          {
            "bbox": {
              "l": 145.30841064453125,
              "t": 449.8288879394531,
              "r": 242.92559814453125,
              "b": 443.5434265136719,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 2,
            "end_row_offset_idx": 3,
            "start_col_offset_idx": 0,
            "end_col_offset_idx": 1,
            "text": "ResNet-50 + MLP baseline",
            "column_header": false,
            "row_header": true,
            "row_section": false
          },
          {
            "bbox": {
              "l": 257.3809814453125,
              "t": 449.79302978515625,
              "r": 307.01898193359375,
              "b": 443.4717102050781,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 2,
            "end_row_offset_idx": 3,
            "start_col_offset_idx": 1,
            "end_col_offset_idx": 2,
            "text": "92.6 89.9",
            "column_header": false,
            "row_header": false,
            "row_section": false
          },
          {
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 2,
            "end_row_offset_idx": 3,
            "start_col_offset_idx": 2,
            "end_col_offset_idx": 3,
            "text": "",
            "column_header": false,
            "row_header": false,
            "row_section": false
          },
          {
            "bbox": {
              "l": 329.5281066894531,
              "t": 449.79302978515625,
              "r": 420.86883544921875,
              "b": 443.4717102050781,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 2,
            "end_row_offset_idx": 3,
            "start_col_offset_idx": 3,
            "end_col_offset_idx": 4,
            "text": "86.2 96.3 73.7",
            "column_header": false,
            "row_header": false,
            "row_section": false
          },
          {
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 2,
            "end_row_offset_idx": 3,
            "start_col_offset_idx": 4,
            "end_col_offset_idx": 5,
            "text": "",
            "column_header": false,
            "row_header": false,
            "row_section": false
          },
          {
            "bbox": {
              "l": 443.05230712890625,
              "t": 449.7212829589844,
              "r": 458.071044921875,
              "b": 443.5434265136719,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 2,
            "end_row_offset_idx": 3,
            "start_col_offset_idx": 5,
            "end_col_offset_idx": 6,
            "text": "77.8",
            "column_header": false,
            "row_header": false,
            "row_section": false
          },
          {
            "bbox": {
              "l": 145.2994384765625,
              "t": 439.0450439453125,
              "r": 189.6024169921875,
              "b": 430.97528076171875,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 3,
            "end_row_offset_idx": 4,
            "start_col_offset_idx": 0,
            "end_col_offset_idx": 1,
            "text": "DrivingGPT",
            "column_header": false,
            "row_header": true,
            "row_section": false
          },
          {
            "bbox": {
              "l": 257.3451232910156,
              "t": 439.0898742675781,
              "r": 307.1803894042969,
              "b": 432.8133850097656,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 3,
            "end_row_offset_idx": 4,
            "start_col_offset_idx": 1,
            "end_col_offset_idx": 2,
            "text": "98.9 90.7",
            "column_header": false,
            "row_header": false,
            "row_section": false
          },
          {
            "bbox": {
              "l": 329.2591247558594,
              "t": 439.0898742675781,
              "r": 344.47509765625,
              "b": 432.8133850097656,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 3,
            "end_row_offset_idx": 4,
            "start_col_offset_idx": 2,
            "end_col_offset_idx": 3,
            "text": "94.9",
            "column_header": false,
            "row_header": false,
            "row_section": false
          },
          {
            "bbox": {
              "l": 369.344970703125,
              "t": 439.0898742675781,
              "r": 384.4802551269531,
              "b": 432.7326965332031,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 3,
            "end_row_offset_idx": 4,
            "start_col_offset_idx": 3,
            "end_col_offset_idx": 4,
            "text": "95.6",
            "column_header": false,
            "row_header": false,
            "row_section": false
          },
          {
            "bbox": {
              "l": 405.7904357910156,
              "t": 439.0898742675781,
              "r": 421.12298583984375,
              "b": 432.8133850097656,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 3,
            "end_row_offset_idx": 4,
            "start_col_offset_idx": 4,
            "end_col_offset_idx": 5,
            "text": "79.7",
            "column_header": false,
            "row_header": false,
            "row_section": false
          },
          {
            "bbox": {
              "l": 443.1240539550781,
              "t": 439.0898742675781,
              "r": 458.34002685546875,
              "b": 432.8133850097656,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 3,
            "end_row_offset_idx": 4,
            "start_col_offset_idx": 5,
            "end_col_offset_idx": 6,
            "text": "82.4",
            "column_header": false,
            "row_header": false,
            "row_section": false
          }
        ],
        "num_rows": 4,
        "num_cols": 6,
        "grid": [
          [
            {
              "bbox": {
                "l": 145.2815399169922,
                "t": 476.2032775878906,
                "r": 174.84375,
                "b": 470.0254211425781,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 0,
              "end_row_offset_idx": 1,
              "start_col_offset_idx": 0,
              "end_col_offset_idx": 1,
              "text": "Method",
              "column_header": true,
              "row_header": false,
              "row_section": false
            },
            {
              "bbox": {
                "l": 255.2024688720703,
                "t": 476.36468505859375,
                "r": 312.122314453125,
                "b": 468.4114685058594,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 0,
              "end_row_offset_idx": 1,
              "start_col_offset_idx": 1,
              "end_col_offset_idx": 2,
              "text": "NC \u2191  DAC \u2191",
              "column_header": true,
              "row_header": false,
              "row_section": false
            },
            {
              "bbox": {
                "l": 324.5069580078125,
                "t": 476.36468505859375,
                "r": 349.3623046875,
                "b": 468.4114685058594,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 0,
              "end_row_offset_idx": 1,
              "start_col_offset_idx": 2,
              "end_col_offset_idx": 3,
              "text": "TTC \u2191",
              "column_header": true,
              "row_header": false,
              "row_section": false
            },
            {
              "bbox": {
                "l": 361.9073791503906,
                "t": 476.36468505859375,
                "r": 392.22332763671875,
                "b": 468.4114685058594,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 0,
              "end_row_offset_idx": 1,
              "start_col_offset_idx": 3,
              "end_col_offset_idx": 4,
              "text": "Comf. \u2191",
              "column_header": true,
              "row_header": false,
              "row_section": false
            },
            {
              "bbox": {
                "l": 404.4734802246094,
                "t": 476.36468505859375,
                "r": 422.486328125,
                "b": 468.4114685058594,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 0,
              "end_row_offset_idx": 1,
              "start_col_offset_idx": 4,
              "end_col_offset_idx": 5,
              "text": "EP \u2191",
              "column_header": true,
              "row_header": false,
              "row_section": false
            },
            {
              "bbox": {
                "l": 434.7364501953125,
                "t": 476.36468505859375,
                "r": 466.6922912597656,
                "b": 468.4114685058594,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 0,
              "end_row_offset_idx": 1,
              "start_col_offset_idx": 5,
              "end_col_offset_idx": 6,
              "text": "PDMS \u2191",
              "column_header": true,
              "row_header": false,
              "row_section": false
            }
          ],
          [
            {
              "bbox": {
                "l": 145.4070587158203,
                "t": 460.5240478515625,
                "r": 208.94297790527344,
                "b": 452.45428466796875,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 1,
              "end_row_offset_idx": 2,
              "start_col_offset_idx": 0,
              "end_col_offset_idx": 1,
              "text": "Constant Velocity",
              "column_header": false,
              "row_header": true,
              "row_section": false
            },
            {
              "bbox": {
                "l": 257.4168701171875,
                "t": 460.53302001953125,
                "r": 307.01898193359375,
                "b": 454.2117004394531,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 1,
              "end_row_offset_idx": 2,
              "start_col_offset_idx": 1,
              "end_col_offset_idx": 2,
              "text": "66.7 63.9",
              "column_header": false,
              "row_header": false,
              "row_section": false
            },
            {
              "bbox": {
                "l": 329.13360595703125,
                "t": 460.5688781738281,
                "r": 344.4930419921875,
                "b": 454.2834167480469,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 1,
              "end_row_offset_idx": 2,
              "start_col_offset_idx": 2,
              "end_col_offset_idx": 3,
              "text": "45.2",
              "column_header": false,
              "row_header": false,
              "row_section": false
            },
            {
              "bbox": {
                "l": 367.41680908203125,
                "t": 460.5688781738281,
                "r": 386.7931823730469,
                "b": 454.2923889160156,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 1,
              "end_row_offset_idx": 2,
              "start_col_offset_idx": 3,
              "end_col_offset_idx": 4,
              "text": "100.0",
              "column_header": false,
              "row_header": false,
              "row_section": false
            },
            {
              "bbox": {
                "l": 405.906982421875,
                "t": 460.53302001953125,
                "r": 421.0422668457031,
                "b": 454.2834167480469,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 1,
              "end_row_offset_idx": 2,
              "start_col_offset_idx": 4,
              "end_col_offset_idx": 5,
              "text": "23.6",
              "column_header": false,
              "row_header": false,
              "row_section": false
            },
            {
              "bbox": {
                "l": 443.1419677734375,
                "t": 460.4612731933594,
                "r": 458.34002685546875,
                "b": 454.3103332519531,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 1,
              "end_row_offset_idx": 2,
              "start_col_offset_idx": 5,
              "end_col_offset_idx": 6,
              "text": "24.2",
              "column_header": false,
              "row_header": false,
              "row_section": false
            }
          ],
          [
            {
              "bbox": {
                "l": 145.30841064453125,
                "t": 449.8288879394531,
                "r": 242.92559814453125,
                "b": 443.5434265136719,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 2,
              "end_row_offset_idx": 3,
              "start_col_offset_idx": 0,
              "end_col_offset_idx": 1,
              "text": "ResNet-50 + MLP baseline",
              "column_header": false,
              "row_header": true,
              "row_section": false
            },
            {
              "bbox": {
                "l": 257.3809814453125,
                "t": 449.79302978515625,
                "r": 307.01898193359375,
                "b": 443.4717102050781,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 2,
              "end_row_offset_idx": 3,
              "start_col_offset_idx": 1,
              "end_col_offset_idx": 2,
              "text": "92.6 89.9",
              "column_header": false,
              "row_header": false,
              "row_section": false
            },
            {
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 2,
              "end_row_offset_idx": 3,
              "start_col_offset_idx": 2,
              "end_col_offset_idx": 3,
              "text": "",
              "column_header": false,
              "row_header": false,
              "row_section": false
            },
            {
              "bbox": {
                "l": 329.5281066894531,
                "t": 449.79302978515625,
                "r": 420.86883544921875,
                "b": 443.4717102050781,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 2,
              "end_row_offset_idx": 3,
              "start_col_offset_idx": 3,
              "end_col_offset_idx": 4,
              "text": "86.2 96.3 73.7",
              "column_header": false,
              "row_header": false,
              "row_section": false
            },
            {
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 2,
              "end_row_offset_idx": 3,
              "start_col_offset_idx": 4,
              "end_col_offset_idx": 5,
              "text": "",
              "column_header": false,
              "row_header": false,
              "row_section": false
            },
            {
              "bbox": {
                "l": 443.05230712890625,
                "t": 449.7212829589844,
                "r": 458.071044921875,
                "b": 443.5434265136719,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 2,
              "end_row_offset_idx": 3,
              "start_col_offset_idx": 5,
              "end_col_offset_idx": 6,
              "text": "77.8",
              "column_header": false,
              "row_header": false,
              "row_section": false
            }
          ],
          [
            {
              "bbox": {
                "l": 145.2994384765625,
                "t": 439.0450439453125,
                "r": 189.6024169921875,
                "b": 430.97528076171875,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 3,
              "end_row_offset_idx": 4,
              "start_col_offset_idx": 0,
              "end_col_offset_idx": 1,
              "text": "DrivingGPT",
              "column_header": false,
              "row_header": true,
              "row_section": false
            },
            {
              "bbox": {
                "l": 257.3451232910156,
                "t": 439.0898742675781,
                "r": 307.1803894042969,
                "b": 432.8133850097656,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 3,
              "end_row_offset_idx": 4,
              "start_col_offset_idx": 1,
              "end_col_offset_idx": 2,
              "text": "98.9 90.7",
              "column_header": false,
              "row_header": false,
              "row_section": false
            },
            {
              "bbox": {
                "l": 329.2591247558594,
                "t": 439.0898742675781,
                "r": 344.47509765625,
                "b": 432.8133850097656,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 3,
              "end_row_offset_idx": 4,
              "start_col_offset_idx": 2,
              "end_col_offset_idx": 3,
              "text": "94.9",
              "column_header": false,
              "row_header": false,
              "row_section": false
            },
            {
              "bbox": {
                "l": 369.344970703125,
                "t": 439.0898742675781,
                "r": 384.4802551269531,
                "b": 432.7326965332031,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 3,
              "end_row_offset_idx": 4,
              "start_col_offset_idx": 3,
              "end_col_offset_idx": 4,
              "text": "95.6",
              "column_header": false,
              "row_header": false,
              "row_section": false
            },
            {
              "bbox": {
                "l": 405.7904357910156,
                "t": 439.0898742675781,
                "r": 421.12298583984375,
                "b": 432.8133850097656,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 3,
              "end_row_offset_idx": 4,
              "start_col_offset_idx": 4,
              "end_col_offset_idx": 5,
              "text": "79.7",
              "column_header": false,
              "row_header": false,
              "row_section": false
            },
            {
              "bbox": {
                "l": 443.1240539550781,
                "t": 439.0898742675781,
                "r": 458.34002685546875,
                "b": 432.8133850097656,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 3,
              "end_row_offset_idx": 4,
              "start_col_offset_idx": 5,
              "end_col_offset_idx": 6,
              "text": "82.4",
              "column_header": false,
              "row_header": false,
              "row_section": false
            }
          ]
        ]
      }
    },
    {
      "self_ref": "#/tables/3",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "table",
      "prov": [
        {
          "page_no": 7,
          "bbox": {
            "l": 316.4113464355469,
            "t": 384.3707275390625,
            "r": 554.3980102539062,
            "b": 330.4047546386719,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            0
          ]
        }
      ],
      "captions": [
        {
          "$ref": "#/texts/159"
        }
      ],
      "references": [],
      "footnotes": [],
      "data": {
        "table_cells": [
          {
            "bbox": {
              "l": 343.8994445800781,
              "t": 379.34405517578125,
              "r": 379.3077392578125,
              "b": 373.1393127441406,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 0,
            "end_row_offset_idx": 1,
            "start_col_offset_idx": 0,
            "end_col_offset_idx": 1,
            "text": "Tokenizer",
            "column_header": true,
            "row_header": false,
            "row_section": false
          },
          {
            "bbox": {
              "l": 411.808837890625,
              "t": 379.44268798828125,
              "r": 471.1322937011719,
              "b": 371.4894714355469,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 0,
            "end_row_offset_idx": 1,
            "start_col_offset_idx": 1,
            "end_col_offset_idx": 2,
            "text": "rFVD\u2193  rFID\u2193",
            "column_header": true,
            "row_header": false,
            "row_section": false
          },
          {
            "bbox": {
              "l": 483.3824462890625,
              "t": 379.44268798828125,
              "r": 547.6102294921875,
              "b": 371.4894714355469,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 0,
            "end_row_offset_idx": 1,
            "start_col_offset_idx": 2,
            "end_col_offset_idx": 3,
            "text": "PSNR\u2191  SSIM\u2191",
            "column_header": true,
            "row_header": false,
            "row_section": false
          },
          {
            "bbox": {
              "l": 332.6195983886719,
              "t": 363.60205078125,
              "r": 389.7355651855469,
              "b": 356.08819580078125,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 1,
            "end_row_offset_idx": 2,
            "start_col_offset_idx": 0,
            "end_col_offset_idx": 1,
            "text": "Llama-Gen [49]",
            "column_header": false,
            "row_header": true,
            "row_section": false
          },
          {
            "bbox": {
              "l": 414.6910705566406,
              "t": 363.6468811035156,
              "r": 467.9066467285156,
              "b": 357.3703918457031,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 1,
            "end_row_offset_idx": 2,
            "start_col_offset_idx": 1,
            "end_col_offset_idx": 2,
            "text": "68.40 5.67",
            "column_header": false,
            "row_header": false,
            "row_section": false
          },
          {
            "bbox": {
              "l": 486.9369812011719,
              "t": 363.6468811035156,
              "r": 544.8599243164062,
              "b": 357.2897033691406,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 1,
            "end_row_offset_idx": 2,
            "start_col_offset_idx": 2,
            "end_col_offset_idx": 3,
            "text": "23.09 0.652",
            "column_header": false,
            "row_header": false,
            "row_section": false
          },
          {
            "bbox": {
              "l": 323.5328674316406,
              "t": 352.7992858886719,
              "r": 399.0209655761719,
              "b": 344.80126953125,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 2,
            "end_row_offset_idx": 3,
            "start_col_offset_idx": 0,
            "end_col_offset_idx": 1,
            "text": "OpenMAGVIT2 [39]",
            "column_header": false,
            "row_header": true,
            "row_section": false
          },
          {
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 2,
            "end_row_offset_idx": 3,
            "start_col_offset_idx": 1,
            "end_col_offset_idx": 2,
            "text": "",
            "column_header": false,
            "row_header": false,
            "row_section": false
          },
          {
            "bbox": {
              "l": 414.708984375,
              "t": 352.9068908691406,
              "r": 544.865234375,
              "b": 346.5497131347656,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 2,
            "end_row_offset_idx": 3,
            "start_col_offset_idx": 2,
            "end_col_offset_idx": 3,
            "text": "96.32 6.70 15.57 0.410",
            "column_header": false,
            "row_header": false,
            "row_section": false
          },
          {
            "bbox": {
              "l": 328.4280700683594,
              "t": 342.123046875,
              "r": 394.8780517578125,
              "b": 335.8824157714844,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 3,
            "end_row_offset_idx": 4,
            "start_col_offset_idx": 0,
            "end_col_offset_idx": 1,
            "text": "Cosmos Tokenizer",
            "column_header": false,
            "row_header": true,
            "row_section": false
          },
          {
            "bbox": {
              "l": 413.19427490234375,
              "t": 342.1678771972656,
              "r": 470.13092041015625,
              "b": 335.8824157714844,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 3,
            "end_row_offset_idx": 4,
            "start_col_offset_idx": 1,
            "end_col_offset_idx": 2,
            "text": "178.50 27.12",
            "column_header": false,
            "row_header": false,
            "row_section": false
          },
          {
            "bbox": {
              "l": 486.8204345703125,
              "t": 342.1678771972656,
              "r": 544.8151245117188,
              "b": 335.8913879394531,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 3,
            "end_row_offset_idx": 4,
            "start_col_offset_idx": 2,
            "end_col_offset_idx": 3,
            "text": "25.05 0.695",
            "column_header": false,
            "row_header": false,
            "row_section": false
          }
        ],
        "num_rows": 4,
        "num_cols": 3,
        "grid": [
          [
            {
              "bbox": {
                "l": 343.8994445800781,
                "t": 379.34405517578125,
                "r": 379.3077392578125,
                "b": 373.1393127441406,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 0,
              "end_row_offset_idx": 1,
              "start_col_offset_idx": 0,
              "end_col_offset_idx": 1,
              "text": "Tokenizer",
              "column_header": true,
              "row_header": false,
              "row_section": false
            },
            {
              "bbox": {
                "l": 411.808837890625,
                "t": 379.44268798828125,
                "r": 471.1322937011719,
                "b": 371.4894714355469,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 0,
              "end_row_offset_idx": 1,
              "start_col_offset_idx": 1,
              "end_col_offset_idx": 2,
              "text": "rFVD\u2193  rFID\u2193",
              "column_header": true,
              "row_header": false,
              "row_section": false
            },
            {
              "bbox": {
                "l": 483.3824462890625,
                "t": 379.44268798828125,
                "r": 547.6102294921875,
                "b": 371.4894714355469,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 0,
              "end_row_offset_idx": 1,
              "start_col_offset_idx": 2,
              "end_col_offset_idx": 3,
              "text": "PSNR\u2191  SSIM\u2191",
              "column_header": true,
              "row_header": false,
              "row_section": false
            }
          ],
          [
            {
              "bbox": {
                "l": 332.6195983886719,
                "t": 363.60205078125,
                "r": 389.7355651855469,
                "b": 356.08819580078125,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 1,
              "end_row_offset_idx": 2,
              "start_col_offset_idx": 0,
              "end_col_offset_idx": 1,
              "text": "Llama-Gen [49]",
              "column_header": false,
              "row_header": true,
              "row_section": false
            },
            {
              "bbox": {
                "l": 414.6910705566406,
                "t": 363.6468811035156,
                "r": 467.9066467285156,
                "b": 357.3703918457031,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 1,
              "end_row_offset_idx": 2,
              "start_col_offset_idx": 1,
              "end_col_offset_idx": 2,
              "text": "68.40 5.67",
              "column_header": false,
              "row_header": false,
              "row_section": false
            },
            {
              "bbox": {
                "l": 486.9369812011719,
                "t": 363.6468811035156,
                "r": 544.8599243164062,
                "b": 357.2897033691406,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 1,
              "end_row_offset_idx": 2,
              "start_col_offset_idx": 2,
              "end_col_offset_idx": 3,
              "text": "23.09 0.652",
              "column_header": false,
              "row_header": false,
              "row_section": false
            }
          ],
          [
            {
              "bbox": {
                "l": 323.5328674316406,
                "t": 352.7992858886719,
                "r": 399.0209655761719,
                "b": 344.80126953125,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 2,
              "end_row_offset_idx": 3,
              "start_col_offset_idx": 0,
              "end_col_offset_idx": 1,
              "text": "OpenMAGVIT2 [39]",
              "column_header": false,
              "row_header": true,
              "row_section": false
            },
            {
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 2,
              "end_row_offset_idx": 3,
              "start_col_offset_idx": 1,
              "end_col_offset_idx": 2,
              "text": "",
              "column_header": false,
              "row_header": false,
              "row_section": false
            },
            {
              "bbox": {
                "l": 414.708984375,
                "t": 352.9068908691406,
                "r": 544.865234375,
                "b": 346.5497131347656,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 2,
              "end_row_offset_idx": 3,
              "start_col_offset_idx": 2,
              "end_col_offset_idx": 3,
              "text": "96.32 6.70 15.57 0.410",
              "column_header": false,
              "row_header": false,
              "row_section": false
            }
          ],
          [
            {
              "bbox": {
                "l": 328.4280700683594,
                "t": 342.123046875,
                "r": 394.8780517578125,
                "b": 335.8824157714844,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 3,
              "end_row_offset_idx": 4,
              "start_col_offset_idx": 0,
              "end_col_offset_idx": 1,
              "text": "Cosmos Tokenizer",
              "column_header": false,
              "row_header": true,
              "row_section": false
            },
            {
              "bbox": {
                "l": 413.19427490234375,
                "t": 342.1678771972656,
                "r": 470.13092041015625,
                "b": 335.8824157714844,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 3,
              "end_row_offset_idx": 4,
              "start_col_offset_idx": 1,
              "end_col_offset_idx": 2,
              "text": "178.50 27.12",
              "column_header": false,
              "row_header": false,
              "row_section": false
            },
            {
              "bbox": {
                "l": 486.8204345703125,
                "t": 342.1678771972656,
                "r": 544.8151245117188,
                "b": 335.8913879394531,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 3,
              "end_row_offset_idx": 4,
              "start_col_offset_idx": 2,
              "end_col_offset_idx": 3,
              "text": "25.05 0.695",
              "column_header": false,
              "row_header": false,
              "row_section": false
            }
          ]
        ]
      }
    },
    {
      "self_ref": "#/tables/4",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "table",
      "prov": [
        {
          "page_no": 8,
          "bbox": {
            "l": 148.61468505859375,
            "t": 535.6893310546875,
            "r": 462.6405334472656,
            "b": 470.093505859375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            0
          ]
        }
      ],
      "captions": [
        {
          "$ref": "#/texts/169"
        }
      ],
      "references": [],
      "footnotes": [],
      "data": {
        "table_cells": [
          {
            "bbox": {
              "l": 162.49099731445312,
              "t": 530.018310546875,
              "r": 225.73101806640625,
              "b": 521.8678588867188,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 0,
            "end_row_offset_idx": 1,
            "start_col_offset_idx": 0,
            "end_col_offset_idx": 1,
            "text": "x y \u03b8",
            "column_header": true,
            "row_header": false,
            "row_section": false
          },
          {
            "bbox": {
              "l": 244.61146545410156,
              "t": 529.919677734375,
              "r": 301.53228759765625,
              "b": 521.9664916992188,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 0,
            "end_row_offset_idx": 1,
            "start_col_offset_idx": 1,
            "end_col_offset_idx": 2,
            "text": "NC \u2191  DAC \u2191",
            "column_header": true,
            "row_header": false,
            "row_section": false
          },
          {
            "bbox": {
              "l": 313.9169616699219,
              "t": 529.919677734375,
              "r": 338.77130126953125,
              "b": 521.9664916992188,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 0,
            "end_row_offset_idx": 1,
            "start_col_offset_idx": 2,
            "end_col_offset_idx": 3,
            "text": "TTC \u2191",
            "column_header": true,
            "row_header": false,
            "row_section": false
          },
          {
            "bbox": {
              "l": 351.3173522949219,
              "t": 529.919677734375,
              "r": 381.6322937011719,
              "b": 521.9664916992188,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 0,
            "end_row_offset_idx": 1,
            "start_col_offset_idx": 3,
            "end_col_offset_idx": 4,
            "text": "Comf. \u2191",
            "column_header": true,
            "row_header": false,
            "row_section": false
          },
          {
            "bbox": {
              "l": 393.8824462890625,
              "t": 529.919677734375,
              "r": 411.8962707519531,
              "b": 521.9664916992188,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 0,
            "end_row_offset_idx": 1,
            "start_col_offset_idx": 4,
            "end_col_offset_idx": 5,
            "text": "EP \u2191",
            "column_header": true,
            "row_header": false,
            "row_section": false
          },
          {
            "bbox": {
              "l": 424.1464538574219,
              "t": 529.919677734375,
              "r": 456.102294921875,
              "b": 521.9664916992188,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 0,
            "end_row_offset_idx": 1,
            "start_col_offset_idx": 5,
            "end_col_offset_idx": 6,
            "text": "PDMS \u2191",
            "column_header": true,
            "row_header": false,
            "row_section": false
          },
          {
            "bbox": {
              "l": 156.91183471679688,
              "t": 514.0800170898438,
              "r": 231.72747802734375,
              "b": 506.0192565917969,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 1,
            "end_row_offset_idx": 2,
            "start_col_offset_idx": 0,
            "end_col_offset_idx": 1,
            "text": "pred pred pred",
            "column_header": false,
            "row_header": false,
            "row_section": false
          },
          {
            "bbox": {
              "l": 246.75411987304688,
              "t": 514.1248779296875,
              "r": 296.5893859863281,
              "b": 507.848388671875,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 1,
            "end_row_offset_idx": 2,
            "start_col_offset_idx": 1,
            "end_col_offset_idx": 2,
            "text": "98.9 90.7",
            "column_header": false,
            "row_header": false,
            "row_section": false
          },
          {
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 1,
            "end_row_offset_idx": 2,
            "start_col_offset_idx": 2,
            "end_col_offset_idx": 3,
            "text": "",
            "column_header": false,
            "row_header": false,
            "row_section": false
          },
          {
            "bbox": {
              "l": 318.6681213378906,
              "t": 514.1248779296875,
              "r": 373.9549560546875,
              "b": 507.848388671875,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 1,
            "end_row_offset_idx": 2,
            "start_col_offset_idx": 3,
            "end_col_offset_idx": 4,
            "text": "94.9 95.6",
            "column_header": false,
            "row_header": false,
            "row_section": false
          },
          {
            "bbox": {
              "l": 395.2273254394531,
              "t": 514.0172729492188,
              "r": 410.28192138671875,
              "b": 507.7677001953125,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 1,
            "end_row_offset_idx": 2,
            "start_col_offset_idx": 4,
            "end_col_offset_idx": 5,
            "text": "79.7",
            "column_header": false,
            "row_header": false,
            "row_section": false
          },
          {
            "bbox": {
              "l": 432.5340576171875,
              "t": 514.1248779296875,
              "r": 447.7500305175781,
              "b": 507.848388671875,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 1,
            "end_row_offset_idx": 2,
            "start_col_offset_idx": 5,
            "end_col_offset_idx": 6,
            "text": "82.4",
            "column_header": false,
            "row_header": false,
            "row_section": false
          },
          {
            "bbox": {
              "l": 156.3871612548828,
              "t": 503.3400573730469,
              "r": 231.7318115234375,
              "b": 495.2702941894531,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 2,
            "end_row_offset_idx": 3,
            "start_col_offset_idx": 0,
            "end_col_offset_idx": 1,
            "text": "copy pred pred",
            "column_header": false,
            "row_header": false,
            "row_section": false
          },
          {
            "bbox": {
              "l": 246.7003173828125,
              "t": 503.3848876953125,
              "r": 296.5086669921875,
              "b": 497.0277099609375,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 2,
            "end_row_offset_idx": 3,
            "start_col_offset_idx": 1,
            "end_col_offset_idx": 2,
            "text": "75.9 89.6",
            "column_header": false,
            "row_header": false,
            "row_section": false
          },
          {
            "bbox": {
              "l": 318.7398681640625,
              "t": 503.3490295410156,
              "r": 333.1757507324219,
              "b": 497.09942626953125,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 2,
            "end_row_offset_idx": 3,
            "start_col_offset_idx": 2,
            "end_col_offset_idx": 3,
            "text": "63.1",
            "column_header": false,
            "row_header": false,
            "row_section": false
          },
          {
            "bbox": {
              "l": 356.8268127441406,
              "t": 503.3848876953125,
              "r": 376.20318603515625,
              "b": 497.1083984375,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 2,
            "end_row_offset_idx": 3,
            "start_col_offset_idx": 3,
            "end_col_offset_idx": 4,
            "text": "100.0",
            "column_header": false,
            "row_header": false,
            "row_section": false
          },
          {
            "bbox": {
              "l": 395.15557861328125,
              "t": 503.27728271484375,
              "r": 410.5150146484375,
              "b": 497.09942626953125,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 2,
            "end_row_offset_idx": 3,
            "start_col_offset_idx": 4,
            "end_col_offset_idx": 5,
            "text": "48.2",
            "column_header": false,
            "row_header": false,
            "row_section": false
          },
          {
            "bbox": {
              "l": 432.5699157714844,
              "t": 503.3848876953125,
              "r": 447.41827392578125,
              "b": 497.09942626953125,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 2,
            "end_row_offset_idx": 3,
            "start_col_offset_idx": 5,
            "end_col_offset_idx": 6,
            "text": "53.5",
            "column_header": false,
            "row_header": false,
            "row_section": false
          },
          {
            "bbox": {
              "l": 156.91183471679688,
              "t": 492.6000671386719,
              "r": 231.72747802734375,
              "b": 484.5303039550781,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 3,
            "end_row_offset_idx": 4,
            "start_col_offset_idx": 0,
            "end_col_offset_idx": 1,
            "text": "pred copy pred",
            "column_header": false,
            "row_header": false,
            "row_section": false
          },
          {
            "bbox": {
              "l": 246.7899932861328,
              "t": 492.53729248046875,
              "r": 296.5445556640625,
              "b": 486.2877197265625,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 3,
            "end_row_offset_idx": 4,
            "start_col_offset_idx": 1,
            "end_col_offset_idx": 2,
            "text": "97.8 88.4",
            "column_header": false,
            "row_header": false,
            "row_section": false
          },
          {
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 3,
            "end_row_offset_idx": 4,
            "start_col_offset_idx": 2,
            "end_col_offset_idx": 3,
            "text": "",
            "column_header": false,
            "row_header": false,
            "row_section": false
          },
          {
            "bbox": {
              "l": 318.7039794921875,
              "t": 492.6090393066406,
              "r": 410.5109558105469,
              "b": 486.2877197265625,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 3,
            "end_row_offset_idx": 4,
            "start_col_offset_idx": 3,
            "end_col_offset_idx": 4,
            "text": "90.6 94.7 76.2",
            "column_header": false,
            "row_header": false,
            "row_section": false
          },
          {
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 3,
            "end_row_offset_idx": 4,
            "start_col_offset_idx": 4,
            "end_col_offset_idx": 5,
            "text": "",
            "column_header": false,
            "row_header": false,
            "row_section": false
          },
          {
            "bbox": {
              "l": 432.4623107910156,
              "t": 492.53729248046875,
              "r": 447.72314453125,
              "b": 486.2877197265625,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 3,
            "end_row_offset_idx": 4,
            "start_col_offset_idx": 5,
            "end_col_offset_idx": 6,
            "text": "79.4",
            "column_header": false,
            "row_header": false,
            "row_section": false
          },
          {
            "bbox": {
              "l": 155.79083251953125,
              "t": 481.8610534667969,
              "r": 232.29217529296875,
              "b": 473.7912902832031,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 4,
            "end_row_offset_idx": 5,
            "start_col_offset_idx": 0,
            "end_col_offset_idx": 1,
            "text": "pred. pred copy",
            "column_header": false,
            "row_header": false,
            "row_section": false
          },
          {
            "bbox": {
              "l": 246.7899932861328,
              "t": 481.9058837890625,
              "r": 296.3024597167969,
              "b": 475.5487060546875,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 4,
            "end_row_offset_idx": 5,
            "start_col_offset_idx": 1,
            "end_col_offset_idx": 2,
            "text": "95.8 81.8",
            "column_header": false,
            "row_header": false,
            "row_section": false
          },
          {
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 4,
            "end_row_offset_idx": 5,
            "start_col_offset_idx": 2,
            "end_col_offset_idx": 3,
            "text": "",
            "column_header": false,
            "row_header": false,
            "row_section": false
          },
          {
            "bbox": {
              "l": 318.9371032714844,
              "t": 481.8700256347656,
              "r": 410.27783203125,
              "b": 475.5487060546875,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 4,
            "end_row_offset_idx": 5,
            "start_col_offset_idx": 3,
            "end_col_offset_idx": 4,
            "text": "88.1 94.6 70.7",
            "column_header": false,
            "row_header": false,
            "row_section": false
          },
          {
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 4,
            "end_row_offset_idx": 5,
            "start_col_offset_idx": 4,
            "end_col_offset_idx": 5,
            "text": "",
            "column_header": false,
            "row_header": false,
            "row_section": false
          },
          {
            "bbox": {
              "l": 432.4623107910156,
              "t": 481.79827880859375,
              "r": 447.02374267578125,
              "b": 475.62042236328125,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 4,
            "end_row_offset_idx": 5,
            "start_col_offset_idx": 5,
            "end_col_offset_idx": 6,
            "text": "73.1",
            "column_header": false,
            "row_header": false,
            "row_section": false
          }
        ],
        "num_rows": 5,
        "num_cols": 6,
        "grid": [
          [
            {
              "bbox": {
                "l": 162.49099731445312,
                "t": 530.018310546875,
                "r": 225.73101806640625,
                "b": 521.8678588867188,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 0,
              "end_row_offset_idx": 1,
              "start_col_offset_idx": 0,
              "end_col_offset_idx": 1,
              "text": "x y \u03b8",
              "column_header": true,
              "row_header": false,
              "row_section": false
            },
            {
              "bbox": {
                "l": 244.61146545410156,
                "t": 529.919677734375,
                "r": 301.53228759765625,
                "b": 521.9664916992188,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 0,
              "end_row_offset_idx": 1,
              "start_col_offset_idx": 1,
              "end_col_offset_idx": 2,
              "text": "NC \u2191  DAC \u2191",
              "column_header": true,
              "row_header": false,
              "row_section": false
            },
            {
              "bbox": {
                "l": 313.9169616699219,
                "t": 529.919677734375,
                "r": 338.77130126953125,
                "b": 521.9664916992188,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 0,
              "end_row_offset_idx": 1,
              "start_col_offset_idx": 2,
              "end_col_offset_idx": 3,
              "text": "TTC \u2191",
              "column_header": true,
              "row_header": false,
              "row_section": false
            },
            {
              "bbox": {
                "l": 351.3173522949219,
                "t": 529.919677734375,
                "r": 381.6322937011719,
                "b": 521.9664916992188,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 0,
              "end_row_offset_idx": 1,
              "start_col_offset_idx": 3,
              "end_col_offset_idx": 4,
              "text": "Comf. \u2191",
              "column_header": true,
              "row_header": false,
              "row_section": false
            },
            {
              "bbox": {
                "l": 393.8824462890625,
                "t": 529.919677734375,
                "r": 411.8962707519531,
                "b": 521.9664916992188,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 0,
              "end_row_offset_idx": 1,
              "start_col_offset_idx": 4,
              "end_col_offset_idx": 5,
              "text": "EP \u2191",
              "column_header": true,
              "row_header": false,
              "row_section": false
            },
            {
              "bbox": {
                "l": 424.1464538574219,
                "t": 529.919677734375,
                "r": 456.102294921875,
                "b": 521.9664916992188,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 0,
              "end_row_offset_idx": 1,
              "start_col_offset_idx": 5,
              "end_col_offset_idx": 6,
              "text": "PDMS \u2191",
              "column_header": true,
              "row_header": false,
              "row_section": false
            }
          ],
          [
            {
              "bbox": {
                "l": 156.91183471679688,
                "t": 514.0800170898438,
                "r": 231.72747802734375,
                "b": 506.0192565917969,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 1,
              "end_row_offset_idx": 2,
              "start_col_offset_idx": 0,
              "end_col_offset_idx": 1,
              "text": "pred pred pred",
              "column_header": false,
              "row_header": false,
              "row_section": false
            },
            {
              "bbox": {
                "l": 246.75411987304688,
                "t": 514.1248779296875,
                "r": 296.5893859863281,
                "b": 507.848388671875,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 1,
              "end_row_offset_idx": 2,
              "start_col_offset_idx": 1,
              "end_col_offset_idx": 2,
              "text": "98.9 90.7",
              "column_header": false,
              "row_header": false,
              "row_section": false
            },
            {
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 1,
              "end_row_offset_idx": 2,
              "start_col_offset_idx": 2,
              "end_col_offset_idx": 3,
              "text": "",
              "column_header": false,
              "row_header": false,
              "row_section": false
            },
            {
              "bbox": {
                "l": 318.6681213378906,
                "t": 514.1248779296875,
                "r": 373.9549560546875,
                "b": 507.848388671875,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 1,
              "end_row_offset_idx": 2,
              "start_col_offset_idx": 3,
              "end_col_offset_idx": 4,
              "text": "94.9 95.6",
              "column_header": false,
              "row_header": false,
              "row_section": false
            },
            {
              "bbox": {
                "l": 395.2273254394531,
                "t": 514.0172729492188,
                "r": 410.28192138671875,
                "b": 507.7677001953125,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 1,
              "end_row_offset_idx": 2,
              "start_col_offset_idx": 4,
              "end_col_offset_idx": 5,
              "text": "79.7",
              "column_header": false,
              "row_header": false,
              "row_section": false
            },
            {
              "bbox": {
                "l": 432.5340576171875,
                "t": 514.1248779296875,
                "r": 447.7500305175781,
                "b": 507.848388671875,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 1,
              "end_row_offset_idx": 2,
              "start_col_offset_idx": 5,
              "end_col_offset_idx": 6,
              "text": "82.4",
              "column_header": false,
              "row_header": false,
              "row_section": false
            }
          ],
          [
            {
              "bbox": {
                "l": 156.3871612548828,
                "t": 503.3400573730469,
                "r": 231.7318115234375,
                "b": 495.2702941894531,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 2,
              "end_row_offset_idx": 3,
              "start_col_offset_idx": 0,
              "end_col_offset_idx": 1,
              "text": "copy pred pred",
              "column_header": false,
              "row_header": false,
              "row_section": false
            },
            {
              "bbox": {
                "l": 246.7003173828125,
                "t": 503.3848876953125,
                "r": 296.5086669921875,
                "b": 497.0277099609375,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 2,
              "end_row_offset_idx": 3,
              "start_col_offset_idx": 1,
              "end_col_offset_idx": 2,
              "text": "75.9 89.6",
              "column_header": false,
              "row_header": false,
              "row_section": false
            },
            {
              "bbox": {
                "l": 318.7398681640625,
                "t": 503.3490295410156,
                "r": 333.1757507324219,
                "b": 497.09942626953125,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 2,
              "end_row_offset_idx": 3,
              "start_col_offset_idx": 2,
              "end_col_offset_idx": 3,
              "text": "63.1",
              "column_header": false,
              "row_header": false,
              "row_section": false
            },
            {
              "bbox": {
                "l": 356.8268127441406,
                "t": 503.3848876953125,
                "r": 376.20318603515625,
                "b": 497.1083984375,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 2,
              "end_row_offset_idx": 3,
              "start_col_offset_idx": 3,
              "end_col_offset_idx": 4,
              "text": "100.0",
              "column_header": false,
              "row_header": false,
              "row_section": false
            },
            {
              "bbox": {
                "l": 395.15557861328125,
                "t": 503.27728271484375,
                "r": 410.5150146484375,
                "b": 497.09942626953125,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 2,
              "end_row_offset_idx": 3,
              "start_col_offset_idx": 4,
              "end_col_offset_idx": 5,
              "text": "48.2",
              "column_header": false,
              "row_header": false,
              "row_section": false
            },
            {
              "bbox": {
                "l": 432.5699157714844,
                "t": 503.3848876953125,
                "r": 447.41827392578125,
                "b": 497.09942626953125,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 2,
              "end_row_offset_idx": 3,
              "start_col_offset_idx": 5,
              "end_col_offset_idx": 6,
              "text": "53.5",
              "column_header": false,
              "row_header": false,
              "row_section": false
            }
          ],
          [
            {
              "bbox": {
                "l": 156.91183471679688,
                "t": 492.6000671386719,
                "r": 231.72747802734375,
                "b": 484.5303039550781,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 3,
              "end_row_offset_idx": 4,
              "start_col_offset_idx": 0,
              "end_col_offset_idx": 1,
              "text": "pred copy pred",
              "column_header": false,
              "row_header": false,
              "row_section": false
            },
            {
              "bbox": {
                "l": 246.7899932861328,
                "t": 492.53729248046875,
                "r": 296.5445556640625,
                "b": 486.2877197265625,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 3,
              "end_row_offset_idx": 4,
              "start_col_offset_idx": 1,
              "end_col_offset_idx": 2,
              "text": "97.8 88.4",
              "column_header": false,
              "row_header": false,
              "row_section": false
            },
            {
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 3,
              "end_row_offset_idx": 4,
              "start_col_offset_idx": 2,
              "end_col_offset_idx": 3,
              "text": "",
              "column_header": false,
              "row_header": false,
              "row_section": false
            },
            {
              "bbox": {
                "l": 318.7039794921875,
                "t": 492.6090393066406,
                "r": 410.5109558105469,
                "b": 486.2877197265625,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 3,
              "end_row_offset_idx": 4,
              "start_col_offset_idx": 3,
              "end_col_offset_idx": 4,
              "text": "90.6 94.7 76.2",
              "column_header": false,
              "row_header": false,
              "row_section": false
            },
            {
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 3,
              "end_row_offset_idx": 4,
              "start_col_offset_idx": 4,
              "end_col_offset_idx": 5,
              "text": "",
              "column_header": false,
              "row_header": false,
              "row_section": false
            },
            {
              "bbox": {
                "l": 432.4623107910156,
                "t": 492.53729248046875,
                "r": 447.72314453125,
                "b": 486.2877197265625,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 3,
              "end_row_offset_idx": 4,
              "start_col_offset_idx": 5,
              "end_col_offset_idx": 6,
              "text": "79.4",
              "column_header": false,
              "row_header": false,
              "row_section": false
            }
          ],
          [
            {
              "bbox": {
                "l": 155.79083251953125,
                "t": 481.8610534667969,
                "r": 232.29217529296875,
                "b": 473.7912902832031,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 4,
              "end_row_offset_idx": 5,
              "start_col_offset_idx": 0,
              "end_col_offset_idx": 1,
              "text": "pred. pred copy",
              "column_header": false,
              "row_header": false,
              "row_section": false
            },
            {
              "bbox": {
                "l": 246.7899932861328,
                "t": 481.9058837890625,
                "r": 296.3024597167969,
                "b": 475.5487060546875,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 4,
              "end_row_offset_idx": 5,
              "start_col_offset_idx": 1,
              "end_col_offset_idx": 2,
              "text": "95.8 81.8",
              "column_header": false,
              "row_header": false,
              "row_section": false
            },
            {
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 4,
              "end_row_offset_idx": 5,
              "start_col_offset_idx": 2,
              "end_col_offset_idx": 3,
              "text": "",
              "column_header": false,
              "row_header": false,
              "row_section": false
            },
            {
              "bbox": {
                "l": 318.9371032714844,
                "t": 481.8700256347656,
                "r": 410.27783203125,
                "b": 475.5487060546875,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 4,
              "end_row_offset_idx": 5,
              "start_col_offset_idx": 3,
              "end_col_offset_idx": 4,
              "text": "88.1 94.6 70.7",
              "column_header": false,
              "row_header": false,
              "row_section": false
            },
            {
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 4,
              "end_row_offset_idx": 5,
              "start_col_offset_idx": 4,
              "end_col_offset_idx": 5,
              "text": "",
              "column_header": false,
              "row_header": false,
              "row_section": false
            },
            {
              "bbox": {
                "l": 432.4623107910156,
                "t": 481.79827880859375,
                "r": 447.02374267578125,
                "b": 475.62042236328125,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 4,
              "end_row_offset_idx": 5,
              "start_col_offset_idx": 5,
              "end_col_offset_idx": 6,
              "text": "73.1",
              "column_header": false,
              "row_header": false,
              "row_section": false
            }
          ]
        ]
      }
    },
    {
      "self_ref": "#/tables/5",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "table",
      "prov": [
        {
          "page_no": 8,
          "bbox": {
            "l": 58.50141525268555,
            "t": 398.0300598144531,
            "r": 294.2572326660156,
            "b": 353.6367492675781,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            0
          ]
        }
      ],
      "captions": [
        {
          "$ref": "#/texts/170"
        }
      ],
      "references": [],
      "footnotes": [],
      "data": {
        "table_cells": [
          {
            "bbox": {
              "l": 80.20646667480469,
              "t": 392.1142883300781,
              "r": 243.44874572753906,
              "b": 384.11627197265625,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 0,
            "end_row_offset_idx": 1,
            "start_col_offset_idx": 0,
            "end_col_offset_idx": 1,
            "text": "Dataset # Sequences # Frames / Seq",
            "column_header": true,
            "row_header": false,
            "row_section": false
          },
          {
            "bbox": {
              "l": 255.6544647216797,
              "t": 392.27569580078125,
              "r": 287.61029052734375,
              "b": 384.3224792480469,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 0,
            "end_row_offset_idx": 1,
            "start_col_offset_idx": 1,
            "end_col_offset_idx": 2,
            "text": "PDMS \u2191",
            "column_header": true,
            "row_header": false,
            "row_section": false
          },
          {
            "bbox": {
              "l": 65.63146209716797,
              "t": 376.4798889160156,
              "r": 220.98330688476562,
              "b": 370.1944274902344,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 1,
            "end_row_offset_idx": 2,
            "start_col_offset_idx": 0,
            "end_col_offset_idx": 1,
            "text": "nuPlan uniform 651k 16",
            "column_header": false,
            "row_header": false,
            "row_section": false
          },
          {
            "bbox": {
              "l": 263.9703063964844,
              "t": 376.44403076171875,
              "r": 279.19525146484375,
              "b": 370.1944274902344,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 1,
            "end_row_offset_idx": 2,
            "start_col_offset_idx": 1,
            "end_col_offset_idx": 2,
            "text": "74.6",
            "column_header": false,
            "row_header": false,
            "row_section": false
          },
          {
            "bbox": {
              "l": 67.35758209228516,
              "t": 365.695068359375,
              "r": 221.0416717529297,
              "b": 359.4544372558594,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 2,
            "end_row_offset_idx": 3,
            "start_col_offset_idx": 0,
            "end_col_offset_idx": 1,
            "text": "NAVSIM train 104k 12",
            "column_header": false,
            "row_header": false,
            "row_section": false
          },
          {
            "bbox": {
              "l": 264.04205322265625,
              "t": 365.7398986816406,
              "r": 279.2580261230469,
              "b": 359.4634094238281,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 2,
            "end_row_offset_idx": 3,
            "start_col_offset_idx": 1,
            "end_col_offset_idx": 2,
            "text": "82.4",
            "column_header": false,
            "row_header": false,
            "row_section": false
          }
        ],
        "num_rows": 3,
        "num_cols": 2,
        "grid": [
          [
            {
              "bbox": {
                "l": 80.20646667480469,
                "t": 392.1142883300781,
                "r": 243.44874572753906,
                "b": 384.11627197265625,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 0,
              "end_row_offset_idx": 1,
              "start_col_offset_idx": 0,
              "end_col_offset_idx": 1,
              "text": "Dataset # Sequences # Frames / Seq",
              "column_header": true,
              "row_header": false,
              "row_section": false
            },
            {
              "bbox": {
                "l": 255.6544647216797,
                "t": 392.27569580078125,
                "r": 287.61029052734375,
                "b": 384.3224792480469,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 0,
              "end_row_offset_idx": 1,
              "start_col_offset_idx": 1,
              "end_col_offset_idx": 2,
              "text": "PDMS \u2191",
              "column_header": true,
              "row_header": false,
              "row_section": false
            }
          ],
          [
            {
              "bbox": {
                "l": 65.63146209716797,
                "t": 376.4798889160156,
                "r": 220.98330688476562,
                "b": 370.1944274902344,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 1,
              "end_row_offset_idx": 2,
              "start_col_offset_idx": 0,
              "end_col_offset_idx": 1,
              "text": "nuPlan uniform 651k 16",
              "column_header": false,
              "row_header": false,
              "row_section": false
            },
            {
              "bbox": {
                "l": 263.9703063964844,
                "t": 376.44403076171875,
                "r": 279.19525146484375,
                "b": 370.1944274902344,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 1,
              "end_row_offset_idx": 2,
              "start_col_offset_idx": 1,
              "end_col_offset_idx": 2,
              "text": "74.6",
              "column_header": false,
              "row_header": false,
              "row_section": false
            }
          ],
          [
            {
              "bbox": {
                "l": 67.35758209228516,
                "t": 365.695068359375,
                "r": 221.0416717529297,
                "b": 359.4544372558594,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 2,
              "end_row_offset_idx": 3,
              "start_col_offset_idx": 0,
              "end_col_offset_idx": 1,
              "text": "NAVSIM train 104k 12",
              "column_header": false,
              "row_header": false,
              "row_section": false
            },
            {
              "bbox": {
                "l": 264.04205322265625,
                "t": 365.7398986816406,
                "r": 279.2580261230469,
                "b": 359.4634094238281,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 2,
              "end_row_offset_idx": 3,
              "start_col_offset_idx": 1,
              "end_col_offset_idx": 2,
              "text": "82.4",
              "column_header": false,
              "row_header": false,
              "row_section": false
            }
          ]
        ]
      }
    },
    {
      "self_ref": "#/tables/6",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "label": "table",
      "prov": [
        {
          "page_no": 8,
          "bbox": {
            "l": 332.2141418457031,
            "t": 325.1646728515625,
            "r": 537.8648681640625,
            "b": 281.13055419921875,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            0
          ]
        }
      ],
      "captions": [
        {
          "$ref": "#/texts/174"
        },
        {
          "$ref": "#/texts/175"
        }
      ],
      "references": [],
      "footnotes": [],
      "data": {
        "table_cells": [
          {
            "bbox": {
              "l": 339.199462890625,
              "t": 319.3150634765625,
              "r": 487.3512878417969,
              "b": 311.24530029296875,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 0,
            "end_row_offset_idx": 1,
            "start_col_offset_idx": 0,
            "end_col_offset_idx": 1,
            "text": "PosEmb for Image PosEmb for Action",
            "column_header": true,
            "row_header": false,
            "row_section": false
          },
          {
            "bbox": {
              "l": 499.5864562988281,
              "t": 319.4136962890625,
              "r": 531.5422973632812,
              "b": 311.4604797363281,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 0,
            "end_row_offset_idx": 1,
            "start_col_offset_idx": 1,
            "end_col_offset_idx": 2,
            "text": "PDMS \u2191",
            "column_header": true,
            "row_header": false,
            "row_section": false
          },
          {
            "bbox": {
              "l": 369.69317626953125,
              "t": 303.7165222167969,
              "r": 375.6468811035156,
              "b": 297.21588134765625,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 1,
            "end_row_offset_idx": 2,
            "start_col_offset_idx": 0,
            "end_col_offset_idx": 1,
            "text": "\u2713",
            "column_header": false,
            "row_header": false,
            "row_section": false
          },
          {
            "bbox": {
              "l": 508.0278625488281,
              "t": 303.6178894042969,
              "r": 522.8045043945312,
              "b": 297.3324279785156,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 1,
            "end_row_offset_idx": 2,
            "start_col_offset_idx": 1,
            "end_col_offset_idx": 2,
            "text": "65.3",
            "column_header": false,
            "row_header": false,
            "row_section": false
          },
          {
            "bbox": {
              "l": 369.69317626953125,
              "t": 292.9775085449219,
              "r": 455.8333740234375,
              "b": 286.47686767578125,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 2,
            "end_row_offset_idx": 3,
            "start_col_offset_idx": 0,
            "end_col_offset_idx": 1,
            "text": "\u2713 \u2713",
            "column_header": false,
            "row_header": false,
            "row_section": false
          },
          {
            "bbox": {
              "l": 507.97406005859375,
              "t": 292.8788757324219,
              "r": 523.1900634765625,
              "b": 286.6023864746094,
              "coord_origin": "BOTTOMLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 2,
            "end_row_offset_idx": 3,
            "start_col_offset_idx": 1,
            "end_col_offset_idx": 2,
            "text": "82.4",
            "column_header": false,
            "row_header": false,
            "row_section": false
          }
        ],
        "num_rows": 3,
        "num_cols": 2,
        "grid": [
          [
            {
              "bbox": {
                "l": 339.199462890625,
                "t": 319.3150634765625,
                "r": 487.3512878417969,
                "b": 311.24530029296875,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 0,
              "end_row_offset_idx": 1,
              "start_col_offset_idx": 0,
              "end_col_offset_idx": 1,
              "text": "PosEmb for Image PosEmb for Action",
              "column_header": true,
              "row_header": false,
              "row_section": false
            },
            {
              "bbox": {
                "l": 499.5864562988281,
                "t": 319.4136962890625,
                "r": 531.5422973632812,
                "b": 311.4604797363281,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 0,
              "end_row_offset_idx": 1,
              "start_col_offset_idx": 1,
              "end_col_offset_idx": 2,
              "text": "PDMS \u2191",
              "column_header": true,
              "row_header": false,
              "row_section": false
            }
          ],
          [
            {
              "bbox": {
                "l": 369.69317626953125,
                "t": 303.7165222167969,
                "r": 375.6468811035156,
                "b": 297.21588134765625,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 1,
              "end_row_offset_idx": 2,
              "start_col_offset_idx": 0,
              "end_col_offset_idx": 1,
              "text": "\u2713",
              "column_header": false,
              "row_header": false,
              "row_section": false
            },
            {
              "bbox": {
                "l": 508.0278625488281,
                "t": 303.6178894042969,
                "r": 522.8045043945312,
                "b": 297.3324279785156,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 1,
              "end_row_offset_idx": 2,
              "start_col_offset_idx": 1,
              "end_col_offset_idx": 2,
              "text": "65.3",
              "column_header": false,
              "row_header": false,
              "row_section": false
            }
          ],
          [
            {
              "bbox": {
                "l": 369.69317626953125,
                "t": 292.9775085449219,
                "r": 455.8333740234375,
                "b": 286.47686767578125,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 2,
              "end_row_offset_idx": 3,
              "start_col_offset_idx": 0,
              "end_col_offset_idx": 1,
              "text": "\u2713 \u2713",
              "column_header": false,
              "row_header": false,
              "row_section": false
            },
            {
              "bbox": {
                "l": 507.97406005859375,
                "t": 292.8788757324219,
                "r": 523.1900634765625,
                "b": 286.6023864746094,
                "coord_origin": "BOTTOMLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 2,
              "end_row_offset_idx": 3,
              "start_col_offset_idx": 1,
              "end_col_offset_idx": 2,
              "text": "82.4",
              "column_header": false,
              "row_header": false,
              "row_section": false
            }
          ]
        ]
      }
    }
  ],
  "key_value_items": [],
  "pages": {
    "1": {
      "size": {
        "width": 612.0,
        "height": 792.0
      },
      "page_no": 1
    },
    "2": {
      "size": {
        "width": 612.0,
        "height": 792.0
      },
      "page_no": 2
    },
    "3": {
      "size": {
        "width": 612.0,
        "height": 792.0
      },
      "page_no": 3
    },
    "4": {
      "size": {
        "width": 612.0,
        "height": 792.0
      },
      "page_no": 4
    },
    "5": {
      "size": {
        "width": 612.0,
        "height": 792.0
      },
      "page_no": 5
    },
    "6": {
      "size": {
        "width": 612.0,
        "height": 792.0
      },
      "page_no": 6
    },
    "7": {
      "size": {
        "width": 612.0,
        "height": 792.0
      },
      "page_no": 7
    },
    "8": {
      "size": {
        "width": 612.0,
        "height": 792.0
      },
      "page_no": 8
    },
    "9": {
      "size": {
        "width": 612.0,
        "height": 792.0
      },
      "page_no": 9
    },
    "10": {
      "size": {
        "width": 612.0,
        "height": 792.0
      },
      "page_no": 10
    },
    "11": {
      "size": {
        "width": 612.0,
        "height": 792.0
      },
      "page_no": 11
    },
    "12": {
      "size": {
        "width": 612.0,
        "height": 792.0
      },
      "page_no": 12
    },
    "13": {
      "size": {
        "width": 612.0,
        "height": 792.0
      },
      "page_no": 13
    },
    "14": {
      "size": {
        "width": 612.0,
        "height": 792.0
      },
      "page_no": 14
    },
    "15": {
      "size": {
        "width": 612.0,
        "height": 792.0
      },
      "page_no": 15
    }
  }
}